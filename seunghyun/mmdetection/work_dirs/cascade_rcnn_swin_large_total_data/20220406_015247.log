2022-04-06 01:52:48,258 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2
OpenCV: 4.5.5
MMCV: 1.4.6
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMDetection: 2.22.0+
------------------------------------------------------------

2022-04-06 01:52:50,135 - mmdet - INFO - Distributed training: False
2022-04-06 01:52:52,101 - mmdet - INFO - Config:
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='SwinTransformer',
        embed_dims=192,
        depths=[2, 2, 18, 2],
        num_heads=[6, 12, 24, 48],
        window_size=12,
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.2,
        patch_norm=True,
        out_indices=(0, 1, 2, 3),
        with_cp=False,
        convert_weights=True,
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth'
        )),
    neck=dict(
        type='FPN',
        in_channels=[192, 384, 768, 1536],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[2, 4, 8, 16],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(
            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))
        ]),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100)))
dataset_type = 'CocoDataset'
data_root = '/opt/ml/detection/dataset/'
classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
img_scale = (1024, 1024)
albu_train_transforms = [
    dict(
        type='OneOf',
        transforms=[
            dict(type='Flip', p=1.0),
            dict(type='RandomRotate90', p=1.0)
        ],
        p=0.5),
    dict(
        type='RandomResizedCrop',
        height=1024,
        width=1024,
        scale=(0.5, 1.0),
        p=0.5),
    dict(
        type='RandomBrightnessContrast',
        brightness_limit=0.1,
        contrast_limit=0.15,
        p=0.5),
    dict(
        type='HueSaturationValue',
        hue_shift_limit=15,
        sat_shift_limit=25,
        val_shift_limit=10,
        p=0.5),
    dict(type='GaussNoise', p=0.3),
    dict(
        type='OneOf',
        transforms=[
            dict(type='Blur', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='MedianBlur', blur_limit=5, p=1.0),
            dict(type='MotionBlur', p=1.0)
        ],
        p=0.1)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1024, 1024), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.0),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Flip', p=1.0),
                    dict(type='RandomRotate90', p=1.0)
                ],
                p=0.5),
            dict(
                type='RandomResizedCrop',
                height=1024,
                width=1024,
                scale=(0.5, 1.0),
                p=0.5),
            dict(
                type='RandomBrightnessContrast',
                brightness_limit=0.1,
                contrast_limit=0.15,
                p=0.5),
            dict(
                type='HueSaturationValue',
                hue_shift_limit=15,
                sat_shift_limit=25,
                val_shift_limit=10,
                p=0.5),
            dict(type='GaussNoise', p=0.3),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Blur', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='MedianBlur', blur_limit=5, p=1.0),
                    dict(type='MotionBlur', p=1.0)
                ],
                p=0.1)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/train.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1024, 1024), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.0),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Flip', p=1.0),
                            dict(type='RandomRotate90', p=1.0)
                        ],
                        p=0.5),
                    dict(
                        type='RandomResizedCrop',
                        height=1024,
                        width=1024,
                        scale=(0.5, 1.0),
                        p=0.5),
                    dict(
                        type='RandomBrightnessContrast',
                        brightness_limit=0.1,
                        contrast_limit=0.15,
                        p=0.5),
                    dict(
                        type='HueSaturationValue',
                        hue_shift_limit=15,
                        sat_shift_limit=25,
                        val_shift_limit=10,
                        p=0.5),
                    dict(type='GaussNoise', p=0.3),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Blur', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='MedianBlur', blur_limit=5, p=1.0),
                            dict(type='MotionBlur', p=1.0)
                        ],
                        p=0.1)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file=
        '/opt/ml/detection/dataset/stratified_kfold/basic_v2/cv_val_3.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/test.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='bbox', classwise=True)
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=2442,
    warmup_ratio=0.001,
    min_lr=1e-06)
runner = dict(type='EpochBasedRunner', max_epochs=15)
checkpoint_config = dict(max_keep_ckpts=3, interval=1)
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(
            type='WandbLoggerHook',
            interval=1000,
            init_kwargs=dict(
                project='two-stage-model',
                entity='canvas11',
                name='LEE_SwinL_CASCADE_RPN_CHANGED_TOTAL_DATA'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = '/opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/cascade_rcnn_swin_large/epoch_12.pth'
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth'
work_dir = 'work_dirs/cascade_rcnn_swin_large_total_data'
auto_resume = False
gpu_ids = [0]

2022-04-06 01:52:52,101 - mmdet - INFO - Set random seed to 160368801, deterministic: False
2022-04-06 01:52:54,222 - mmdet - INFO - load checkpoint from http path: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth
2022-04-06 01:52:54,892 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2022-04-06 01:52:54,917 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2022-04-06 01:52:54,925 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-04-06 01:52:55,038 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-04-06 01:52:55,159 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([192, 3, 4, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.projection.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.weight - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.reduction.weight - torch.Size([1536, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 48]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([4608, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([4608]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([1536, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([6144, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([6144]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([1536, 6144]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 48]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([4608, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([4608]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([1536, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([6144, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([6144]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([1536, 6144]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.norm0.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 192, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 384, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 1536, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([48, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([48]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 
2022-04-06 01:52:59,645 - mmdet - INFO - load checkpoint from local path: /opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/cascade_rcnn_swin_large/epoch_12.pth
2022-04-06 01:53:01,501 - mmdet - INFO - resumed epoch 12, iter 23412
2022-04-06 01:53:01,504 - mmdet - INFO - Start running, host: root@0a25b60abdd2, work_dir: /opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/cascade_rcnn_swin_large_total_data
2022-04-06 01:53:01,505 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2022-04-06 01:53:01,505 - mmdet - INFO - workflow: [('train', 1)], max: 15 epochs
2022-04-06 01:53:01,506 - mmdet - INFO - Checkpoints will be saved to /opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/cascade_rcnn_swin_large_total_data by HardDiskBackend.
2022-04-06 01:54:26,179 - mmdet - INFO - Epoch [13][50/2442]	lr: 1.045e-05, eta: 5:41:01, time: 1.554, data_time: 0.057, memory: 26586, loss_rpn_cls: 0.0390, loss_rpn_bbox: 0.0462, s0.loss_cls: 0.1681, s0.acc: 94.4746, s0.loss_bbox: 0.0875, s1.loss_cls: 0.0859, s1.acc: 94.7440, s1.loss_bbox: 0.0858, s2.loss_cls: 0.0442, s2.acc: 94.4591, s2.loss_bbox: 0.0543, loss: 0.6110
2022-04-06 01:55:40,728 - mmdet - INFO - Epoch [13][100/2442]	lr: 1.045e-05, eta: 5:32:51, time: 1.491, data_time: 0.008, memory: 26894, loss_rpn_cls: 0.0188, loss_rpn_bbox: 0.0499, s0.loss_cls: 0.1663, s0.acc: 94.2266, s0.loss_bbox: 0.0913, s1.loss_cls: 0.0754, s1.acc: 94.5940, s1.loss_bbox: 0.0847, s2.loss_cls: 0.0379, s2.acc: 94.5443, s2.loss_bbox: 0.0520, loss: 0.5763
2022-04-06 01:56:55,173 - mmdet - INFO - Epoch [13][150/2442]	lr: 1.045e-05, eta: 5:29:08, time: 1.489, data_time: 0.008, memory: 27148, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.0509, s0.loss_cls: 0.1761, s0.acc: 94.1113, s0.loss_bbox: 0.0864, s1.loss_cls: 0.0810, s1.acc: 94.6142, s1.loss_bbox: 0.0848, s2.loss_cls: 0.0408, s2.acc: 94.5861, s2.loss_bbox: 0.0538, loss: 0.5981
2022-04-06 01:58:09,619 - mmdet - INFO - Epoch [13][200/2442]	lr: 1.045e-05, eta: 5:26:40, time: 1.489, data_time: 0.008, memory: 27148, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0435, s0.loss_cls: 0.1605, s0.acc: 94.5488, s0.loss_bbox: 0.0863, s1.loss_cls: 0.0733, s1.acc: 95.0087, s1.loss_bbox: 0.0851, s2.loss_cls: 0.0367, s2.acc: 95.0086, s2.loss_bbox: 0.0502, loss: 0.5557
2022-04-06 01:59:24,009 - mmdet - INFO - Epoch [13][250/2442]	lr: 1.045e-05, eta: 5:24:38, time: 1.488, data_time: 0.007, memory: 27148, loss_rpn_cls: 0.0199, loss_rpn_bbox: 0.0474, s0.loss_cls: 0.1575, s0.acc: 94.5957, s0.loss_bbox: 0.0861, s1.loss_cls: 0.0722, s1.acc: 94.9595, s1.loss_bbox: 0.0867, s2.loss_cls: 0.0353, s2.acc: 95.0820, s2.loss_bbox: 0.0542, loss: 0.5593
2022-04-06 02:00:38,662 - mmdet - INFO - Epoch [13][300/2442]	lr: 1.045e-05, eta: 5:23:04, time: 1.493, data_time: 0.008, memory: 27148, loss_rpn_cls: 0.0165, loss_rpn_bbox: 0.0395, s0.loss_cls: 0.1548, s0.acc: 94.6504, s0.loss_bbox: 0.0872, s1.loss_cls: 0.0728, s1.acc: 95.2403, s1.loss_bbox: 0.0791, s2.loss_cls: 0.0341, s2.acc: 95.6411, s2.loss_bbox: 0.0451, loss: 0.5290
2022-04-06 02:01:53,603 - mmdet - INFO - Epoch [13][350/2442]	lr: 1.045e-05, eta: 5:21:45, time: 1.499, data_time: 0.008, memory: 27148, loss_rpn_cls: 0.0263, loss_rpn_bbox: 0.0474, s0.loss_cls: 0.1682, s0.acc: 94.1914, s0.loss_bbox: 0.0973, s1.loss_cls: 0.0724, s1.acc: 95.3120, s1.loss_bbox: 0.0928, s2.loss_cls: 0.0341, s2.acc: 95.3093, s2.loss_bbox: 0.0574, loss: 0.5959
2022-04-06 02:03:08,762 - mmdet - INFO - Epoch [13][400/2442]	lr: 1.045e-05, eta: 5:20:35, time: 1.503, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0340, loss_rpn_bbox: 0.0543, s0.loss_cls: 0.1721, s0.acc: 94.0195, s0.loss_bbox: 0.1096, s1.loss_cls: 0.0768, s1.acc: 94.6598, s1.loss_bbox: 0.0959, s2.loss_cls: 0.0371, s2.acc: 94.4102, s2.loss_bbox: 0.0602, loss: 0.6401
2022-04-06 02:04:23,564 - mmdet - INFO - Epoch [13][450/2442]	lr: 1.045e-05, eta: 5:19:13, time: 1.496, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0230, loss_rpn_bbox: 0.0503, s0.loss_cls: 0.1655, s0.acc: 94.1875, s0.loss_bbox: 0.0888, s1.loss_cls: 0.0745, s1.acc: 94.9572, s1.loss_bbox: 0.0854, s2.loss_cls: 0.0355, s2.acc: 95.2340, s2.loss_bbox: 0.0554, loss: 0.5785
2022-04-06 02:05:38,543 - mmdet - INFO - Epoch [13][500/2442]	lr: 1.045e-05, eta: 5:17:58, time: 1.500, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0181, loss_rpn_bbox: 0.0442, s0.loss_cls: 0.1838, s0.acc: 94.0586, s0.loss_bbox: 0.0949, s1.loss_cls: 0.0822, s1.acc: 94.9417, s1.loss_bbox: 0.0938, s2.loss_cls: 0.0388, s2.acc: 94.8416, s2.loss_bbox: 0.0612, loss: 0.6169
2022-04-06 02:06:53,480 - mmdet - INFO - Epoch [13][550/2442]	lr: 1.045e-05, eta: 5:16:41, time: 1.499, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.0364, s0.loss_cls: 0.1681, s0.acc: 94.7676, s0.loss_bbox: 0.0779, s1.loss_cls: 0.0749, s1.acc: 95.6460, s1.loss_bbox: 0.0714, s2.loss_cls: 0.0357, s2.acc: 95.8549, s2.loss_bbox: 0.0469, loss: 0.5306
2022-04-06 02:08:08,473 - mmdet - INFO - Epoch [13][600/2442]	lr: 1.045e-05, eta: 5:15:26, time: 1.500, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0384, s0.loss_cls: 0.1542, s0.acc: 94.5957, s0.loss_bbox: 0.0793, s1.loss_cls: 0.0672, s1.acc: 95.5055, s1.loss_bbox: 0.0822, s2.loss_cls: 0.0315, s2.acc: 95.6248, s2.loss_bbox: 0.0536, loss: 0.5243
2022-04-06 02:09:23,981 - mmdet - INFO - Epoch [13][650/2442]	lr: 1.045e-05, eta: 5:14:21, time: 1.510, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0206, loss_rpn_bbox: 0.0384, s0.loss_cls: 0.1499, s0.acc: 94.9844, s0.loss_bbox: 0.0773, s1.loss_cls: 0.0650, s1.acc: 95.8481, s1.loss_bbox: 0.0799, s2.loss_cls: 0.0322, s2.acc: 95.6079, s2.loss_bbox: 0.0516, loss: 0.5147
2022-04-06 02:10:38,713 - mmdet - INFO - Epoch [13][700/2442]	lr: 1.045e-05, eta: 5:13:00, time: 1.495, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.0521, s0.loss_cls: 0.1856, s0.acc: 93.7676, s0.loss_bbox: 0.0910, s1.loss_cls: 0.0810, s1.acc: 94.7071, s1.loss_bbox: 0.0846, s2.loss_cls: 0.0390, s2.acc: 94.9870, s2.loss_bbox: 0.0543, loss: 0.6130
2022-04-06 02:11:53,554 - mmdet - INFO - Epoch [13][750/2442]	lr: 1.045e-05, eta: 5:11:42, time: 1.497, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.0557, s0.loss_cls: 0.1840, s0.acc: 94.0137, s0.loss_bbox: 0.0962, s1.loss_cls: 0.0823, s1.acc: 94.6372, s1.loss_bbox: 0.0865, s2.loss_cls: 0.0409, s2.acc: 94.7057, s2.loss_bbox: 0.0514, loss: 0.6205
2022-04-06 02:13:08,411 - mmdet - INFO - Epoch [13][800/2442]	lr: 1.045e-05, eta: 5:10:25, time: 1.497, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0338, loss_rpn_bbox: 0.0443, s0.loss_cls: 0.1901, s0.acc: 93.9570, s0.loss_bbox: 0.0857, s1.loss_cls: 0.0923, s1.acc: 94.2147, s1.loss_bbox: 0.0803, s2.loss_cls: 0.0452, s2.acc: 94.3454, s2.loss_bbox: 0.0511, loss: 0.6229
2022-04-06 02:14:22,877 - mmdet - INFO - Epoch [13][850/2442]	lr: 1.045e-05, eta: 5:09:02, time: 1.489, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0409, s0.loss_cls: 0.1470, s0.acc: 94.9668, s0.loss_bbox: 0.0785, s1.loss_cls: 0.0661, s1.acc: 95.6707, s1.loss_bbox: 0.0729, s2.loss_cls: 0.0296, s2.acc: 96.0626, s2.loss_bbox: 0.0453, loss: 0.4980
2022-04-06 02:15:37,485 - mmdet - INFO - Epoch [13][900/2442]	lr: 1.045e-05, eta: 5:07:42, time: 1.492, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0148, loss_rpn_bbox: 0.0436, s0.loss_cls: 0.1453, s0.acc: 95.0469, s0.loss_bbox: 0.0714, s1.loss_cls: 0.0644, s1.acc: 95.9531, s1.loss_bbox: 0.0699, s2.loss_cls: 0.0304, s2.acc: 96.0406, s2.loss_bbox: 0.0469, loss: 0.4866
2022-04-06 02:16:52,032 - mmdet - INFO - Epoch [13][950/2442]	lr: 1.045e-05, eta: 5:06:22, time: 1.491, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0166, loss_rpn_bbox: 0.0460, s0.loss_cls: 0.1629, s0.acc: 94.3730, s0.loss_bbox: 0.0867, s1.loss_cls: 0.0692, s1.acc: 95.3592, s1.loss_bbox: 0.0830, s2.loss_cls: 0.0342, s2.acc: 95.1963, s2.loss_bbox: 0.0532, loss: 0.5517
2022-04-06 02:18:06,665 - mmdet - INFO - Epoch [13][1000/2442]	lr: 1.045e-05, eta: 5:05:04, time: 1.493, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0179, loss_rpn_bbox: 0.0485, s0.loss_cls: 0.1881, s0.acc: 93.6230, s0.loss_bbox: 0.0979, s1.loss_cls: 0.0857, s1.acc: 94.4311, s1.loss_bbox: 0.0970, s2.loss_cls: 0.0420, s2.acc: 94.2842, s2.loss_bbox: 0.0620, loss: 0.6390
2022-04-06 02:19:21,109 - mmdet - INFO - Epoch [13][1050/2442]	lr: 1.045e-05, eta: 5:03:44, time: 1.489, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0193, loss_rpn_bbox: 0.0452, s0.loss_cls: 0.1632, s0.acc: 94.3848, s0.loss_bbox: 0.0831, s1.loss_cls: 0.0754, s1.acc: 94.8499, s1.loss_bbox: 0.0803, s2.loss_cls: 0.0376, s2.acc: 94.8754, s2.loss_bbox: 0.0541, loss: 0.5583
2022-04-06 02:20:35,589 - mmdet - INFO - Epoch [13][1100/2442]	lr: 1.045e-05, eta: 5:02:24, time: 1.490, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0505, s0.loss_cls: 0.1887, s0.acc: 93.6621, s0.loss_bbox: 0.0934, s1.loss_cls: 0.0899, s1.acc: 94.3522, s1.loss_bbox: 0.0876, s2.loss_cls: 0.0448, s2.acc: 94.4423, s2.loss_bbox: 0.0513, loss: 0.6241
2022-04-06 02:21:49,597 - mmdet - INFO - Epoch [13][1150/2442]	lr: 1.045e-05, eta: 5:01:00, time: 1.480, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0160, loss_rpn_bbox: 0.0491, s0.loss_cls: 0.1721, s0.acc: 94.2031, s0.loss_bbox: 0.0945, s1.loss_cls: 0.0842, s1.acc: 94.6419, s1.loss_bbox: 0.0899, s2.loss_cls: 0.0432, s2.acc: 94.6926, s2.loss_bbox: 0.0524, loss: 0.6013
2022-04-06 02:23:04,013 - mmdet - INFO - Epoch [13][1200/2442]	lr: 1.045e-05, eta: 4:59:41, time: 1.488, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0217, loss_rpn_bbox: 0.0442, s0.loss_cls: 0.1685, s0.acc: 94.2090, s0.loss_bbox: 0.0999, s1.loss_cls: 0.0766, s1.acc: 94.9456, s1.loss_bbox: 0.0928, s2.loss_cls: 0.0359, s2.acc: 95.1603, s2.loss_bbox: 0.0557, loss: 0.5955
2022-04-06 02:24:17,717 - mmdet - INFO - Epoch [13][1250/2442]	lr: 1.045e-05, eta: 4:58:16, time: 1.474, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0199, loss_rpn_bbox: 0.0530, s0.loss_cls: 0.1983, s0.acc: 92.9297, s0.loss_bbox: 0.1106, s1.loss_cls: 0.0906, s1.acc: 93.5781, s1.loss_bbox: 0.1146, s2.loss_cls: 0.0459, s2.acc: 93.4029, s2.loss_bbox: 0.0686, loss: 0.7017
2022-04-06 02:25:32,140 - mmdet - INFO - Epoch [13][1300/2442]	lr: 1.045e-05, eta: 4:56:58, time: 1.488, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0270, loss_rpn_bbox: 0.0514, s0.loss_cls: 0.1703, s0.acc: 94.1777, s0.loss_bbox: 0.0931, s1.loss_cls: 0.0750, s1.acc: 95.1058, s1.loss_bbox: 0.0926, s2.loss_cls: 0.0364, s2.acc: 95.3143, s2.loss_bbox: 0.0598, loss: 0.6056
2022-04-06 02:26:46,897 - mmdet - INFO - Epoch [13][1350/2442]	lr: 1.045e-05, eta: 4:55:43, time: 1.495, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0227, loss_rpn_bbox: 0.0531, s0.loss_cls: 0.1848, s0.acc: 93.7969, s0.loss_bbox: 0.0986, s1.loss_cls: 0.0876, s1.acc: 94.2239, s1.loss_bbox: 0.0957, s2.loss_cls: 0.0437, s2.acc: 94.3316, s2.loss_bbox: 0.0567, loss: 0.6428
2022-04-06 02:28:01,515 - mmdet - INFO - Epoch [13][1400/2442]	lr: 1.045e-05, eta: 4:54:27, time: 1.492, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0311, loss_rpn_bbox: 0.0486, s0.loss_cls: 0.1876, s0.acc: 93.6270, s0.loss_bbox: 0.0995, s1.loss_cls: 0.0896, s1.acc: 93.8693, s1.loss_bbox: 0.1008, s2.loss_cls: 0.0456, s2.acc: 93.6184, s2.loss_bbox: 0.0612, loss: 0.6639
2022-04-06 02:29:16,116 - mmdet - INFO - Epoch [13][1450/2442]	lr: 1.045e-05, eta: 4:53:11, time: 1.492, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0197, loss_rpn_bbox: 0.0438, s0.loss_cls: 0.1554, s0.acc: 94.6816, s0.loss_bbox: 0.0821, s1.loss_cls: 0.0665, s1.acc: 95.5184, s1.loss_bbox: 0.0766, s2.loss_cls: 0.0320, s2.acc: 95.5780, s2.loss_bbox: 0.0513, loss: 0.5274
2022-04-06 02:30:31,356 - mmdet - INFO - Epoch [13][1500/2442]	lr: 1.045e-05, eta: 4:52:01, time: 1.505, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0187, loss_rpn_bbox: 0.0489, s0.loss_cls: 0.1759, s0.acc: 93.9473, s0.loss_bbox: 0.1042, s1.loss_cls: 0.0783, s1.acc: 94.5446, s1.loss_bbox: 0.0933, s2.loss_cls: 0.0376, s2.acc: 94.7477, s2.loss_bbox: 0.0559, loss: 0.6130
2022-04-06 02:31:47,571 - mmdet - INFO - Epoch [13][1550/2442]	lr: 1.045e-05, eta: 4:50:57, time: 1.524, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0471, s0.loss_cls: 0.1578, s0.acc: 94.9336, s0.loss_bbox: 0.0825, s1.loss_cls: 0.0693, s1.acc: 95.8682, s1.loss_bbox: 0.0786, s2.loss_cls: 0.0359, s2.acc: 95.3956, s2.loss_bbox: 0.0528, loss: 0.5401
2022-04-06 02:33:02,334 - mmdet - INFO - Epoch [13][1600/2442]	lr: 1.045e-05, eta: 4:49:42, time: 1.495, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0462, s0.loss_cls: 0.1696, s0.acc: 94.0918, s0.loss_bbox: 0.0806, s1.loss_cls: 0.0789, s1.acc: 94.4715, s1.loss_bbox: 0.0717, s2.loss_cls: 0.0394, s2.acc: 94.4074, s2.loss_bbox: 0.0450, loss: 0.5480
2022-04-06 02:34:17,128 - mmdet - INFO - Epoch [13][1650/2442]	lr: 1.045e-05, eta: 4:48:27, time: 1.496, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.0420, s0.loss_cls: 0.1705, s0.acc: 94.4199, s0.loss_bbox: 0.0939, s1.loss_cls: 0.0739, s1.acc: 95.3986, s1.loss_bbox: 0.0910, s2.loss_cls: 0.0354, s2.acc: 95.5392, s2.loss_bbox: 0.0581, loss: 0.5818
2022-04-06 02:35:32,196 - mmdet - INFO - Epoch [13][1700/2442]	lr: 1.045e-05, eta: 4:47:14, time: 1.501, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0166, loss_rpn_bbox: 0.0427, s0.loss_cls: 0.1512, s0.acc: 94.7637, s0.loss_bbox: 0.0858, s1.loss_cls: 0.0647, s1.acc: 95.6995, s1.loss_bbox: 0.0844, s2.loss_cls: 0.0304, s2.acc: 95.7288, s2.loss_bbox: 0.0528, loss: 0.5286
2022-04-06 02:36:47,149 - mmdet - INFO - Epoch [13][1750/2442]	lr: 1.045e-05, eta: 4:46:00, time: 1.499, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0208, loss_rpn_bbox: 0.0520, s0.loss_cls: 0.1767, s0.acc: 94.0117, s0.loss_bbox: 0.0941, s1.loss_cls: 0.0814, s1.acc: 94.4341, s1.loss_bbox: 0.0960, s2.loss_cls: 0.0395, s2.acc: 94.8768, s2.loss_bbox: 0.0608, loss: 0.6213
2022-04-06 02:38:01,779 - mmdet - INFO - Epoch [13][1800/2442]	lr: 1.045e-05, eta: 4:44:44, time: 1.493, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0219, loss_rpn_bbox: 0.0443, s0.loss_cls: 0.1403, s0.acc: 95.1230, s0.loss_bbox: 0.0824, s1.loss_cls: 0.0596, s1.acc: 95.9119, s1.loss_bbox: 0.0863, s2.loss_cls: 0.0281, s2.acc: 96.2969, s2.loss_bbox: 0.0516, loss: 0.5144
2022-04-06 02:39:16,842 - mmdet - INFO - Epoch [13][1850/2442]	lr: 1.045e-05, eta: 4:43:30, time: 1.501, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.0468, s0.loss_cls: 0.1650, s0.acc: 94.4355, s0.loss_bbox: 0.0782, s1.loss_cls: 0.0734, s1.acc: 95.1991, s1.loss_bbox: 0.0818, s2.loss_cls: 0.0352, s2.acc: 95.3743, s2.loss_bbox: 0.0558, loss: 0.5616
2022-04-06 02:40:31,497 - mmdet - INFO - Epoch [13][1900/2442]	lr: 1.045e-05, eta: 4:42:15, time: 1.493, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0273, loss_rpn_bbox: 0.0566, s0.loss_cls: 0.1921, s0.acc: 94.0547, s0.loss_bbox: 0.0966, s1.loss_cls: 0.0847, s1.acc: 95.0895, s1.loss_bbox: 0.0888, s2.loss_cls: 0.0409, s2.acc: 95.1522, s2.loss_bbox: 0.0565, loss: 0.6435
2022-04-06 02:41:46,190 - mmdet - INFO - Epoch [13][1950/2442]	lr: 1.045e-05, eta: 4:40:59, time: 1.494, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0199, loss_rpn_bbox: 0.0434, s0.loss_cls: 0.1426, s0.acc: 95.1660, s0.loss_bbox: 0.0740, s1.loss_cls: 0.0612, s1.acc: 96.0101, s1.loss_bbox: 0.0682, s2.loss_cls: 0.0285, s2.acc: 96.4421, s2.loss_bbox: 0.0438, loss: 0.4818
2022-04-06 02:43:00,941 - mmdet - INFO - Epoch [13][2000/2442]	lr: 1.045e-05, eta: 4:39:44, time: 1.495, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0235, loss_rpn_bbox: 0.0342, s0.loss_cls: 0.1415, s0.acc: 95.2090, s0.loss_bbox: 0.0718, s1.loss_cls: 0.0630, s1.acc: 96.0683, s1.loss_bbox: 0.0672, s2.loss_cls: 0.0311, s2.acc: 95.9555, s2.loss_bbox: 0.0442, loss: 0.4764
2022-04-06 02:44:15,821 - mmdet - INFO - Epoch [13][2050/2442]	lr: 1.045e-05, eta: 4:38:30, time: 1.498, data_time: 0.008, memory: 27544, loss_rpn_cls: 0.0203, loss_rpn_bbox: 0.0493, s0.loss_cls: 0.1845, s0.acc: 93.5332, s0.loss_bbox: 0.1048, s1.loss_cls: 0.0854, s1.acc: 94.1782, s1.loss_bbox: 0.0999, s2.loss_cls: 0.0436, s2.acc: 94.3307, s2.loss_bbox: 0.0599, loss: 0.6477
2022-04-06 02:45:30,766 - mmdet - INFO - Epoch [13][2100/2442]	lr: 1.045e-05, eta: 4:37:15, time: 1.499, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0512, s0.loss_cls: 0.2006, s0.acc: 93.1523, s0.loss_bbox: 0.1067, s1.loss_cls: 0.0938, s1.acc: 93.8152, s1.loss_bbox: 0.1018, s2.loss_cls: 0.0477, s2.acc: 93.8866, s2.loss_bbox: 0.0622, loss: 0.6842
2022-04-06 02:46:45,546 - mmdet - INFO - Epoch [13][2150/2442]	lr: 1.045e-05, eta: 4:36:00, time: 1.496, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0182, loss_rpn_bbox: 0.0403, s0.loss_cls: 0.1375, s0.acc: 94.9004, s0.loss_bbox: 0.0694, s1.loss_cls: 0.0608, s1.acc: 95.6260, s1.loss_bbox: 0.0661, s2.loss_cls: 0.0295, s2.acc: 95.7407, s2.loss_bbox: 0.0428, loss: 0.4645
2022-04-06 02:48:00,078 - mmdet - INFO - Epoch [13][2200/2442]	lr: 1.045e-05, eta: 4:34:44, time: 1.491, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0223, loss_rpn_bbox: 0.0414, s0.loss_cls: 0.1653, s0.acc: 94.5039, s0.loss_bbox: 0.0815, s1.loss_cls: 0.0707, s1.acc: 95.2873, s1.loss_bbox: 0.0838, s2.loss_cls: 0.0353, s2.acc: 95.5036, s2.loss_bbox: 0.0556, loss: 0.5559
2022-04-06 02:49:15,115 - mmdet - INFO - Epoch [13][2250/2442]	lr: 1.045e-05, eta: 4:33:30, time: 1.501, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.0381, s0.loss_cls: 0.1638, s0.acc: 94.5996, s0.loss_bbox: 0.0802, s1.loss_cls: 0.0806, s1.acc: 94.9451, s1.loss_bbox: 0.0741, s2.loss_cls: 0.0410, s2.acc: 94.8217, s2.loss_bbox: 0.0452, loss: 0.5405
2022-04-06 02:50:30,384 - mmdet - INFO - Epoch [13][2300/2442]	lr: 1.045e-05, eta: 4:32:18, time: 1.505, data_time: 0.007, memory: 27544, loss_rpn_cls: 0.0176, loss_rpn_bbox: 0.0472, s0.loss_cls: 0.1599, s0.acc: 94.5449, s0.loss_bbox: 0.0913, s1.loss_cls: 0.0676, s1.acc: 95.4037, s1.loss_bbox: 0.0933, s2.loss_cls: 0.0346, s2.acc: 95.2669, s2.loss_bbox: 0.0591, loss: 0.5707
2022-04-06 02:51:45,522 - mmdet - INFO - Epoch [13][2350/2442]	lr: 1.045e-05, eta: 4:31:04, time: 1.503, data_time: 0.007, memory: 28072, loss_rpn_cls: 0.0225, loss_rpn_bbox: 0.0516, s0.loss_cls: 0.1895, s0.acc: 93.6309, s0.loss_bbox: 0.1015, s1.loss_cls: 0.0912, s1.acc: 93.9708, s1.loss_bbox: 0.1035, s2.loss_cls: 0.0477, s2.acc: 93.7051, s2.loss_bbox: 0.0563, loss: 0.6638
2022-04-06 02:53:00,408 - mmdet - INFO - Epoch [13][2400/2442]	lr: 1.045e-05, eta: 4:29:50, time: 1.498, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0308, loss_rpn_bbox: 0.0506, s0.loss_cls: 0.1699, s0.acc: 94.1172, s0.loss_bbox: 0.0949, s1.loss_cls: 0.0749, s1.acc: 94.8947, s1.loss_bbox: 0.0961, s2.loss_cls: 0.0363, s2.acc: 95.0222, s2.loss_bbox: 0.0598, loss: 0.6131
2022-04-06 02:54:03,494 - mmdet - INFO - Saving checkpoint at 13 epochs
2022-04-06 02:58:12,876 - mmdet - INFO - Evaluating bbox...
2022-04-06 02:58:15,897 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.699
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.584
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.023
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.182
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.045
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.319
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.690

2022-04-06 02:58:15,898 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.350 | Paper       | 0.391 | Paper pack | 0.615 |
| Metal         | 0.579 | Glass       | 0.490 | Plastic    | 0.504 |
| Styrofoam     | 0.486 | Plastic bag | 0.627 | Battery    | 0.864 |
| Clothing      | 0.566 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-06 02:58:15,936 - mmdet - INFO - Exp name: cascade_rcnn_swin_large.py
2022-04-06 02:58:15,936 - mmdet - INFO - Epoch(val) [13][982]	bbox_mAP: 0.5470, bbox_mAP_50: 0.6990, bbox_mAP_75: 0.5840, bbox_mAP_s: 0.0230, bbox_mAP_m: 0.1820, bbox_mAP_l: 0.6220, bbox_mAP_copypaste: 0.547 0.699 0.584 0.023 0.182 0.622
2022-04-06 02:59:33,517 - mmdet - INFO - Epoch [14][50/2442]	lr: 5.279e-06, eta: 4:23:13, time: 1.551, data_time: 0.056, memory: 28072, loss_rpn_cls: 0.0194, loss_rpn_bbox: 0.0440, s0.loss_cls: 0.1429, s0.acc: 95.0195, s0.loss_bbox: 0.0832, s1.loss_cls: 0.0620, s1.acc: 95.7461, s1.loss_bbox: 0.0822, s2.loss_cls: 0.0300, s2.acc: 96.0527, s2.loss_bbox: 0.0533, loss: 0.5170
2022-04-06 03:00:48,613 - mmdet - INFO - Epoch [14][100/2442]	lr: 5.279e-06, eta: 4:22:06, time: 1.502, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0246, loss_rpn_bbox: 0.0366, s0.loss_cls: 0.1320, s0.acc: 95.2129, s0.loss_bbox: 0.0706, s1.loss_cls: 0.0559, s1.acc: 96.0652, s1.loss_bbox: 0.0717, s2.loss_cls: 0.0272, s2.acc: 96.1889, s2.loss_bbox: 0.0519, loss: 0.4705
2022-04-06 03:02:03,561 - mmdet - INFO - Epoch [14][150/2442]	lr: 5.279e-06, eta: 4:20:58, time: 1.499, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0187, loss_rpn_bbox: 0.0380, s0.loss_cls: 0.1398, s0.acc: 95.1621, s0.loss_bbox: 0.0698, s1.loss_cls: 0.0629, s1.acc: 95.7318, s1.loss_bbox: 0.0709, s2.loss_cls: 0.0324, s2.acc: 95.7310, s2.loss_bbox: 0.0436, loss: 0.4762
2022-04-06 03:03:18,377 - mmdet - INFO - Epoch [14][200/2442]	lr: 5.279e-06, eta: 4:19:48, time: 1.496, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0166, loss_rpn_bbox: 0.0394, s0.loss_cls: 0.1565, s0.acc: 94.8027, s0.loss_bbox: 0.0851, s1.loss_cls: 0.0740, s1.acc: 94.9736, s1.loss_bbox: 0.0823, s2.loss_cls: 0.0361, s2.acc: 94.9259, s2.loss_bbox: 0.0513, loss: 0.5413
2022-04-06 03:04:32,810 - mmdet - INFO - Epoch [14][250/2442]	lr: 5.279e-06, eta: 4:18:38, time: 1.489, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0270, loss_rpn_bbox: 0.0460, s0.loss_cls: 0.1595, s0.acc: 94.3516, s0.loss_bbox: 0.0949, s1.loss_cls: 0.0702, s1.acc: 95.2332, s1.loss_bbox: 0.0953, s2.loss_cls: 0.0349, s2.acc: 95.1486, s2.loss_bbox: 0.0597, loss: 0.5874
2022-04-06 03:05:47,650 - mmdet - INFO - Epoch [14][300/2442]	lr: 5.279e-06, eta: 4:17:28, time: 1.497, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0216, loss_rpn_bbox: 0.0543, s0.loss_cls: 0.1995, s0.acc: 93.1094, s0.loss_bbox: 0.1032, s1.loss_cls: 0.0889, s1.acc: 93.9010, s1.loss_bbox: 0.0984, s2.loss_cls: 0.0413, s2.acc: 94.2639, s2.loss_bbox: 0.0584, loss: 0.6656
2022-04-06 03:07:02,510 - mmdet - INFO - Epoch [14][350/2442]	lr: 5.279e-06, eta: 4:16:19, time: 1.497, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0147, loss_rpn_bbox: 0.0420, s0.loss_cls: 0.1623, s0.acc: 94.6270, s0.loss_bbox: 0.0836, s1.loss_cls: 0.0734, s1.acc: 95.1174, s1.loss_bbox: 0.0827, s2.loss_cls: 0.0355, s2.acc: 95.7655, s2.loss_bbox: 0.0513, loss: 0.5454
2022-04-06 03:08:17,967 - mmdet - INFO - Epoch [14][400/2442]	lr: 5.279e-06, eta: 4:15:11, time: 1.509, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0274, loss_rpn_bbox: 0.0541, s0.loss_cls: 0.1879, s0.acc: 93.8613, s0.loss_bbox: 0.0886, s1.loss_cls: 0.0835, s1.acc: 94.6421, s1.loss_bbox: 0.0793, s2.loss_cls: 0.0395, s2.acc: 95.0153, s2.loss_bbox: 0.0501, loss: 0.6104
2022-04-06 03:09:32,694 - mmdet - INFO - Epoch [14][450/2442]	lr: 5.279e-06, eta: 4:14:01, time: 1.494, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0265, loss_rpn_bbox: 0.0493, s0.loss_cls: 0.1563, s0.acc: 94.3848, s0.loss_bbox: 0.0891, s1.loss_cls: 0.0670, s1.acc: 95.4501, s1.loss_bbox: 0.0860, s2.loss_cls: 0.0324, s2.acc: 95.5961, s2.loss_bbox: 0.0564, loss: 0.5630
2022-04-06 03:10:47,544 - mmdet - INFO - Epoch [14][500/2442]	lr: 5.279e-06, eta: 4:12:51, time: 1.497, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0195, loss_rpn_bbox: 0.0485, s0.loss_cls: 0.1634, s0.acc: 94.3809, s0.loss_bbox: 0.0868, s1.loss_cls: 0.0685, s1.acc: 95.3281, s1.loss_bbox: 0.0869, s2.loss_cls: 0.0329, s2.acc: 95.3871, s2.loss_bbox: 0.0604, loss: 0.5669
2022-04-06 03:12:02,587 - mmdet - INFO - Epoch [14][550/2442]	lr: 5.279e-06, eta: 4:11:41, time: 1.501, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0133, loss_rpn_bbox: 0.0393, s0.loss_cls: 0.1219, s0.acc: 95.6289, s0.loss_bbox: 0.0682, s1.loss_cls: 0.0518, s1.acc: 96.3969, s1.loss_bbox: 0.0648, s2.loss_cls: 0.0236, s2.acc: 96.5112, s2.loss_bbox: 0.0399, loss: 0.4228
2022-04-06 03:13:17,304 - mmdet - INFO - Epoch [14][600/2442]	lr: 5.279e-06, eta: 4:10:30, time: 1.494, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0176, loss_rpn_bbox: 0.0498, s0.loss_cls: 0.1541, s0.acc: 94.8262, s0.loss_bbox: 0.0772, s1.loss_cls: 0.0689, s1.acc: 95.6941, s1.loss_bbox: 0.0746, s2.loss_cls: 0.0359, s2.acc: 95.5293, s2.loss_bbox: 0.0483, loss: 0.5263
2022-04-06 03:14:31,896 - mmdet - INFO - Epoch [14][650/2442]	lr: 5.279e-06, eta: 4:09:19, time: 1.492, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0147, loss_rpn_bbox: 0.0407, s0.loss_cls: 0.1558, s0.acc: 94.6621, s0.loss_bbox: 0.0780, s1.loss_cls: 0.0705, s1.acc: 95.3142, s1.loss_bbox: 0.0820, s2.loss_cls: 0.0352, s2.acc: 95.4640, s2.loss_bbox: 0.0556, loss: 0.5324
2022-04-06 03:15:47,055 - mmdet - INFO - Epoch [14][700/2442]	lr: 5.279e-06, eta: 4:08:09, time: 1.503, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0209, loss_rpn_bbox: 0.0444, s0.loss_cls: 0.1630, s0.acc: 94.1973, s0.loss_bbox: 0.0873, s1.loss_cls: 0.0715, s1.acc: 94.8121, s1.loss_bbox: 0.0856, s2.loss_cls: 0.0372, s2.acc: 94.6050, s2.loss_bbox: 0.0490, loss: 0.5589
2022-04-06 03:17:02,141 - mmdet - INFO - Epoch [14][750/2442]	lr: 5.279e-06, eta: 4:06:59, time: 1.502, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0172, loss_rpn_bbox: 0.0430, s0.loss_cls: 0.1469, s0.acc: 95.0293, s0.loss_bbox: 0.0782, s1.loss_cls: 0.0654, s1.acc: 95.8033, s1.loss_bbox: 0.0777, s2.loss_cls: 0.0316, s2.acc: 95.7831, s2.loss_bbox: 0.0504, loss: 0.5103
2022-04-06 03:18:16,803 - mmdet - INFO - Epoch [14][800/2442]	lr: 5.279e-06, eta: 4:05:47, time: 1.493, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0181, loss_rpn_bbox: 0.0471, s0.loss_cls: 0.1499, s0.acc: 94.5684, s0.loss_bbox: 0.0873, s1.loss_cls: 0.0653, s1.acc: 95.1668, s1.loss_bbox: 0.0849, s2.loss_cls: 0.0312, s2.acc: 95.4596, s2.loss_bbox: 0.0545, loss: 0.5381
2022-04-06 03:19:31,173 - mmdet - INFO - Epoch [14][850/2442]	lr: 5.279e-06, eta: 4:04:35, time: 1.487, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0176, loss_rpn_bbox: 0.0461, s0.loss_cls: 0.1787, s0.acc: 93.6582, s0.loss_bbox: 0.0956, s1.loss_cls: 0.0801, s1.acc: 94.3427, s1.loss_bbox: 0.0910, s2.loss_cls: 0.0386, s2.acc: 94.3206, s2.loss_bbox: 0.0534, loss: 0.6009
2022-04-06 03:20:45,964 - mmdet - INFO - Epoch [14][900/2442]	lr: 5.279e-06, eta: 4:03:23, time: 1.496, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.0493, s0.loss_cls: 0.1902, s0.acc: 93.4746, s0.loss_bbox: 0.0979, s1.loss_cls: 0.0872, s1.acc: 93.9608, s1.loss_bbox: 0.0939, s2.loss_cls: 0.0424, s2.acc: 93.9001, s2.loss_bbox: 0.0577, loss: 0.6372
2022-04-06 03:22:01,008 - mmdet - INFO - Epoch [14][950/2442]	lr: 5.279e-06, eta: 4:02:13, time: 1.501, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0433, s0.loss_cls: 0.1457, s0.acc: 94.8770, s0.loss_bbox: 0.0776, s1.loss_cls: 0.0646, s1.acc: 95.6034, s1.loss_bbox: 0.0767, s2.loss_cls: 0.0322, s2.acc: 95.5328, s2.loss_bbox: 0.0489, loss: 0.5051
2022-04-06 03:23:15,757 - mmdet - INFO - Epoch [14][1000/2442]	lr: 5.279e-06, eta: 4:01:01, time: 1.495, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0150, loss_rpn_bbox: 0.0392, s0.loss_cls: 0.1435, s0.acc: 95.3223, s0.loss_bbox: 0.0737, s1.loss_cls: 0.0652, s1.acc: 95.7109, s1.loss_bbox: 0.0807, s2.loss_cls: 0.0291, s2.acc: 95.9917, s2.loss_bbox: 0.0507, loss: 0.4970
2022-04-06 03:24:30,596 - mmdet - INFO - Epoch [14][1050/2442]	lr: 5.279e-06, eta: 3:59:49, time: 1.497, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0447, s0.loss_cls: 0.1512, s0.acc: 94.8516, s0.loss_bbox: 0.0849, s1.loss_cls: 0.0617, s1.acc: 95.8314, s1.loss_bbox: 0.0762, s2.loss_cls: 0.0291, s2.acc: 96.0236, s2.loss_bbox: 0.0478, loss: 0.5124
2022-04-06 03:25:45,037 - mmdet - INFO - Epoch [14][1100/2442]	lr: 5.279e-06, eta: 3:58:37, time: 1.489, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0276, loss_rpn_bbox: 0.0519, s0.loss_cls: 0.1589, s0.acc: 94.3770, s0.loss_bbox: 0.0887, s1.loss_cls: 0.0743, s1.acc: 94.8755, s1.loss_bbox: 0.0863, s2.loss_cls: 0.0352, s2.acc: 95.3037, s2.loss_bbox: 0.0529, loss: 0.5759
2022-04-06 03:26:59,416 - mmdet - INFO - Epoch [14][1150/2442]	lr: 5.279e-06, eta: 3:57:24, time: 1.488, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0420, s0.loss_cls: 0.1595, s0.acc: 94.1426, s0.loss_bbox: 0.0854, s1.loss_cls: 0.0708, s1.acc: 94.6239, s1.loss_bbox: 0.0895, s2.loss_cls: 0.0348, s2.acc: 94.7653, s2.loss_bbox: 0.0528, loss: 0.5527
2022-04-06 03:28:14,206 - mmdet - INFO - Epoch [14][1200/2442]	lr: 5.279e-06, eta: 3:56:12, time: 1.496, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0146, loss_rpn_bbox: 0.0404, s0.loss_cls: 0.1429, s0.acc: 94.8711, s0.loss_bbox: 0.0747, s1.loss_cls: 0.0654, s1.acc: 95.2946, s1.loss_bbox: 0.0746, s2.loss_cls: 0.0305, s2.acc: 95.7961, s2.loss_bbox: 0.0479, loss: 0.4910
2022-04-06 03:29:29,244 - mmdet - INFO - Epoch [14][1250/2442]	lr: 5.279e-06, eta: 3:55:00, time: 1.501, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.0393, s0.loss_cls: 0.1569, s0.acc: 94.5625, s0.loss_bbox: 0.0826, s1.loss_cls: 0.0704, s1.acc: 94.8811, s1.loss_bbox: 0.0820, s2.loss_cls: 0.0342, s2.acc: 95.2880, s2.loss_bbox: 0.0553, loss: 0.5377
2022-04-06 03:30:44,070 - mmdet - INFO - Epoch [14][1300/2442]	lr: 5.279e-06, eta: 3:53:49, time: 1.496, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.0568, s0.loss_cls: 0.1935, s0.acc: 93.3398, s0.loss_bbox: 0.1110, s1.loss_cls: 0.0874, s1.acc: 94.0037, s1.loss_bbox: 0.1015, s2.loss_cls: 0.0434, s2.acc: 94.1083, s2.loss_bbox: 0.0604, loss: 0.6710
2022-04-06 03:31:58,735 - mmdet - INFO - Epoch [14][1350/2442]	lr: 5.279e-06, eta: 3:52:36, time: 1.493, data_time: 0.008, memory: 28072, loss_rpn_cls: 0.0190, loss_rpn_bbox: 0.0472, s0.loss_cls: 0.1611, s0.acc: 94.1133, s0.loss_bbox: 0.0930, s1.loss_cls: 0.0706, s1.acc: 94.9748, s1.loss_bbox: 0.0920, s2.loss_cls: 0.0347, s2.acc: 94.9173, s2.loss_bbox: 0.0594, loss: 0.5770
2022-04-06 03:33:13,295 - mmdet - INFO - Epoch [14][1400/2442]	lr: 5.279e-06, eta: 3:51:23, time: 1.491, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0341, s0.loss_cls: 0.1533, s0.acc: 94.7012, s0.loss_bbox: 0.0790, s1.loss_cls: 0.0626, s1.acc: 95.7202, s1.loss_bbox: 0.0783, s2.loss_cls: 0.0291, s2.acc: 96.1000, s2.loss_bbox: 0.0531, loss: 0.5079
2022-04-06 03:34:27,658 - mmdet - INFO - Epoch [14][1450/2442]	lr: 5.279e-06, eta: 3:50:10, time: 1.487, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0446, s0.loss_cls: 0.1948, s0.acc: 93.7480, s0.loss_bbox: 0.0990, s1.loss_cls: 0.0862, s1.acc: 94.5079, s1.loss_bbox: 0.0893, s2.loss_cls: 0.0425, s2.acc: 94.5087, s2.loss_bbox: 0.0520, loss: 0.6260
2022-04-06 03:35:42,472 - mmdet - INFO - Epoch [14][1500/2442]	lr: 5.279e-06, eta: 3:48:58, time: 1.496, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0292, loss_rpn_bbox: 0.0597, s0.loss_cls: 0.1847, s0.acc: 93.5762, s0.loss_bbox: 0.1055, s1.loss_cls: 0.0816, s1.acc: 94.4517, s1.loss_bbox: 0.1051, s2.loss_cls: 0.0397, s2.acc: 94.3525, s2.loss_bbox: 0.0638, loss: 0.6693
2022-04-06 03:36:56,742 - mmdet - INFO - Epoch [14][1550/2442]	lr: 5.279e-06, eta: 3:47:44, time: 1.485, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0116, loss_rpn_bbox: 0.0348, s0.loss_cls: 0.1533, s0.acc: 94.7520, s0.loss_bbox: 0.0827, s1.loss_cls: 0.0698, s1.acc: 95.4743, s1.loss_bbox: 0.0795, s2.loss_cls: 0.0348, s2.acc: 95.2137, s2.loss_bbox: 0.0444, loss: 0.5110
2022-04-06 03:38:11,169 - mmdet - INFO - Epoch [14][1600/2442]	lr: 5.279e-06, eta: 3:46:31, time: 1.489, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0209, loss_rpn_bbox: 0.0426, s0.loss_cls: 0.1642, s0.acc: 94.2500, s0.loss_bbox: 0.0927, s1.loss_cls: 0.0712, s1.acc: 95.1001, s1.loss_bbox: 0.0867, s2.loss_cls: 0.0346, s2.acc: 95.0651, s2.loss_bbox: 0.0562, loss: 0.5690
2022-04-06 03:39:25,729 - mmdet - INFO - Epoch [14][1650/2442]	lr: 5.279e-06, eta: 3:45:18, time: 1.491, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0194, loss_rpn_bbox: 0.0350, s0.loss_cls: 0.1289, s0.acc: 95.4746, s0.loss_bbox: 0.0747, s1.loss_cls: 0.0584, s1.acc: 95.9157, s1.loss_bbox: 0.0757, s2.loss_cls: 0.0291, s2.acc: 96.0019, s2.loss_bbox: 0.0488, loss: 0.4700
2022-04-06 03:40:40,381 - mmdet - INFO - Epoch [14][1700/2442]	lr: 5.279e-06, eta: 3:44:05, time: 1.493, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0168, loss_rpn_bbox: 0.0347, s0.loss_cls: 0.1450, s0.acc: 95.1133, s0.loss_bbox: 0.0689, s1.loss_cls: 0.0624, s1.acc: 96.0303, s1.loss_bbox: 0.0742, s2.loss_cls: 0.0295, s2.acc: 96.2419, s2.loss_bbox: 0.0515, loss: 0.4829
2022-04-06 03:41:54,820 - mmdet - INFO - Epoch [14][1750/2442]	lr: 5.279e-06, eta: 3:42:52, time: 1.489, data_time: 0.007, memory: 28083, loss_rpn_cls: 0.0200, loss_rpn_bbox: 0.0379, s0.loss_cls: 0.1504, s0.acc: 94.7266, s0.loss_bbox: 0.0831, s1.loss_cls: 0.0704, s1.acc: 94.9690, s1.loss_bbox: 0.0851, s2.loss_cls: 0.0353, s2.acc: 95.1053, s2.loss_bbox: 0.0512, loss: 0.5334
2022-04-06 03:43:09,218 - mmdet - INFO - Epoch [14][1800/2442]	lr: 5.279e-06, eta: 3:41:39, time: 1.488, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0172, loss_rpn_bbox: 0.0390, s0.loss_cls: 0.1464, s0.acc: 94.7676, s0.loss_bbox: 0.0780, s1.loss_cls: 0.0638, s1.acc: 95.1956, s1.loss_bbox: 0.0748, s2.loss_cls: 0.0307, s2.acc: 95.3897, s2.loss_bbox: 0.0481, loss: 0.4980
2022-04-06 03:44:23,989 - mmdet - INFO - Epoch [14][1850/2442]	lr: 5.279e-06, eta: 3:40:26, time: 1.495, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0197, loss_rpn_bbox: 0.0438, s0.loss_cls: 0.1464, s0.acc: 94.5508, s0.loss_bbox: 0.0871, s1.loss_cls: 0.0647, s1.acc: 95.3484, s1.loss_bbox: 0.0833, s2.loss_cls: 0.0326, s2.acc: 95.1962, s2.loss_bbox: 0.0514, loss: 0.5290
2022-04-06 03:45:38,448 - mmdet - INFO - Epoch [14][1900/2442]	lr: 5.279e-06, eta: 3:39:13, time: 1.489, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0197, loss_rpn_bbox: 0.0548, s0.loss_cls: 0.1755, s0.acc: 93.6250, s0.loss_bbox: 0.1013, s1.loss_cls: 0.0791, s1.acc: 94.4421, s1.loss_bbox: 0.1024, s2.loss_cls: 0.0408, s2.acc: 94.5448, s2.loss_bbox: 0.0622, loss: 0.6357
2022-04-06 03:46:52,925 - mmdet - INFO - Epoch [14][1950/2442]	lr: 5.279e-06, eta: 3:37:59, time: 1.490, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0240, loss_rpn_bbox: 0.0445, s0.loss_cls: 0.1532, s0.acc: 94.9043, s0.loss_bbox: 0.0857, s1.loss_cls: 0.0653, s1.acc: 95.7702, s1.loss_bbox: 0.0818, s2.loss_cls: 0.0299, s2.acc: 96.2133, s2.loss_bbox: 0.0515, loss: 0.5358
2022-04-06 03:48:07,110 - mmdet - INFO - Epoch [14][2000/2442]	lr: 5.279e-06, eta: 3:36:45, time: 1.484, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0199, loss_rpn_bbox: 0.0432, s0.loss_cls: 0.1512, s0.acc: 94.6953, s0.loss_bbox: 0.0835, s1.loss_cls: 0.0655, s1.acc: 95.6520, s1.loss_bbox: 0.0821, s2.loss_cls: 0.0307, s2.acc: 95.7109, s2.loss_bbox: 0.0510, loss: 0.5273
2022-04-06 03:49:21,709 - mmdet - INFO - Epoch [14][2050/2442]	lr: 5.279e-06, eta: 3:35:32, time: 1.492, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.0447, s0.loss_cls: 0.1368, s0.acc: 95.2129, s0.loss_bbox: 0.0820, s1.loss_cls: 0.0632, s1.acc: 95.4939, s1.loss_bbox: 0.0847, s2.loss_cls: 0.0305, s2.acc: 95.5658, s2.loss_bbox: 0.0540, loss: 0.5134
2022-04-06 03:50:36,477 - mmdet - INFO - Epoch [14][2100/2442]	lr: 5.279e-06, eta: 3:34:19, time: 1.495, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0204, loss_rpn_bbox: 0.0483, s0.loss_cls: 0.1668, s0.acc: 93.9863, s0.loss_bbox: 0.0997, s1.loss_cls: 0.0761, s1.acc: 94.5964, s1.loss_bbox: 0.1005, s2.loss_cls: 0.0376, s2.acc: 94.4170, s2.loss_bbox: 0.0606, loss: 0.6101
2022-04-06 03:51:51,134 - mmdet - INFO - Epoch [14][2150/2442]	lr: 5.279e-06, eta: 3:33:06, time: 1.493, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0206, loss_rpn_bbox: 0.0544, s0.loss_cls: 0.1976, s0.acc: 93.1055, s0.loss_bbox: 0.1143, s1.loss_cls: 0.0886, s1.acc: 93.8256, s1.loss_bbox: 0.1122, s2.loss_cls: 0.0428, s2.acc: 93.9529, s2.loss_bbox: 0.0703, loss: 0.7008
2022-04-06 03:53:05,815 - mmdet - INFO - Epoch [14][2200/2442]	lr: 5.279e-06, eta: 3:31:53, time: 1.494, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0210, loss_rpn_bbox: 0.0467, s0.loss_cls: 0.1424, s0.acc: 94.8457, s0.loss_bbox: 0.0821, s1.loss_cls: 0.0624, s1.acc: 95.5862, s1.loss_bbox: 0.0798, s2.loss_cls: 0.0310, s2.acc: 95.5468, s2.loss_bbox: 0.0522, loss: 0.5176
2022-04-06 03:54:20,361 - mmdet - INFO - Epoch [14][2250/2442]	lr: 5.279e-06, eta: 3:30:40, time: 1.491, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0114, loss_rpn_bbox: 0.0368, s0.loss_cls: 0.1274, s0.acc: 95.6523, s0.loss_bbox: 0.0664, s1.loss_cls: 0.0538, s1.acc: 96.3520, s1.loss_bbox: 0.0652, s2.loss_cls: 0.0257, s2.acc: 96.5334, s2.loss_bbox: 0.0441, loss: 0.4307
2022-04-06 03:55:34,505 - mmdet - INFO - Epoch [14][2300/2442]	lr: 5.279e-06, eta: 3:29:26, time: 1.483, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0400, s0.loss_cls: 0.1616, s0.acc: 94.7734, s0.loss_bbox: 0.0834, s1.loss_cls: 0.0699, s1.acc: 95.4815, s1.loss_bbox: 0.0815, s2.loss_cls: 0.0311, s2.acc: 96.0494, s2.loss_bbox: 0.0480, loss: 0.5309
2022-04-06 03:56:49,014 - mmdet - INFO - Epoch [14][2350/2442]	lr: 5.279e-06, eta: 3:28:12, time: 1.490, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0185, loss_rpn_bbox: 0.0470, s0.loss_cls: 0.1674, s0.acc: 94.0527, s0.loss_bbox: 0.0911, s1.loss_cls: 0.0727, s1.acc: 94.8653, s1.loss_bbox: 0.0891, s2.loss_cls: 0.0341, s2.acc: 95.1235, s2.loss_bbox: 0.0607, loss: 0.5808
2022-04-06 03:58:03,423 - mmdet - INFO - Epoch [14][2400/2442]	lr: 5.279e-06, eta: 3:26:59, time: 1.488, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0451, s0.loss_cls: 0.1667, s0.acc: 94.3086, s0.loss_bbox: 0.0905, s1.loss_cls: 0.0753, s1.acc: 95.0332, s1.loss_bbox: 0.0876, s2.loss_cls: 0.0350, s2.acc: 95.2479, s2.loss_bbox: 0.0541, loss: 0.5727
2022-04-06 03:59:06,213 - mmdet - INFO - Saving checkpoint at 14 epochs
2022-04-06 04:03:14,886 - mmdet - INFO - Evaluating bbox...
2022-04-06 04:03:17,971 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.611
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.026
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.211
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.045
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.706

2022-04-06 04:03:17,972 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.383 | Paper       | 0.415 | Paper pack | 0.631 |
| Metal         | 0.596 | Glass       | 0.506 | Plastic    | 0.530 |
| Styrofoam     | 0.502 | Plastic bag | 0.650 | Battery    | 0.880 |
| Clothing      | 0.612 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-06 04:03:18,004 - mmdet - INFO - Exp name: cascade_rcnn_swin_large.py
2022-04-06 04:03:18,005 - mmdet - INFO - Epoch(val) [14][982]	bbox_mAP: 0.5700, bbox_mAP_50: 0.7230, bbox_mAP_75: 0.6110, bbox_mAP_s: 0.0260, bbox_mAP_m: 0.2110, bbox_mAP_l: 0.6450, bbox_mAP_copypaste: 0.570 0.723 0.611 0.026 0.211 0.645
2022-04-06 04:04:34,979 - mmdet - INFO - Epoch [15][50/2442]	lr: 2.082e-06, eta: 3:23:02, time: 1.539, data_time: 0.056, memory: 28083, loss_rpn_cls: 0.0171, loss_rpn_bbox: 0.0478, s0.loss_cls: 0.1635, s0.acc: 94.3867, s0.loss_bbox: 0.0924, s1.loss_cls: 0.0731, s1.acc: 95.2157, s1.loss_bbox: 0.0883, s2.loss_cls: 0.0351, s2.acc: 95.4718, s2.loss_bbox: 0.0580, loss: 0.5753
2022-04-06 04:05:49,552 - mmdet - INFO - Epoch [15][100/2442]	lr: 2.082e-06, eta: 3:21:51, time: 1.491, data_time: 0.007, memory: 28083, loss_rpn_cls: 0.0301, loss_rpn_bbox: 0.0506, s0.loss_cls: 0.1705, s0.acc: 94.0723, s0.loss_bbox: 0.0927, s1.loss_cls: 0.0764, s1.acc: 94.7318, s1.loss_bbox: 0.0889, s2.loss_cls: 0.0371, s2.acc: 94.9883, s2.loss_bbox: 0.0529, loss: 0.5992
2022-04-06 04:07:03,891 - mmdet - INFO - Epoch [15][150/2442]	lr: 2.082e-06, eta: 3:20:38, time: 1.487, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0497, s0.loss_cls: 0.1441, s0.acc: 94.9023, s0.loss_bbox: 0.0837, s1.loss_cls: 0.0605, s1.acc: 95.7696, s1.loss_bbox: 0.0793, s2.loss_cls: 0.0286, s2.acc: 95.9527, s2.loss_bbox: 0.0492, loss: 0.5131
2022-04-06 04:08:18,736 - mmdet - INFO - Epoch [15][200/2442]	lr: 2.082e-06, eta: 3:19:27, time: 1.497, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0169, loss_rpn_bbox: 0.0411, s0.loss_cls: 0.1520, s0.acc: 94.8574, s0.loss_bbox: 0.0826, s1.loss_cls: 0.0620, s1.acc: 95.8057, s1.loss_bbox: 0.0761, s2.loss_cls: 0.0277, s2.acc: 96.3256, s2.loss_bbox: 0.0468, loss: 0.5052
2022-04-06 04:09:33,194 - mmdet - INFO - Epoch [15][250/2442]	lr: 2.082e-06, eta: 3:18:15, time: 1.489, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0205, loss_rpn_bbox: 0.0511, s0.loss_cls: 0.1641, s0.acc: 94.0293, s0.loss_bbox: 0.0992, s1.loss_cls: 0.0750, s1.acc: 94.7300, s1.loss_bbox: 0.1005, s2.loss_cls: 0.0353, s2.acc: 94.8539, s2.loss_bbox: 0.0633, loss: 0.6089
2022-04-06 04:10:47,130 - mmdet - INFO - Epoch [15][300/2442]	lr: 2.082e-06, eta: 3:17:02, time: 1.479, data_time: 0.007, memory: 28083, loss_rpn_cls: 0.0147, loss_rpn_bbox: 0.0437, s0.loss_cls: 0.1552, s0.acc: 94.4824, s0.loss_bbox: 0.0891, s1.loss_cls: 0.0680, s1.acc: 95.2479, s1.loss_bbox: 0.0911, s2.loss_cls: 0.0334, s2.acc: 95.1383, s2.loss_bbox: 0.0573, loss: 0.5526
2022-04-06 04:12:01,119 - mmdet - INFO - Epoch [15][350/2442]	lr: 2.082e-06, eta: 3:15:49, time: 1.480, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0178, loss_rpn_bbox: 0.0436, s0.loss_cls: 0.1566, s0.acc: 94.3105, s0.loss_bbox: 0.0933, s1.loss_cls: 0.0656, s1.acc: 95.5485, s1.loss_bbox: 0.0987, s2.loss_cls: 0.0325, s2.acc: 95.5683, s2.loss_bbox: 0.0640, loss: 0.5721
2022-04-06 04:13:15,559 - mmdet - INFO - Epoch [15][400/2442]	lr: 2.082e-06, eta: 3:14:37, time: 1.489, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0157, loss_rpn_bbox: 0.0494, s0.loss_cls: 0.1704, s0.acc: 94.0898, s0.loss_bbox: 0.0960, s1.loss_cls: 0.0790, s1.acc: 94.5594, s1.loss_bbox: 0.0901, s2.loss_cls: 0.0376, s2.acc: 94.5480, s2.loss_bbox: 0.0552, loss: 0.5935
2022-04-06 04:14:30,045 - mmdet - INFO - Epoch [15][450/2442]	lr: 2.082e-06, eta: 3:13:24, time: 1.490, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0387, s0.loss_cls: 0.1237, s0.acc: 95.6895, s0.loss_bbox: 0.0688, s1.loss_cls: 0.0531, s1.acc: 96.2312, s1.loss_bbox: 0.0690, s2.loss_cls: 0.0257, s2.acc: 96.2991, s2.loss_bbox: 0.0439, loss: 0.4389
2022-04-06 04:15:44,492 - mmdet - INFO - Epoch [15][500/2442]	lr: 2.082e-06, eta: 3:12:12, time: 1.489, data_time: 0.007, memory: 28083, loss_rpn_cls: 0.0267, loss_rpn_bbox: 0.0422, s0.loss_cls: 0.1791, s0.acc: 93.9434, s0.loss_bbox: 0.0872, s1.loss_cls: 0.0774, s1.acc: 94.7401, s1.loss_bbox: 0.0877, s2.loss_cls: 0.0367, s2.acc: 94.9325, s2.loss_bbox: 0.0541, loss: 0.5910
2022-04-06 04:16:59,034 - mmdet - INFO - Epoch [15][550/2442]	lr: 2.082e-06, eta: 3:11:00, time: 1.491, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0220, loss_rpn_bbox: 0.0486, s0.loss_cls: 0.1502, s0.acc: 94.7227, s0.loss_bbox: 0.0965, s1.loss_cls: 0.0647, s1.acc: 95.4366, s1.loss_bbox: 0.0934, s2.loss_cls: 0.0314, s2.acc: 95.6508, s2.loss_bbox: 0.0559, loss: 0.5628
2022-04-06 04:18:13,207 - mmdet - INFO - Epoch [15][600/2442]	lr: 2.082e-06, eta: 3:09:47, time: 1.483, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0163, loss_rpn_bbox: 0.0338, s0.loss_cls: 0.1363, s0.acc: 95.2363, s0.loss_bbox: 0.0785, s1.loss_cls: 0.0588, s1.acc: 95.7964, s1.loss_bbox: 0.0819, s2.loss_cls: 0.0281, s2.acc: 96.0468, s2.loss_bbox: 0.0548, loss: 0.4886
2022-04-06 04:19:27,643 - mmdet - INFO - Epoch [15][650/2442]	lr: 2.082e-06, eta: 3:08:34, time: 1.489, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0157, loss_rpn_bbox: 0.0464, s0.loss_cls: 0.1623, s0.acc: 94.4648, s0.loss_bbox: 0.0829, s1.loss_cls: 0.0706, s1.acc: 95.3603, s1.loss_bbox: 0.0822, s2.loss_cls: 0.0351, s2.acc: 95.3230, s2.loss_bbox: 0.0562, loss: 0.5514
2022-04-06 04:20:42,093 - mmdet - INFO - Epoch [15][700/2442]	lr: 2.082e-06, eta: 3:07:22, time: 1.489, data_time: 0.007, memory: 28083, loss_rpn_cls: 0.0238, loss_rpn_bbox: 0.0480, s0.loss_cls: 0.1554, s0.acc: 94.5586, s0.loss_bbox: 0.0834, s1.loss_cls: 0.0689, s1.acc: 95.4231, s1.loss_bbox: 0.0887, s2.loss_cls: 0.0342, s2.acc: 95.2472, s2.loss_bbox: 0.0630, loss: 0.5655
2022-04-06 04:21:56,384 - mmdet - INFO - Epoch [15][750/2442]	lr: 2.082e-06, eta: 3:06:09, time: 1.486, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0178, loss_rpn_bbox: 0.0342, s0.loss_cls: 0.1246, s0.acc: 95.6543, s0.loss_bbox: 0.0618, s1.loss_cls: 0.0533, s1.acc: 96.4326, s1.loss_bbox: 0.0637, s2.loss_cls: 0.0262, s2.acc: 96.2188, s2.loss_bbox: 0.0451, loss: 0.4267
2022-04-06 04:23:10,804 - mmdet - INFO - Epoch [15][800/2442]	lr: 2.082e-06, eta: 3:04:56, time: 1.488, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0240, loss_rpn_bbox: 0.0507, s0.loss_cls: 0.1380, s0.acc: 95.1523, s0.loss_bbox: 0.0862, s1.loss_cls: 0.0583, s1.acc: 96.1339, s1.loss_bbox: 0.0878, s2.loss_cls: 0.0280, s2.acc: 96.2750, s2.loss_bbox: 0.0582, loss: 0.5313
2022-04-06 04:24:25,247 - mmdet - INFO - Epoch [15][850/2442]	lr: 2.082e-06, eta: 3:03:44, time: 1.489, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0171, loss_rpn_bbox: 0.0444, s0.loss_cls: 0.1539, s0.acc: 94.8008, s0.loss_bbox: 0.0869, s1.loss_cls: 0.0660, s1.acc: 95.5981, s1.loss_bbox: 0.0878, s2.loss_cls: 0.0297, s2.acc: 96.1539, s2.loss_bbox: 0.0538, loss: 0.5395
2022-04-06 04:25:39,996 - mmdet - INFO - Epoch [15][900/2442]	lr: 2.082e-06, eta: 3:02:32, time: 1.495, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0118, loss_rpn_bbox: 0.0339, s0.loss_cls: 0.1436, s0.acc: 95.2207, s0.loss_bbox: 0.0763, s1.loss_cls: 0.0609, s1.acc: 95.9930, s1.loss_bbox: 0.0678, s2.loss_cls: 0.0298, s2.acc: 96.1192, s2.loss_bbox: 0.0444, loss: 0.4684
2022-04-06 04:26:55,087 - mmdet - INFO - Epoch [15][950/2442]	lr: 2.082e-06, eta: 3:01:20, time: 1.502, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0198, loss_rpn_bbox: 0.0432, s0.loss_cls: 0.1520, s0.acc: 94.8789, s0.loss_bbox: 0.0794, s1.loss_cls: 0.0658, s1.acc: 95.5514, s1.loss_bbox: 0.0754, s2.loss_cls: 0.0309, s2.acc: 95.6291, s2.loss_bbox: 0.0494, loss: 0.5159
2022-04-06 04:28:10,046 - mmdet - INFO - Epoch [15][1000/2442]	lr: 2.082e-06, eta: 3:00:08, time: 1.499, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0168, loss_rpn_bbox: 0.0551, s0.loss_cls: 0.1640, s0.acc: 94.4082, s0.loss_bbox: 0.0936, s1.loss_cls: 0.0716, s1.acc: 95.2299, s1.loss_bbox: 0.0911, s2.loss_cls: 0.0343, s2.acc: 95.3859, s2.loss_bbox: 0.0578, loss: 0.5844
2022-04-06 04:29:24,357 - mmdet - INFO - Epoch [15][1050/2442]	lr: 2.082e-06, eta: 2:58:55, time: 1.486, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.0437, s0.loss_cls: 0.1439, s0.acc: 95.0449, s0.loss_bbox: 0.0763, s1.loss_cls: 0.0648, s1.acc: 95.4496, s1.loss_bbox: 0.0733, s2.loss_cls: 0.0323, s2.acc: 95.1302, s2.loss_bbox: 0.0451, loss: 0.4987
2022-04-06 04:30:38,955 - mmdet - INFO - Epoch [15][1100/2442]	lr: 2.082e-06, eta: 2:57:42, time: 1.492, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0278, loss_rpn_bbox: 0.0463, s0.loss_cls: 0.1730, s0.acc: 93.9043, s0.loss_bbox: 0.0931, s1.loss_cls: 0.0734, s1.acc: 94.8329, s1.loss_bbox: 0.0948, s2.loss_cls: 0.0370, s2.acc: 95.0739, s2.loss_bbox: 0.0575, loss: 0.6030
2022-04-06 04:31:54,078 - mmdet - INFO - Epoch [15][1150/2442]	lr: 2.082e-06, eta: 2:56:30, time: 1.502, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0140, loss_rpn_bbox: 0.0447, s0.loss_cls: 0.1390, s0.acc: 95.1387, s0.loss_bbox: 0.0814, s1.loss_cls: 0.0615, s1.acc: 95.8863, s1.loss_bbox: 0.0783, s2.loss_cls: 0.0302, s2.acc: 96.0553, s2.loss_bbox: 0.0525, loss: 0.5017
2022-04-06 04:33:08,873 - mmdet - INFO - Epoch [15][1200/2442]	lr: 2.082e-06, eta: 2:55:18, time: 1.496, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0435, s0.loss_cls: 0.1512, s0.acc: 94.5332, s0.loss_bbox: 0.0908, s1.loss_cls: 0.0633, s1.acc: 95.4469, s1.loss_bbox: 0.0854, s2.loss_cls: 0.0307, s2.acc: 95.7959, s2.loss_bbox: 0.0520, loss: 0.5349
2022-04-06 04:34:24,088 - mmdet - INFO - Epoch [15][1250/2442]	lr: 2.082e-06, eta: 2:54:06, time: 1.504, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0149, loss_rpn_bbox: 0.0440, s0.loss_cls: 0.1630, s0.acc: 94.4961, s0.loss_bbox: 0.0976, s1.loss_cls: 0.0716, s1.acc: 95.3754, s1.loss_bbox: 0.0865, s2.loss_cls: 0.0344, s2.acc: 95.6838, s2.loss_bbox: 0.0500, loss: 0.5620
2022-04-06 04:35:38,649 - mmdet - INFO - Epoch [15][1300/2442]	lr: 2.082e-06, eta: 2:52:53, time: 1.491, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0399, loss_rpn_bbox: 0.0475, s0.loss_cls: 0.1688, s0.acc: 94.0625, s0.loss_bbox: 0.0916, s1.loss_cls: 0.0719, s1.acc: 94.9578, s1.loss_bbox: 0.0876, s2.loss_cls: 0.0348, s2.acc: 94.9483, s2.loss_bbox: 0.0549, loss: 0.5970
2022-04-06 04:36:53,259 - mmdet - INFO - Epoch [15][1350/2442]	lr: 2.082e-06, eta: 2:51:40, time: 1.492, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.0452, s0.loss_cls: 0.1575, s0.acc: 94.4551, s0.loss_bbox: 0.0938, s1.loss_cls: 0.0708, s1.acc: 94.8999, s1.loss_bbox: 0.0934, s2.loss_cls: 0.0342, s2.acc: 95.0516, s2.loss_bbox: 0.0549, loss: 0.5671
2022-04-06 04:38:07,489 - mmdet - INFO - Epoch [15][1400/2442]	lr: 2.082e-06, eta: 2:50:27, time: 1.485, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0214, loss_rpn_bbox: 0.0554, s0.loss_cls: 0.1887, s0.acc: 93.5547, s0.loss_bbox: 0.1072, s1.loss_cls: 0.0844, s1.acc: 94.2721, s1.loss_bbox: 0.1050, s2.loss_cls: 0.0404, s2.acc: 94.4020, s2.loss_bbox: 0.0641, loss: 0.6667
2022-04-06 04:39:22,118 - mmdet - INFO - Epoch [15][1450/2442]	lr: 2.082e-06, eta: 2:49:14, time: 1.493, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0422, s0.loss_cls: 0.1452, s0.acc: 94.9512, s0.loss_bbox: 0.0814, s1.loss_cls: 0.0639, s1.acc: 95.7914, s1.loss_bbox: 0.0802, s2.loss_cls: 0.0314, s2.acc: 95.7328, s2.loss_bbox: 0.0489, loss: 0.5085
2022-04-06 04:40:37,051 - mmdet - INFO - Epoch [15][1500/2442]	lr: 2.082e-06, eta: 2:48:02, time: 1.499, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0149, loss_rpn_bbox: 0.0380, s0.loss_cls: 0.1361, s0.acc: 95.1641, s0.loss_bbox: 0.0771, s1.loss_cls: 0.0594, s1.acc: 95.8339, s1.loss_bbox: 0.0780, s2.loss_cls: 0.0302, s2.acc: 95.9372, s2.loss_bbox: 0.0502, loss: 0.4839
2022-04-06 04:41:52,031 - mmdet - INFO - Epoch [15][1550/2442]	lr: 2.082e-06, eta: 2:46:49, time: 1.500, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0116, loss_rpn_bbox: 0.0309, s0.loss_cls: 0.1236, s0.acc: 95.6992, s0.loss_bbox: 0.0672, s1.loss_cls: 0.0545, s1.acc: 96.5007, s1.loss_bbox: 0.0674, s2.loss_cls: 0.0257, s2.acc: 96.6820, s2.loss_bbox: 0.0425, loss: 0.4236
2022-04-06 04:43:06,501 - mmdet - INFO - Epoch [15][1600/2442]	lr: 2.082e-06, eta: 2:45:36, time: 1.489, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0413, s0.loss_cls: 0.1623, s0.acc: 94.1895, s0.loss_bbox: 0.0958, s1.loss_cls: 0.0722, s1.acc: 95.0129, s1.loss_bbox: 0.0884, s2.loss_cls: 0.0338, s2.acc: 95.3658, s2.loss_bbox: 0.0550, loss: 0.5705
2022-04-06 04:44:21,035 - mmdet - INFO - Epoch [15][1650/2442]	lr: 2.082e-06, eta: 2:44:23, time: 1.491, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0143, loss_rpn_bbox: 0.0506, s0.loss_cls: 0.1587, s0.acc: 94.2227, s0.loss_bbox: 0.0925, s1.loss_cls: 0.0685, s1.acc: 94.9221, s1.loss_bbox: 0.0941, s2.loss_cls: 0.0331, s2.acc: 95.1509, s2.loss_bbox: 0.0606, loss: 0.5724
2022-04-06 04:45:35,653 - mmdet - INFO - Epoch [15][1700/2442]	lr: 2.082e-06, eta: 2:43:10, time: 1.492, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0239, loss_rpn_bbox: 0.0480, s0.loss_cls: 0.1704, s0.acc: 94.2500, s0.loss_bbox: 0.0925, s1.loss_cls: 0.0779, s1.acc: 95.0405, s1.loss_bbox: 0.0921, s2.loss_cls: 0.0384, s2.acc: 94.9553, s2.loss_bbox: 0.0581, loss: 0.6014
2022-04-06 04:46:50,116 - mmdet - INFO - Epoch [15][1750/2442]	lr: 2.082e-06, eta: 2:41:57, time: 1.489, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0187, loss_rpn_bbox: 0.0455, s0.loss_cls: 0.1483, s0.acc: 94.6406, s0.loss_bbox: 0.0870, s1.loss_cls: 0.0669, s1.acc: 95.2716, s1.loss_bbox: 0.0805, s2.loss_cls: 0.0325, s2.acc: 95.4826, s2.loss_bbox: 0.0494, loss: 0.5289
2022-04-06 04:48:05,178 - mmdet - INFO - Epoch [15][1800/2442]	lr: 2.082e-06, eta: 2:40:45, time: 1.501, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0142, loss_rpn_bbox: 0.0433, s0.loss_cls: 0.1337, s0.acc: 95.5781, s0.loss_bbox: 0.0667, s1.loss_cls: 0.0600, s1.acc: 96.2897, s1.loss_bbox: 0.0678, s2.loss_cls: 0.0285, s2.acc: 96.4955, s2.loss_bbox: 0.0432, loss: 0.4573
2022-04-06 04:49:20,024 - mmdet - INFO - Epoch [15][1850/2442]	lr: 2.082e-06, eta: 2:39:32, time: 1.497, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0227, loss_rpn_bbox: 0.0449, s0.loss_cls: 0.1595, s0.acc: 94.3105, s0.loss_bbox: 0.0822, s1.loss_cls: 0.0752, s1.acc: 94.7677, s1.loss_bbox: 0.0831, s2.loss_cls: 0.0377, s2.acc: 94.7328, s2.loss_bbox: 0.0546, loss: 0.5598
2022-04-06 04:50:34,942 - mmdet - INFO - Epoch [15][1900/2442]	lr: 2.082e-06, eta: 2:38:19, time: 1.498, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0215, loss_rpn_bbox: 0.0448, s0.loss_cls: 0.1475, s0.acc: 95.1367, s0.loss_bbox: 0.0783, s1.loss_cls: 0.0624, s1.acc: 95.9281, s1.loss_bbox: 0.0748, s2.loss_cls: 0.0312, s2.acc: 95.9847, s2.loss_bbox: 0.0482, loss: 0.5087
2022-04-06 04:51:49,669 - mmdet - INFO - Epoch [15][1950/2442]	lr: 2.082e-06, eta: 2:37:06, time: 1.495, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0493, s0.loss_cls: 0.1766, s0.acc: 93.7051, s0.loss_bbox: 0.1054, s1.loss_cls: 0.0793, s1.acc: 94.4062, s1.loss_bbox: 0.1015, s2.loss_cls: 0.0388, s2.acc: 94.3250, s2.loss_bbox: 0.0613, loss: 0.6324
2022-04-06 04:53:04,188 - mmdet - INFO - Epoch [15][2000/2442]	lr: 2.082e-06, eta: 2:35:53, time: 1.490, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0375, s0.loss_cls: 0.1368, s0.acc: 95.3340, s0.loss_bbox: 0.0753, s1.loss_cls: 0.0609, s1.acc: 96.0984, s1.loss_bbox: 0.0750, s2.loss_cls: 0.0303, s2.acc: 96.2372, s2.loss_bbox: 0.0504, loss: 0.4822
2022-04-06 04:54:18,597 - mmdet - INFO - Epoch [15][2050/2442]	lr: 2.082e-06, eta: 2:34:39, time: 1.488, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0176, loss_rpn_bbox: 0.0375, s0.loss_cls: 0.1628, s0.acc: 94.4473, s0.loss_bbox: 0.0825, s1.loss_cls: 0.0722, s1.acc: 95.0432, s1.loss_bbox: 0.0791, s2.loss_cls: 0.0338, s2.acc: 95.6181, s2.loss_bbox: 0.0507, loss: 0.5363
2022-04-06 04:55:33,100 - mmdet - INFO - Epoch [15][2100/2442]	lr: 2.082e-06, eta: 2:33:26, time: 1.490, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0313, s0.loss_cls: 0.1159, s0.acc: 95.8672, s0.loss_bbox: 0.0650, s1.loss_cls: 0.0487, s1.acc: 96.5550, s1.loss_bbox: 0.0642, s2.loss_cls: 0.0234, s2.acc: 96.4833, s2.loss_bbox: 0.0404, loss: 0.4106
2022-04-06 04:56:47,674 - mmdet - INFO - Epoch [15][2150/2442]	lr: 2.082e-06, eta: 2:32:13, time: 1.491, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0153, loss_rpn_bbox: 0.0432, s0.loss_cls: 0.1279, s0.acc: 95.3477, s0.loss_bbox: 0.0739, s1.loss_cls: 0.0530, s1.acc: 96.1135, s1.loss_bbox: 0.0746, s2.loss_cls: 0.0253, s2.acc: 96.2004, s2.loss_bbox: 0.0463, loss: 0.4595
2022-04-06 04:58:02,189 - mmdet - INFO - Epoch [15][2200/2442]	lr: 2.082e-06, eta: 2:31:00, time: 1.490, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0306, loss_rpn_bbox: 0.0443, s0.loss_cls: 0.1730, s0.acc: 93.9766, s0.loss_bbox: 0.0942, s1.loss_cls: 0.0763, s1.acc: 94.6083, s1.loss_bbox: 0.0932, s2.loss_cls: 0.0382, s2.acc: 94.5239, s2.loss_bbox: 0.0579, loss: 0.6076
2022-04-06 04:59:16,593 - mmdet - INFO - Epoch [15][2250/2442]	lr: 2.082e-06, eta: 2:29:46, time: 1.488, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0133, loss_rpn_bbox: 0.0393, s0.loss_cls: 0.1115, s0.acc: 96.1367, s0.loss_bbox: 0.0566, s1.loss_cls: 0.0469, s1.acc: 97.1099, s1.loss_bbox: 0.0619, s2.loss_cls: 0.0224, s2.acc: 97.2002, s2.loss_bbox: 0.0447, loss: 0.3966
2022-04-06 05:00:30,936 - mmdet - INFO - Epoch [15][2300/2442]	lr: 2.082e-06, eta: 2:28:33, time: 1.487, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.0509, s0.loss_cls: 0.1502, s0.acc: 94.6836, s0.loss_bbox: 0.0795, s1.loss_cls: 0.0659, s1.acc: 95.5410, s1.loss_bbox: 0.0786, s2.loss_cls: 0.0333, s2.acc: 95.1237, s2.loss_bbox: 0.0525, loss: 0.5292
2022-04-06 05:01:45,905 - mmdet - INFO - Epoch [15][2350/2442]	lr: 2.082e-06, eta: 2:27:20, time: 1.499, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0145, loss_rpn_bbox: 0.0458, s0.loss_cls: 0.1702, s0.acc: 94.1133, s0.loss_bbox: 0.0951, s1.loss_cls: 0.0757, s1.acc: 95.0858, s1.loss_bbox: 0.0871, s2.loss_cls: 0.0362, s2.acc: 95.2199, s2.loss_bbox: 0.0544, loss: 0.5790
2022-04-06 05:03:00,618 - mmdet - INFO - Epoch [15][2400/2442]	lr: 2.082e-06, eta: 2:26:07, time: 1.494, data_time: 0.008, memory: 28083, loss_rpn_cls: 0.0256, loss_rpn_bbox: 0.0499, s0.loss_cls: 0.1638, s0.acc: 94.4785, s0.loss_bbox: 0.0978, s1.loss_cls: 0.0703, s1.acc: 95.3555, s1.loss_bbox: 0.0990, s2.loss_cls: 0.0339, s2.acc: 95.5047, s2.loss_bbox: 0.0561, loss: 0.5966
2022-04-06 05:04:03,571 - mmdet - INFO - Saving checkpoint at 15 epochs
2022-04-06 05:08:12,470 - mmdet - INFO - Evaluating bbox...
2022-04-06 05:08:15,416 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.728
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.619
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.023
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.217
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.042
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.712

2022-04-06 05:08:15,417 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.399 | Paper       | 0.419 | Paper pack | 0.643 |
| Metal         | 0.604 | Glass       | 0.514 | Plastic    | 0.544 |
| Styrofoam     | 0.505 | Plastic bag | 0.648 | Battery    | 0.889 |
| Clothing      | 0.616 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-06 05:08:15,453 - mmdet - INFO - Exp name: cascade_rcnn_swin_large.py
2022-04-06 05:08:15,454 - mmdet - INFO - Epoch(val) [15][982]	bbox_mAP: 0.5780, bbox_mAP_50: 0.7280, bbox_mAP_75: 0.6190, bbox_mAP_s: 0.0230, bbox_mAP_m: 0.2170, bbox_mAP_l: 0.6530, bbox_mAP_copypaste: 0.578 0.728 0.619 0.023 0.217 0.653

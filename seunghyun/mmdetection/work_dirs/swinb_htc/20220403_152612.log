2022-04-03 15:26:13,838 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2
OpenCV: 4.5.5
MMCV: 1.4.6
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMDetection: 2.22.0+
------------------------------------------------------------

2022-04-03 15:26:15,781 - mmdet - INFO - Distributed training: False
2022-04-03 15:26:17,719 - mmdet - INFO - Config:
model = dict(
    type='HybridTaskCascade',
    backbone=dict(
        type='SwinTransformer',
        embed_dims=128,
        depths=[2, 2, 18, 2],
        num_heads=[4, 8, 16, 32],
        window_size=7,
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.2,
        patch_norm=True,
        out_indices=(0, 1, 2, 3),
        with_cp=False,
        convert_weights=True,
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth'
        )),
    neck=dict(
        type='FPN',
        in_channels=[128, 256, 512, 1024],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(
            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),
    roi_head=dict(
        type='HybridTaskCascadeRoIHead',
        interleaved=True,
        mask_info_flow=True,
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))
        ]),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.001,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100,
            mask_thr_binary=0.5)))
dataset_type = 'CocoDataset'
data_root = '/opt/ml/detection/dataset/'
classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
img_scale = (1024, 1024)
albu_train_transforms = [
    dict(
        type='OneOf',
        transforms=[
            dict(type='Flip', p=1.0),
            dict(type='RandomRotate90', p=1.0)
        ],
        p=0.5),
    dict(
        type='RandomResizedCrop',
        height=1024,
        width=1024,
        scale=(0.5, 1.0),
        p=0.5),
    dict(
        type='RandomBrightnessContrast',
        brightness_limit=0.1,
        contrast_limit=0.15,
        p=0.5),
    dict(
        type='HueSaturationValue',
        hue_shift_limit=15,
        sat_shift_limit=25,
        val_shift_limit=10,
        p=0.5),
    dict(type='GaussNoise', p=0.3),
    dict(
        type='OneOf',
        transforms=[
            dict(type='Blur', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='MedianBlur', blur_limit=5, p=1.0),
            dict(type='MotionBlur', p=1.0)
        ],
        p=0.1)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1024, 1024), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.0),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Flip', p=1.0),
                    dict(type='RandomRotate90', p=1.0)
                ],
                p=0.5),
            dict(
                type='RandomResizedCrop',
                height=1024,
                width=1024,
                scale=(0.5, 1.0),
                p=0.5),
            dict(
                type='RandomBrightnessContrast',
                brightness_limit=0.1,
                contrast_limit=0.15,
                p=0.5),
            dict(
                type='HueSaturationValue',
                hue_shift_limit=15,
                sat_shift_limit=25,
                val_shift_limit=10,
                p=0.5),
            dict(type='GaussNoise', p=0.3),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Blur', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='MedianBlur', blur_limit=5, p=1.0),
                    dict(type='MotionBlur', p=1.0)
                ],
                p=0.1)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file=
        '/opt/ml/detection/dataset/stratified_kfold/basic_v2/cv_train_3.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1024, 1024), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.0),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Flip', p=1.0),
                            dict(type='RandomRotate90', p=1.0)
                        ],
                        p=0.5),
                    dict(
                        type='RandomResizedCrop',
                        height=1024,
                        width=1024,
                        scale=(0.5, 1.0),
                        p=0.5),
                    dict(
                        type='RandomBrightnessContrast',
                        brightness_limit=0.1,
                        contrast_limit=0.15,
                        p=0.5),
                    dict(
                        type='HueSaturationValue',
                        hue_shift_limit=15,
                        sat_shift_limit=25,
                        val_shift_limit=10,
                        p=0.5),
                    dict(type='GaussNoise', p=0.3),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Blur', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='MedianBlur', blur_limit=5, p=1.0),
                            dict(type='MotionBlur', p=1.0)
                        ],
                        p=0.1)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file=
        '/opt/ml/detection/dataset/stratified_kfold/basic_v2/cv_val_3.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/test.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='bbox', classwise=True)
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=976,
    warmup_ratio=0.001,
    min_lr=1e-06)
runner = dict(type='EpochBasedRunner', max_epochs=36)
checkpoint_config = dict(max_keep_ckpts=5, interval=1)
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(
            type='WandbLoggerHook',
            interval=1000,
            init_kwargs=dict(
                project='two-stage-model',
                entity='canvas11',
                name='LEE_SwinB_HTC'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = '/opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/swinb_htc/epoch_22.pth'
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth'
work_dir = 'work_dirs/swinb_htc'
auto_resume = False
gpu_ids = [0]

2022-04-03 15:26:17,720 - mmdet - INFO - Set random seed to 1955465044, deterministic: False
2022-04-03 15:26:19,070 - mmdet - INFO - load checkpoint from http path: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth
2022-04-03 15:26:19,654 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2022-04-03 15:26:19,688 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2022-04-03 15:26:19,697 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-04-03 15:26:19,815 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-04-03 15:26:19,983 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([128, 3, 4, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.projection.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([384, 128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([128, 128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([512, 128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([128, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([384, 128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([128, 128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([512, 128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([128, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.reduction.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 8]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 8]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.reduction.weight - torch.Size([512, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table - torch.Size([169, 16]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.reduction.weight - torch.Size([1024, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 32]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([4096]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 32]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([4096]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.norm0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.norm0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.norm3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.norm3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.lateral_convs.0.conv.weight - torch.Size([256, 128, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.lateral_convs.1.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.lateral_convs.2.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.lateral_convs.3.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 
2022-04-03 15:26:24,333 - mmdet - INFO - load checkpoint from local path: /opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/swinb_htc/epoch_22.pth
2022-04-03 15:26:25,536 - mmdet - INFO - resumed epoch 22, iter 21472
2022-04-03 15:26:25,539 - mmdet - INFO - Start running, host: root@0a25b60abdd2, work_dir: /opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/swinb_htc
2022-04-03 15:26:25,539 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2022-04-03 15:26:25,540 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
2022-04-03 15:26:25,540 - mmdet - INFO - Checkpoints will be saved to /opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/swinb_htc by HardDiskBackend.
2022-04-03 15:27:54,648 - mmdet - INFO - Epoch [23][50/976]	lr: 3.357e-05, eta: 6:13:03, time: 1.644, data_time: 0.064, memory: 25267, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0142, s0.loss_cls: 0.0865, s0.acc: 96.8750, s0.loss_bbox: 0.0596, s1.loss_cls: 0.0275, s1.acc: 98.0332, s1.loss_bbox: 0.0354, s2.loss_cls: 0.0073, s2.acc: 98.9648, s2.loss_bbox: 0.0094, loss: 0.2466
2022-04-03 15:29:13,719 - mmdet - INFO - Epoch [23][100/976]	lr: 3.357e-05, eta: 6:04:35, time: 1.581, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0124, s0.loss_cls: 0.0792, s0.acc: 97.1504, s0.loss_bbox: 0.0512, s1.loss_cls: 0.0261, s1.acc: 98.1299, s1.loss_bbox: 0.0327, s2.loss_cls: 0.0068, s2.acc: 99.0557, s2.loss_bbox: 0.0088, loss: 0.2252
2022-04-03 15:30:32,592 - mmdet - INFO - Epoch [23][150/976]	lr: 3.357e-05, eta: 6:00:35, time: 1.577, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0142, s0.loss_cls: 0.0873, s0.acc: 96.8086, s0.loss_bbox: 0.0556, s1.loss_cls: 0.0290, s1.acc: 97.9463, s1.loss_bbox: 0.0343, s2.loss_cls: 0.0073, s2.acc: 98.9912, s2.loss_bbox: 0.0091, loss: 0.2436
2022-04-03 15:31:51,353 - mmdet - INFO - Epoch [23][200/976]	lr: 3.357e-05, eta: 5:57:48, time: 1.575, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0908, s0.acc: 96.7207, s0.loss_bbox: 0.0587, s1.loss_cls: 0.0312, s1.acc: 97.7822, s1.loss_bbox: 0.0376, s2.loss_cls: 0.0088, s2.acc: 98.8057, s2.loss_bbox: 0.0112, loss: 0.2627
2022-04-03 15:33:10,544 - mmdet - INFO - Epoch [23][250/976]	lr: 3.357e-05, eta: 5:56:00, time: 1.584, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0093, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0892, s0.acc: 96.7129, s0.loss_bbox: 0.0616, s1.loss_cls: 0.0306, s1.acc: 97.8379, s1.loss_bbox: 0.0391, s2.loss_cls: 0.0081, s2.acc: 98.9121, s2.loss_bbox: 0.0105, loss: 0.2641
2022-04-03 15:34:29,713 - mmdet - INFO - Epoch [23][300/976]	lr: 3.357e-05, eta: 5:54:20, time: 1.583, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0826, s0.acc: 96.9688, s0.loss_bbox: 0.0588, s1.loss_cls: 0.0263, s1.acc: 98.0928, s1.loss_bbox: 0.0340, s2.loss_cls: 0.0064, s2.acc: 99.0898, s2.loss_bbox: 0.0083, loss: 0.2409
2022-04-03 15:35:48,697 - mmdet - INFO - Epoch [23][350/976]	lr: 3.357e-05, eta: 5:52:39, time: 1.580, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0100, loss_rpn_bbox: 0.0174, s0.loss_cls: 0.0869, s0.acc: 96.8291, s0.loss_bbox: 0.0588, s1.loss_cls: 0.0299, s1.acc: 97.8779, s1.loss_bbox: 0.0382, s2.loss_cls: 0.0077, s2.acc: 98.9473, s2.loss_bbox: 0.0101, loss: 0.2590
2022-04-03 15:37:08,193 - mmdet - INFO - Epoch [23][400/976]	lr: 3.357e-05, eta: 5:51:21, time: 1.590, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0834, s0.acc: 97.0098, s0.loss_bbox: 0.0552, s1.loss_cls: 0.0291, s1.acc: 97.9170, s1.loss_bbox: 0.0361, s2.loss_cls: 0.0077, s2.acc: 98.9297, s2.loss_bbox: 0.0100, loss: 0.2444
2022-04-03 15:38:26,686 - mmdet - INFO - Epoch [23][450/976]	lr: 3.357e-05, eta: 5:49:33, time: 1.570, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0145, s0.loss_cls: 0.0752, s0.acc: 97.2217, s0.loss_bbox: 0.0505, s1.loss_cls: 0.0258, s1.acc: 98.1309, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0070, s2.acc: 99.0488, s2.loss_bbox: 0.0087, loss: 0.2205
2022-04-03 15:39:45,601 - mmdet - INFO - Epoch [23][500/976]	lr: 3.357e-05, eta: 5:48:02, time: 1.578, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0142, s0.loss_cls: 0.0668, s0.acc: 97.4854, s0.loss_bbox: 0.0449, s1.loss_cls: 0.0228, s1.acc: 98.3271, s1.loss_bbox: 0.0307, s2.loss_cls: 0.0063, s2.acc: 99.1152, s2.loss_bbox: 0.0085, loss: 0.2011
2022-04-03 15:41:04,456 - mmdet - INFO - Epoch [23][550/976]	lr: 3.357e-05, eta: 5:46:31, time: 1.577, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0152, s0.loss_cls: 0.0819, s0.acc: 97.0107, s0.loss_bbox: 0.0576, s1.loss_cls: 0.0281, s1.acc: 97.9385, s1.loss_bbox: 0.0375, s2.loss_cls: 0.0077, s2.acc: 98.9199, s2.loss_bbox: 0.0104, loss: 0.2451
2022-04-03 15:42:23,006 - mmdet - INFO - Epoch [23][600/976]	lr: 3.357e-05, eta: 5:44:56, time: 1.571, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0146, s0.loss_cls: 0.0816, s0.acc: 96.9482, s0.loss_bbox: 0.0552, s1.loss_cls: 0.0283, s1.acc: 97.9229, s1.loss_bbox: 0.0363, s2.loss_cls: 0.0078, s2.acc: 98.9424, s2.loss_bbox: 0.0099, loss: 0.2415
2022-04-03 15:43:41,920 - mmdet - INFO - Epoch [23][650/976]	lr: 3.357e-05, eta: 5:43:31, time: 1.578, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0110, loss_rpn_bbox: 0.0188, s0.loss_cls: 0.1024, s0.acc: 96.2402, s0.loss_bbox: 0.0686, s1.loss_cls: 0.0374, s1.acc: 97.2598, s1.loss_bbox: 0.0469, s2.loss_cls: 0.0101, s2.acc: 98.5957, s2.loss_bbox: 0.0130, loss: 0.3082
2022-04-03 15:45:00,779 - mmdet - INFO - Epoch [23][700/976]	lr: 3.357e-05, eta: 5:42:06, time: 1.577, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0077, loss_rpn_bbox: 0.0167, s0.loss_cls: 0.1036, s0.acc: 96.1904, s0.loss_bbox: 0.0693, s1.loss_cls: 0.0356, s1.acc: 97.4746, s1.loss_bbox: 0.0443, s2.loss_cls: 0.0093, s2.acc: 98.6729, s2.loss_bbox: 0.0120, loss: 0.2985
2022-04-03 15:46:19,670 - mmdet - INFO - Epoch [23][750/976]	lr: 3.357e-05, eta: 5:40:42, time: 1.578, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0132, loss_rpn_bbox: 0.0189, s0.loss_cls: 0.0951, s0.acc: 96.5088, s0.loss_bbox: 0.0601, s1.loss_cls: 0.0342, s1.acc: 97.5107, s1.loss_bbox: 0.0420, s2.loss_cls: 0.0096, s2.acc: 98.6465, s2.loss_bbox: 0.0121, loss: 0.2850
2022-04-03 15:47:38,821 - mmdet - INFO - Epoch [23][800/976]	lr: 3.357e-05, eta: 5:39:23, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0105, loss_rpn_bbox: 0.0195, s0.loss_cls: 0.0848, s0.acc: 96.9170, s0.loss_bbox: 0.0579, s1.loss_cls: 0.0283, s1.acc: 97.9580, s1.loss_bbox: 0.0364, s2.loss_cls: 0.0081, s2.acc: 98.8750, s2.loss_bbox: 0.0099, loss: 0.2555
2022-04-03 15:48:57,574 - mmdet - INFO - Epoch [23][850/976]	lr: 3.357e-05, eta: 5:37:58, time: 1.575, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0140, s0.loss_cls: 0.0830, s0.acc: 96.9102, s0.loss_bbox: 0.0587, s1.loss_cls: 0.0285, s1.acc: 97.9648, s1.loss_bbox: 0.0379, s2.loss_cls: 0.0077, s2.acc: 98.9268, s2.loss_bbox: 0.0099, loss: 0.2465
2022-04-03 15:50:16,387 - mmdet - INFO - Epoch [23][900/976]	lr: 3.357e-05, eta: 5:36:34, time: 1.576, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0152, s0.loss_cls: 0.0860, s0.acc: 96.9795, s0.loss_bbox: 0.0532, s1.loss_cls: 0.0279, s1.acc: 98.0723, s1.loss_bbox: 0.0346, s2.loss_cls: 0.0079, s2.acc: 98.9258, s2.loss_bbox: 0.0100, loss: 0.2430
2022-04-03 15:51:35,613 - mmdet - INFO - Epoch [23][950/976]	lr: 3.357e-05, eta: 5:35:17, time: 1.585, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0097, loss_rpn_bbox: 0.0203, s0.loss_cls: 0.0907, s0.acc: 96.5771, s0.loss_bbox: 0.0628, s1.loss_cls: 0.0303, s1.acc: 97.7510, s1.loss_bbox: 0.0390, s2.loss_cls: 0.0080, s2.acc: 98.8164, s2.loss_bbox: 0.0106, loss: 0.2714
2022-04-03 15:52:16,867 - mmdet - INFO - Saving checkpoint at 23 epochs
2022-04-03 15:54:44,009 - mmdet - INFO - Evaluating bbox...
2022-04-03 15:54:50,428 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.618
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.159
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.517
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.120
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.380
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.659

2022-04-03 15:54:50,429 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.274 | Paper       | 0.327 | Paper pack | 0.518 |
| Metal         | 0.517 | Glass       | 0.462 | Plastic    | 0.410 |
| Styrofoam     | 0.423 | Plastic bag | 0.566 | Battery    | 0.693 |
| Clothing      | 0.336 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 15:54:50,520 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 15:54:50,520 - mmdet - INFO - Epoch(val) [23][982]	bbox_mAP: 0.4530, bbox_mAP_50: 0.6180, bbox_mAP_75: 0.4870, bbox_mAP_s: 0.0050, bbox_mAP_m: 0.1590, bbox_mAP_l: 0.5170, bbox_mAP_copypaste: 0.453 0.618 0.487 0.005 0.159 0.517
2022-04-03 15:56:12,310 - mmdet - INFO - Epoch [24][50/976]	lr: 2.958e-05, eta: 5:25:22, time: 1.635, data_time: 0.065, memory: 25267, loss_rpn_cls: 0.0092, loss_rpn_bbox: 0.0181, s0.loss_cls: 0.1030, s0.acc: 96.2715, s0.loss_bbox: 0.0660, s1.loss_cls: 0.0352, s1.acc: 97.5195, s1.loss_bbox: 0.0432, s2.loss_cls: 0.0096, s2.acc: 98.7002, s2.loss_bbox: 0.0125, loss: 0.2968
2022-04-03 15:57:31,827 - mmdet - INFO - Epoch [24][100/976]	lr: 2.958e-05, eta: 5:24:32, time: 1.590, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0084, loss_rpn_bbox: 0.0167, s0.loss_cls: 0.0953, s0.acc: 96.5303, s0.loss_bbox: 0.0628, s1.loss_cls: 0.0323, s1.acc: 97.7197, s1.loss_bbox: 0.0419, s2.loss_cls: 0.0089, s2.acc: 98.7549, s2.loss_bbox: 0.0117, loss: 0.2780
2022-04-03 15:58:50,557 - mmdet - INFO - Epoch [24][150/976]	lr: 2.958e-05, eta: 5:23:30, time: 1.575, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0149, s0.loss_cls: 0.0817, s0.acc: 97.1201, s0.loss_bbox: 0.0495, s1.loss_cls: 0.0280, s1.acc: 98.0283, s1.loss_bbox: 0.0351, s2.loss_cls: 0.0072, s2.acc: 99.0332, s2.loss_bbox: 0.0091, loss: 0.2318
2022-04-03 16:00:09,914 - mmdet - INFO - Epoch [24][200/976]	lr: 2.958e-05, eta: 5:22:33, time: 1.587, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0172, s0.loss_cls: 0.0823, s0.acc: 96.9531, s0.loss_bbox: 0.0556, s1.loss_cls: 0.0282, s1.acc: 98.0303, s1.loss_bbox: 0.0356, s2.loss_cls: 0.0077, s2.acc: 98.9727, s2.loss_bbox: 0.0099, loss: 0.2449
2022-04-03 16:01:28,836 - mmdet - INFO - Epoch [24][250/976]	lr: 2.958e-05, eta: 5:21:30, time: 1.578, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0134, s0.loss_cls: 0.0773, s0.acc: 97.1768, s0.loss_bbox: 0.0501, s1.loss_cls: 0.0269, s1.acc: 98.0391, s1.loss_bbox: 0.0337, s2.loss_cls: 0.0072, s2.acc: 99.0225, s2.loss_bbox: 0.0098, loss: 0.2260
2022-04-03 16:02:47,849 - mmdet - INFO - Epoch [24][300/976]	lr: 2.958e-05, eta: 5:20:27, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.0953, s0.acc: 96.5068, s0.loss_bbox: 0.0636, s1.loss_cls: 0.0306, s1.acc: 97.7969, s1.loss_bbox: 0.0409, s2.loss_cls: 0.0083, s2.acc: 98.8242, s2.loss_bbox: 0.0109, loss: 0.2739
2022-04-03 16:04:06,488 - mmdet - INFO - Epoch [24][350/976]	lr: 2.958e-05, eta: 5:19:19, time: 1.573, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0140, s0.loss_cls: 0.0676, s0.acc: 97.4482, s0.loss_bbox: 0.0487, s1.loss_cls: 0.0230, s1.acc: 98.2559, s1.loss_bbox: 0.0322, s2.loss_cls: 0.0064, s2.acc: 99.0381, s2.loss_bbox: 0.0088, loss: 0.2078
2022-04-03 16:05:26,144 - mmdet - INFO - Epoch [24][400/976]	lr: 2.958e-05, eta: 5:18:19, time: 1.593, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0180, s0.loss_cls: 0.0912, s0.acc: 96.6650, s0.loss_bbox: 0.0618, s1.loss_cls: 0.0306, s1.acc: 97.8018, s1.loss_bbox: 0.0392, s2.loss_cls: 0.0084, s2.acc: 98.8105, s2.loss_bbox: 0.0107, loss: 0.2681
2022-04-03 16:06:45,594 - mmdet - INFO - Epoch [24][450/976]	lr: 2.958e-05, eta: 5:17:16, time: 1.589, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.0870, s0.acc: 96.8350, s0.loss_bbox: 0.0623, s1.loss_cls: 0.0301, s1.acc: 97.8203, s1.loss_bbox: 0.0396, s2.loss_cls: 0.0080, s2.acc: 98.8857, s2.loss_bbox: 0.0107, loss: 0.2627
2022-04-03 16:08:04,759 - mmdet - INFO - Epoch [24][500/976]	lr: 2.958e-05, eta: 5:16:10, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0142, s0.loss_cls: 0.0766, s0.acc: 97.1982, s0.loss_bbox: 0.0501, s1.loss_cls: 0.0246, s1.acc: 98.2188, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0063, s2.acc: 99.1074, s2.loss_bbox: 0.0087, loss: 0.2212
2022-04-03 16:09:24,312 - mmdet - INFO - Epoch [24][550/976]	lr: 2.958e-05, eta: 5:15:06, time: 1.591, data_time: 0.015, memory: 25267, loss_rpn_cls: 0.0093, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.0903, s0.acc: 96.6963, s0.loss_bbox: 0.0613, s1.loss_cls: 0.0280, s1.acc: 97.9609, s1.loss_bbox: 0.0361, s2.loss_cls: 0.0080, s2.acc: 98.8730, s2.loss_bbox: 0.0098, loss: 0.2589
2022-04-03 16:10:43,566 - mmdet - INFO - Epoch [24][600/976]	lr: 2.958e-05, eta: 5:13:58, time: 1.585, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0097, loss_rpn_bbox: 0.0155, s0.loss_cls: 0.0744, s0.acc: 97.3789, s0.loss_bbox: 0.0478, s1.loss_cls: 0.0255, s1.acc: 98.2559, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0067, s2.acc: 99.1045, s2.loss_bbox: 0.0077, loss: 0.2178
2022-04-03 16:12:03,191 - mmdet - INFO - Epoch [24][650/976]	lr: 2.958e-05, eta: 5:12:53, time: 1.593, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0085, loss_rpn_bbox: 0.0171, s0.loss_cls: 0.0912, s0.acc: 96.6729, s0.loss_bbox: 0.0641, s1.loss_cls: 0.0311, s1.acc: 97.7793, s1.loss_bbox: 0.0388, s2.loss_cls: 0.0086, s2.acc: 98.8174, s2.loss_bbox: 0.0107, loss: 0.2700
2022-04-03 16:13:22,462 - mmdet - INFO - Epoch [24][700/976]	lr: 2.958e-05, eta: 5:11:44, time: 1.585, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0167, s0.loss_cls: 0.0870, s0.acc: 96.7852, s0.loss_bbox: 0.0553, s1.loss_cls: 0.0296, s1.acc: 97.8906, s1.loss_bbox: 0.0364, s2.loss_cls: 0.0075, s2.acc: 98.9561, s2.loss_bbox: 0.0097, loss: 0.2504
2022-04-03 16:14:42,205 - mmdet - INFO - Epoch [24][750/976]	lr: 2.958e-05, eta: 5:10:38, time: 1.595, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0141, s0.loss_cls: 0.0793, s0.acc: 97.1289, s0.loss_bbox: 0.0540, s1.loss_cls: 0.0271, s1.acc: 98.0430, s1.loss_bbox: 0.0341, s2.loss_cls: 0.0072, s2.acc: 98.9824, s2.loss_bbox: 0.0094, loss: 0.2318
2022-04-03 16:16:01,662 - mmdet - INFO - Epoch [24][800/976]	lr: 2.958e-05, eta: 5:09:30, time: 1.589, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0168, s0.loss_cls: 0.0894, s0.acc: 96.6982, s0.loss_bbox: 0.0597, s1.loss_cls: 0.0322, s1.acc: 97.6748, s1.loss_bbox: 0.0403, s2.loss_cls: 0.0088, s2.acc: 98.8262, s2.loss_bbox: 0.0114, loss: 0.2672
2022-04-03 16:17:20,592 - mmdet - INFO - Epoch [24][850/976]	lr: 2.958e-05, eta: 5:08:17, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0074, loss_rpn_bbox: 0.0168, s0.loss_cls: 0.0808, s0.acc: 97.0879, s0.loss_bbox: 0.0545, s1.loss_cls: 0.0279, s1.acc: 97.9990, s1.loss_bbox: 0.0347, s2.loss_cls: 0.0076, s2.acc: 98.9795, s2.loss_bbox: 0.0100, loss: 0.2398
2022-04-03 16:18:39,356 - mmdet - INFO - Epoch [24][900/976]	lr: 2.958e-05, eta: 5:07:03, time: 1.575, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0085, loss_rpn_bbox: 0.0167, s0.loss_cls: 0.0842, s0.acc: 96.8291, s0.loss_bbox: 0.0573, s1.loss_cls: 0.0287, s1.acc: 97.8789, s1.loss_bbox: 0.0388, s2.loss_cls: 0.0075, s2.acc: 98.9180, s2.loss_bbox: 0.0105, loss: 0.2522
2022-04-03 16:19:57,983 - mmdet - INFO - Epoch [24][950/976]	lr: 2.958e-05, eta: 5:05:47, time: 1.573, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0791, s0.acc: 96.9805, s0.loss_bbox: 0.0581, s1.loss_cls: 0.0276, s1.acc: 97.9170, s1.loss_bbox: 0.0386, s2.loss_cls: 0.0077, s2.acc: 98.9209, s2.loss_bbox: 0.0106, loss: 0.2452
2022-04-03 16:20:39,252 - mmdet - INFO - Saving checkpoint at 24 epochs
2022-04-03 16:23:05,941 - mmdet - INFO - Evaluating bbox...
2022-04-03 16:23:12,485 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.623
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.522
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.127
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.382
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.667

2022-04-03 16:23:12,486 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.270 | Paper       | 0.329 | Paper pack | 0.506 |
| Metal         | 0.533 | Glass       | 0.469 | Plastic    | 0.412 |
| Styrofoam     | 0.418 | Plastic bag | 0.570 | Battery    | 0.703 |
| Clothing      | 0.376 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 16:23:12,567 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 16:23:12,568 - mmdet - INFO - Epoch(val) [24][982]	bbox_mAP: 0.4590, bbox_mAP_50: 0.6230, bbox_mAP_75: 0.4910, bbox_mAP_s: 0.0060, bbox_mAP_m: 0.1660, bbox_mAP_l: 0.5220, bbox_mAP_copypaste: 0.459 0.623 0.491 0.006 0.166 0.522
2022-04-03 16:24:34,705 - mmdet - INFO - Epoch [25][50/976]	lr: 2.575e-05, eta: 5:00:15, time: 1.642, data_time: 0.064, memory: 25267, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0750, s0.acc: 97.2744, s0.loss_bbox: 0.0505, s1.loss_cls: 0.0248, s1.acc: 98.2432, s1.loss_bbox: 0.0328, s2.loss_cls: 0.0071, s2.acc: 99.0010, s2.loss_bbox: 0.0092, loss: 0.2220
2022-04-03 16:25:54,460 - mmdet - INFO - Epoch [25][100/976]	lr: 2.575e-05, eta: 4:59:12, time: 1.595, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0105, loss_rpn_bbox: 0.0183, s0.loss_cls: 0.0954, s0.acc: 96.5039, s0.loss_bbox: 0.0655, s1.loss_cls: 0.0342, s1.acc: 97.4043, s1.loss_bbox: 0.0457, s2.loss_cls: 0.0099, s2.acc: 98.6006, s2.loss_bbox: 0.0136, loss: 0.2932
2022-04-03 16:27:13,545 - mmdet - INFO - Epoch [25][150/976]	lr: 2.575e-05, eta: 4:58:04, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0171, s0.loss_cls: 0.0806, s0.acc: 97.0732, s0.loss_bbox: 0.0547, s1.loss_cls: 0.0280, s1.acc: 97.9238, s1.loss_bbox: 0.0363, s2.loss_cls: 0.0077, s2.acc: 98.9590, s2.loss_bbox: 0.0103, loss: 0.2425
2022-04-03 16:28:32,554 - mmdet - INFO - Epoch [25][200/976]	lr: 2.575e-05, eta: 4:56:56, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0176, s0.loss_cls: 0.0893, s0.acc: 96.7539, s0.loss_bbox: 0.0634, s1.loss_cls: 0.0302, s1.acc: 97.7871, s1.loss_bbox: 0.0412, s2.loss_cls: 0.0083, s2.acc: 98.8096, s2.loss_bbox: 0.0114, loss: 0.2692
2022-04-03 16:29:51,741 - mmdet - INFO - Epoch [25][250/976]	lr: 2.575e-05, eta: 4:55:48, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0107, loss_rpn_bbox: 0.0158, s0.loss_cls: 0.0844, s0.acc: 96.9502, s0.loss_bbox: 0.0555, s1.loss_cls: 0.0276, s1.acc: 98.0186, s1.loss_bbox: 0.0367, s2.loss_cls: 0.0076, s2.acc: 98.9463, s2.loss_bbox: 0.0104, loss: 0.2486
2022-04-03 16:31:11,154 - mmdet - INFO - Epoch [25][300/976]	lr: 2.575e-05, eta: 4:54:41, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.0788, s0.acc: 97.1104, s0.loss_bbox: 0.0520, s1.loss_cls: 0.0260, s1.acc: 98.1162, s1.loss_bbox: 0.0335, s2.loss_cls: 0.0069, s2.acc: 99.0391, s2.loss_bbox: 0.0089, loss: 0.2304
2022-04-03 16:32:31,436 - mmdet - INFO - Epoch [25][350/976]	lr: 2.575e-05, eta: 4:53:37, time: 1.606, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0104, loss_rpn_bbox: 0.0181, s0.loss_cls: 0.0957, s0.acc: 96.5332, s0.loss_bbox: 0.0654, s1.loss_cls: 0.0332, s1.acc: 97.6484, s1.loss_bbox: 0.0433, s2.loss_cls: 0.0090, s2.acc: 98.8027, s2.loss_bbox: 0.0117, loss: 0.2868
2022-04-03 16:33:51,167 - mmdet - INFO - Epoch [25][400/976]	lr: 2.575e-05, eta: 4:52:30, time: 1.595, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0126, s0.loss_cls: 0.0740, s0.acc: 97.2764, s0.loss_bbox: 0.0511, s1.loss_cls: 0.0243, s1.acc: 98.2402, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0064, s2.acc: 99.1152, s2.loss_bbox: 0.0083, loss: 0.2161
2022-04-03 16:35:10,383 - mmdet - INFO - Epoch [25][450/976]	lr: 2.575e-05, eta: 4:51:20, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0155, s0.loss_cls: 0.0872, s0.acc: 96.7930, s0.loss_bbox: 0.0597, s1.loss_cls: 0.0314, s1.acc: 97.6846, s1.loss_bbox: 0.0415, s2.loss_cls: 0.0088, s2.acc: 98.7266, s2.loss_bbox: 0.0117, loss: 0.2636
2022-04-03 16:36:29,895 - mmdet - INFO - Epoch [25][500/976]	lr: 2.575e-05, eta: 4:50:11, time: 1.590, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0183, s0.loss_cls: 0.0809, s0.acc: 96.9951, s0.loss_bbox: 0.0555, s1.loss_cls: 0.0297, s1.acc: 97.8359, s1.loss_bbox: 0.0379, s2.loss_cls: 0.0083, s2.acc: 98.8057, s2.loss_bbox: 0.0107, loss: 0.2495
2022-04-03 16:37:49,103 - mmdet - INFO - Epoch [25][550/976]	lr: 2.575e-05, eta: 4:49:01, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0122, s0.loss_cls: 0.0688, s0.acc: 97.4365, s0.loss_bbox: 0.0484, s1.loss_cls: 0.0228, s1.acc: 98.2793, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0061, s2.acc: 99.1016, s2.loss_bbox: 0.0084, loss: 0.2032
2022-04-03 16:39:08,451 - mmdet - INFO - Epoch [25][600/976]	lr: 2.575e-05, eta: 4:47:50, time: 1.587, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0165, s0.loss_cls: 0.0835, s0.acc: 96.8418, s0.loss_bbox: 0.0596, s1.loss_cls: 0.0298, s1.acc: 97.8789, s1.loss_bbox: 0.0386, s2.loss_cls: 0.0079, s2.acc: 98.9072, s2.loss_bbox: 0.0100, loss: 0.2546
2022-04-03 16:40:27,617 - mmdet - INFO - Epoch [25][650/976]	lr: 2.575e-05, eta: 4:46:39, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0074, loss_rpn_bbox: 0.0121, s0.loss_cls: 0.0665, s0.acc: 97.5605, s0.loss_bbox: 0.0447, s1.loss_cls: 0.0218, s1.acc: 98.4014, s1.loss_bbox: 0.0271, s2.loss_cls: 0.0056, s2.acc: 99.1787, s2.loss_bbox: 0.0075, loss: 0.1928
2022-04-03 16:41:47,038 - mmdet - INFO - Epoch [25][700/976]	lr: 2.575e-05, eta: 4:45:28, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0161, s0.loss_cls: 0.0753, s0.acc: 97.2051, s0.loss_bbox: 0.0529, s1.loss_cls: 0.0247, s1.acc: 98.2334, s1.loss_bbox: 0.0327, s2.loss_cls: 0.0068, s2.acc: 99.0342, s2.loss_bbox: 0.0092, loss: 0.2247
2022-04-03 16:43:06,191 - mmdet - INFO - Epoch [25][750/976]	lr: 2.575e-05, eta: 4:44:16, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0146, s0.loss_cls: 0.0764, s0.acc: 97.1221, s0.loss_bbox: 0.0525, s1.loss_cls: 0.0252, s1.acc: 98.1572, s1.loss_bbox: 0.0322, s2.loss_cls: 0.0067, s2.acc: 99.0723, s2.loss_bbox: 0.0087, loss: 0.2230
2022-04-03 16:44:25,222 - mmdet - INFO - Epoch [25][800/976]	lr: 2.575e-05, eta: 4:43:03, time: 1.581, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0086, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.0833, s0.acc: 96.9951, s0.loss_bbox: 0.0528, s1.loss_cls: 0.0277, s1.acc: 98.0527, s1.loss_bbox: 0.0351, s2.loss_cls: 0.0080, s2.acc: 98.9346, s2.loss_bbox: 0.0101, loss: 0.2417
2022-04-03 16:45:45,127 - mmdet - INFO - Epoch [25][850/976]	lr: 2.575e-05, eta: 4:41:53, time: 1.598, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0161, s0.loss_cls: 0.0716, s0.acc: 97.2812, s0.loss_bbox: 0.0483, s1.loss_cls: 0.0250, s1.acc: 98.1416, s1.loss_bbox: 0.0323, s2.loss_cls: 0.0070, s2.acc: 98.9854, s2.loss_bbox: 0.0092, loss: 0.2175
2022-04-03 16:47:04,307 - mmdet - INFO - Epoch [25][900/976]	lr: 2.575e-05, eta: 4:40:40, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0143, s0.loss_cls: 0.0726, s0.acc: 97.2852, s0.loss_bbox: 0.0525, s1.loss_cls: 0.0247, s1.acc: 98.1406, s1.loss_bbox: 0.0340, s2.loss_cls: 0.0064, s2.acc: 99.0498, s2.loss_bbox: 0.0092, loss: 0.2206
2022-04-03 16:48:23,588 - mmdet - INFO - Epoch [25][950/976]	lr: 2.575e-05, eta: 4:39:28, time: 1.586, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0149, s0.loss_cls: 0.0742, s0.acc: 97.2236, s0.loss_bbox: 0.0505, s1.loss_cls: 0.0267, s1.acc: 98.0371, s1.loss_bbox: 0.0354, s2.loss_cls: 0.0073, s2.acc: 98.9805, s2.loss_bbox: 0.0100, loss: 0.2273
2022-04-03 16:49:05,030 - mmdet - INFO - Saving checkpoint at 25 epochs
2022-04-03 16:51:32,164 - mmdet - INFO - Evaluating bbox...
2022-04-03 16:51:38,503 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.627
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.010
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.163
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.149
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.666

2022-04-03 16:51:38,504 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.271 | Paper       | 0.334 | Paper pack | 0.516 |
| Metal         | 0.534 | Glass       | 0.458 | Plastic    | 0.422 |
| Styrofoam     | 0.415 | Plastic bag | 0.569 | Battery    | 0.726 |
| Clothing      | 0.366 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 16:51:38,584 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 16:51:38,584 - mmdet - INFO - Epoch(val) [25][982]	bbox_mAP: 0.4610, bbox_mAP_50: 0.6270, bbox_mAP_75: 0.4960, bbox_mAP_s: 0.0100, bbox_mAP_m: 0.1630, bbox_mAP_l: 0.5260, bbox_mAP_copypaste: 0.461 0.627 0.496 0.010 0.163 0.526
2022-04-03 16:53:00,620 - mmdet - INFO - Epoch [26][50/976]	lr: 2.211e-05, eta: 4:35:19, time: 1.640, data_time: 0.064, memory: 25267, loss_rpn_cls: 0.0074, loss_rpn_bbox: 0.0140, s0.loss_cls: 0.0826, s0.acc: 97.1143, s0.loss_bbox: 0.0560, s1.loss_cls: 0.0276, s1.acc: 98.0488, s1.loss_bbox: 0.0344, s2.loss_cls: 0.0074, s2.acc: 99.0010, s2.loss_bbox: 0.0091, loss: 0.2386
2022-04-03 16:54:20,543 - mmdet - INFO - Epoch [26][100/976]	lr: 2.211e-05, eta: 4:34:11, time: 1.598, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0149, s0.loss_cls: 0.0754, s0.acc: 97.1855, s0.loss_bbox: 0.0532, s1.loss_cls: 0.0269, s1.acc: 98.0166, s1.loss_bbox: 0.0360, s2.loss_cls: 0.0071, s2.acc: 98.9814, s2.loss_bbox: 0.0103, loss: 0.2302
2022-04-03 16:55:40,199 - mmdet - INFO - Epoch [26][150/976]	lr: 2.211e-05, eta: 4:33:01, time: 1.593, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0139, s0.loss_cls: 0.0864, s0.acc: 96.9004, s0.loss_bbox: 0.0587, s1.loss_cls: 0.0290, s1.acc: 97.9316, s1.loss_bbox: 0.0383, s2.loss_cls: 0.0080, s2.acc: 98.8945, s2.loss_bbox: 0.0103, loss: 0.2527
2022-04-03 16:56:59,613 - mmdet - INFO - Epoch [26][200/976]	lr: 2.211e-05, eta: 4:31:51, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0161, s0.loss_cls: 0.0763, s0.acc: 97.1338, s0.loss_bbox: 0.0541, s1.loss_cls: 0.0266, s1.acc: 97.9902, s1.loss_bbox: 0.0342, s2.loss_cls: 0.0073, s2.acc: 98.9775, s2.loss_bbox: 0.0091, loss: 0.2320
2022-04-03 16:58:19,200 - mmdet - INFO - Epoch [26][250/976]	lr: 2.211e-05, eta: 4:30:40, time: 1.592, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0072, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0720, s0.acc: 97.2920, s0.loss_bbox: 0.0471, s1.loss_cls: 0.0246, s1.acc: 98.1709, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0066, s2.acc: 99.0596, s2.loss_bbox: 0.0088, loss: 0.2117
2022-04-03 16:59:39,037 - mmdet - INFO - Epoch [26][300/976]	lr: 2.211e-05, eta: 4:29:31, time: 1.597, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0124, s0.loss_cls: 0.0600, s0.acc: 97.6777, s0.loss_bbox: 0.0465, s1.loss_cls: 0.0208, s1.acc: 98.4238, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0057, s2.acc: 99.1816, s2.loss_bbox: 0.0081, loss: 0.1890
2022-04-03 17:00:58,530 - mmdet - INFO - Epoch [26][350/976]	lr: 2.211e-05, eta: 4:28:20, time: 1.590, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0698, s0.acc: 97.4062, s0.loss_bbox: 0.0484, s1.loss_cls: 0.0232, s1.acc: 98.3262, s1.loss_bbox: 0.0304, s2.loss_cls: 0.0063, s2.acc: 99.0791, s2.loss_bbox: 0.0092, loss: 0.2070
2022-04-03 17:02:17,698 - mmdet - INFO - Epoch [26][400/976]	lr: 2.211e-05, eta: 4:27:07, time: 1.583, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.0867, s0.acc: 96.8242, s0.loss_bbox: 0.0601, s1.loss_cls: 0.0282, s1.acc: 97.9131, s1.loss_bbox: 0.0357, s2.loss_cls: 0.0076, s2.acc: 98.9150, s2.loss_bbox: 0.0096, loss: 0.2520
2022-04-03 17:03:37,213 - mmdet - INFO - Epoch [26][450/976]	lr: 2.211e-05, eta: 4:25:56, time: 1.590, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0127, s0.loss_cls: 0.0721, s0.acc: 97.2637, s0.loss_bbox: 0.0489, s1.loss_cls: 0.0245, s1.acc: 98.1826, s1.loss_bbox: 0.0328, s2.loss_cls: 0.0065, s2.acc: 99.0674, s2.loss_bbox: 0.0095, loss: 0.2124
2022-04-03 17:04:56,720 - mmdet - INFO - Epoch [26][500/976]	lr: 2.211e-05, eta: 4:24:44, time: 1.590, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0181, s0.loss_cls: 0.0972, s0.acc: 96.2998, s0.loss_bbox: 0.0690, s1.loss_cls: 0.0333, s1.acc: 97.5420, s1.loss_bbox: 0.0446, s2.loss_cls: 0.0094, s2.acc: 98.6445, s2.loss_bbox: 0.0127, loss: 0.2933
2022-04-03 17:06:16,209 - mmdet - INFO - Epoch [26][550/976]	lr: 2.211e-05, eta: 4:23:32, time: 1.590, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0129, s0.loss_cls: 0.0720, s0.acc: 97.2949, s0.loss_bbox: 0.0487, s1.loss_cls: 0.0231, s1.acc: 98.3008, s1.loss_bbox: 0.0315, s2.loss_cls: 0.0064, s2.acc: 99.0977, s2.loss_bbox: 0.0086, loss: 0.2114
2022-04-03 17:07:35,989 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 17:07:35,990 - mmdet - INFO - Epoch [26][600/976]	lr: 2.211e-05, eta: 4:22:21, time: 1.596, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.0880, s0.acc: 96.6865, s0.loss_bbox: 0.0586, s1.loss_cls: 0.0308, s1.acc: 97.7461, s1.loss_bbox: 0.0395, s2.loss_cls: 0.0086, s2.acc: 98.7207, s2.loss_bbox: 0.0121, loss: 0.2601
2022-04-03 17:08:55,740 - mmdet - INFO - Epoch [26][650/976]	lr: 2.211e-05, eta: 4:21:09, time: 1.595, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0084, loss_rpn_bbox: 0.0148, s0.loss_cls: 0.0605, s0.acc: 97.6904, s0.loss_bbox: 0.0416, s1.loss_cls: 0.0206, s1.acc: 98.4746, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0055, s2.acc: 99.1934, s2.loss_bbox: 0.0078, loss: 0.1881
2022-04-03 17:10:14,773 - mmdet - INFO - Epoch [26][700/976]	lr: 2.211e-05, eta: 4:19:55, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0699, s0.acc: 97.3691, s0.loss_bbox: 0.0495, s1.loss_cls: 0.0241, s1.acc: 98.1904, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0062, s2.acc: 99.0889, s2.loss_bbox: 0.0087, loss: 0.2096
2022-04-03 17:11:34,168 - mmdet - INFO - Epoch [26][750/976]	lr: 2.211e-05, eta: 4:18:42, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0106, loss_rpn_bbox: 0.0185, s0.loss_cls: 0.0835, s0.acc: 96.9590, s0.loss_bbox: 0.0591, s1.loss_cls: 0.0293, s1.acc: 97.9326, s1.loss_bbox: 0.0387, s2.loss_cls: 0.0082, s2.acc: 98.8711, s2.loss_bbox: 0.0105, loss: 0.2584
2022-04-03 17:12:53,990 - mmdet - INFO - Epoch [26][800/976]	lr: 2.211e-05, eta: 4:17:30, time: 1.596, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0174, s0.loss_cls: 0.0906, s0.acc: 96.6699, s0.loss_bbox: 0.0609, s1.loss_cls: 0.0313, s1.acc: 97.7451, s1.loss_bbox: 0.0404, s2.loss_cls: 0.0084, s2.acc: 98.7627, s2.loss_bbox: 0.0116, loss: 0.2666
2022-04-03 17:14:13,307 - mmdet - INFO - Epoch [26][850/976]	lr: 2.211e-05, eta: 4:16:16, time: 1.586, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0145, s0.loss_cls: 0.0784, s0.acc: 97.1270, s0.loss_bbox: 0.0515, s1.loss_cls: 0.0266, s1.acc: 98.0439, s1.loss_bbox: 0.0341, s2.loss_cls: 0.0071, s2.acc: 98.9697, s2.loss_bbox: 0.0096, loss: 0.2278
2022-04-03 17:15:32,719 - mmdet - INFO - Epoch [26][900/976]	lr: 2.211e-05, eta: 4:15:02, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0760, s0.acc: 97.2607, s0.loss_bbox: 0.0525, s1.loss_cls: 0.0256, s1.acc: 98.1562, s1.loss_bbox: 0.0349, s2.loss_cls: 0.0066, s2.acc: 99.1172, s2.loss_bbox: 0.0091, loss: 0.2284
2022-04-03 17:16:52,356 - mmdet - INFO - Epoch [26][950/976]	lr: 2.211e-05, eta: 4:13:49, time: 1.593, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0147, s0.loss_cls: 0.0757, s0.acc: 97.0889, s0.loss_bbox: 0.0528, s1.loss_cls: 0.0262, s1.acc: 98.0000, s1.loss_bbox: 0.0363, s2.loss_cls: 0.0070, s2.acc: 98.9941, s2.loss_bbox: 0.0107, loss: 0.2306
2022-04-03 17:17:33,531 - mmdet - INFO - Saving checkpoint at 26 epochs
2022-04-03 17:20:00,488 - mmdet - INFO - Evaluating bbox...
2022-04-03 17:20:06,610 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.629
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.664

2022-04-03 17:20:06,611 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.278 | Paper       | 0.327 | Paper pack | 0.534 |
| Metal         | 0.540 | Glass       | 0.474 | Plastic    | 0.413 |
| Styrofoam     | 0.426 | Plastic bag | 0.571 | Battery    | 0.718 |
| Clothing      | 0.381 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 17:20:06,684 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 17:20:06,684 - mmdet - INFO - Epoch(val) [26][982]	bbox_mAP: 0.4660, bbox_mAP_50: 0.6290, bbox_mAP_75: 0.4950, bbox_mAP_s: 0.0070, bbox_mAP_m: 0.1710, bbox_mAP_l: 0.5310, bbox_mAP_copypaste: 0.466 0.629 0.495 0.007 0.171 0.531
2022-04-03 17:21:28,864 - mmdet - INFO - Epoch [27][50/976]	lr: 1.868e-05, eta: 4:10:22, time: 1.643, data_time: 0.064, memory: 25267, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0148, s0.loss_cls: 0.0784, s0.acc: 97.1104, s0.loss_bbox: 0.0576, s1.loss_cls: 0.0274, s1.acc: 98.0039, s1.loss_bbox: 0.0378, s2.loss_cls: 0.0076, s2.acc: 98.9834, s2.loss_bbox: 0.0100, loss: 0.2425
2022-04-03 17:22:47,978 - mmdet - INFO - Epoch [27][100/976]	lr: 1.868e-05, eta: 4:09:09, time: 1.582, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0108, s0.loss_cls: 0.0671, s0.acc: 97.5518, s0.loss_bbox: 0.0432, s1.loss_cls: 0.0221, s1.acc: 98.3916, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0061, s2.acc: 99.1260, s2.loss_bbox: 0.0083, loss: 0.1917
2022-04-03 17:24:07,285 - mmdet - INFO - Epoch [27][150/976]	lr: 1.868e-05, eta: 4:07:56, time: 1.586, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0679, s0.acc: 97.4375, s0.loss_bbox: 0.0494, s1.loss_cls: 0.0244, s1.acc: 98.1621, s1.loss_bbox: 0.0337, s2.loss_cls: 0.0065, s2.acc: 99.0791, s2.loss_bbox: 0.0093, loss: 0.2131
2022-04-03 17:25:26,409 - mmdet - INFO - Epoch [27][200/976]	lr: 1.868e-05, eta: 4:06:43, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.0760, s0.acc: 97.1270, s0.loss_bbox: 0.0505, s1.loss_cls: 0.0259, s1.acc: 98.0381, s1.loss_bbox: 0.0357, s2.loss_cls: 0.0067, s2.acc: 99.0039, s2.loss_bbox: 0.0095, loss: 0.2252
2022-04-03 17:26:45,442 - mmdet - INFO - Epoch [27][250/976]	lr: 1.868e-05, eta: 4:05:29, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0152, s0.loss_cls: 0.0717, s0.acc: 97.2793, s0.loss_bbox: 0.0505, s1.loss_cls: 0.0253, s1.acc: 98.1250, s1.loss_bbox: 0.0347, s2.loss_cls: 0.0072, s2.acc: 98.9785, s2.loss_bbox: 0.0104, loss: 0.2238
2022-04-03 17:28:04,869 - mmdet - INFO - Epoch [27][300/976]	lr: 1.868e-05, eta: 4:04:16, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0086, loss_rpn_bbox: 0.0184, s0.loss_cls: 0.0873, s0.acc: 96.8662, s0.loss_bbox: 0.0583, s1.loss_cls: 0.0302, s1.acc: 97.8691, s1.loss_bbox: 0.0383, s2.loss_cls: 0.0084, s2.acc: 98.8740, s2.loss_bbox: 0.0107, loss: 0.2603
2022-04-03 17:29:23,922 - mmdet - INFO - Epoch [27][350/976]	lr: 1.868e-05, eta: 4:03:02, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0148, s0.loss_cls: 0.0781, s0.acc: 97.1133, s0.loss_bbox: 0.0544, s1.loss_cls: 0.0266, s1.acc: 98.0234, s1.loss_bbox: 0.0351, s2.loss_cls: 0.0071, s2.acc: 99.0010, s2.loss_bbox: 0.0096, loss: 0.2321
2022-04-03 17:30:43,312 - mmdet - INFO - Epoch [27][400/976]	lr: 1.868e-05, eta: 4:01:49, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0175, s0.loss_cls: 0.0846, s0.acc: 96.7832, s0.loss_bbox: 0.0596, s1.loss_cls: 0.0289, s1.acc: 97.8350, s1.loss_bbox: 0.0390, s2.loss_cls: 0.0078, s2.acc: 98.8721, s2.loss_bbox: 0.0107, loss: 0.2562
2022-04-03 17:32:02,378 - mmdet - INFO - Epoch [27][450/976]	lr: 1.868e-05, eta: 4:00:35, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.0705, s0.acc: 97.3545, s0.loss_bbox: 0.0519, s1.loss_cls: 0.0244, s1.acc: 98.1855, s1.loss_bbox: 0.0353, s2.loss_cls: 0.0070, s2.acc: 98.9736, s2.loss_bbox: 0.0100, loss: 0.2213
2022-04-03 17:33:21,432 - mmdet - INFO - Epoch [27][500/976]	lr: 1.868e-05, eta: 3:59:20, time: 1.581, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0149, s0.loss_cls: 0.0786, s0.acc: 97.0381, s0.loss_bbox: 0.0577, s1.loss_cls: 0.0283, s1.acc: 97.8750, s1.loss_bbox: 0.0386, s2.loss_cls: 0.0077, s2.acc: 98.8809, s2.loss_bbox: 0.0108, loss: 0.2442
2022-04-03 17:34:40,441 - mmdet - INFO - Epoch [27][550/976]	lr: 1.868e-05, eta: 3:58:06, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.0758, s0.acc: 97.1230, s0.loss_bbox: 0.0559, s1.loss_cls: 0.0263, s1.acc: 98.0166, s1.loss_bbox: 0.0367, s2.loss_cls: 0.0072, s2.acc: 98.9629, s2.loss_bbox: 0.0100, loss: 0.2346
2022-04-03 17:35:59,438 - mmdet - INFO - Epoch [27][600/976]	lr: 1.868e-05, eta: 3:56:51, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0113, s0.loss_cls: 0.0643, s0.acc: 97.5713, s0.loss_bbox: 0.0441, s1.loss_cls: 0.0220, s1.acc: 98.3301, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0056, s2.acc: 99.1807, s2.loss_bbox: 0.0075, loss: 0.1896
2022-04-03 17:37:19,107 - mmdet - INFO - Epoch [27][650/976]	lr: 1.868e-05, eta: 3:55:38, time: 1.593, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0153, s0.loss_cls: 0.0800, s0.acc: 97.0576, s0.loss_bbox: 0.0555, s1.loss_cls: 0.0286, s1.acc: 97.9385, s1.loss_bbox: 0.0383, s2.loss_cls: 0.0078, s2.acc: 98.9414, s2.loss_bbox: 0.0107, loss: 0.2447
2022-04-03 17:38:38,283 - mmdet - INFO - Epoch [27][700/976]	lr: 1.868e-05, eta: 3:54:23, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0123, s0.loss_cls: 0.0553, s0.acc: 97.8877, s0.loss_bbox: 0.0361, s1.loss_cls: 0.0193, s1.acc: 98.5576, s1.loss_bbox: 0.0246, s2.loss_cls: 0.0055, s2.acc: 99.2031, s2.loss_bbox: 0.0075, loss: 0.1677
2022-04-03 17:39:57,371 - mmdet - INFO - Epoch [27][750/976]	lr: 1.868e-05, eta: 3:53:09, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0128, s0.loss_cls: 0.0628, s0.acc: 97.6523, s0.loss_bbox: 0.0425, s1.loss_cls: 0.0219, s1.acc: 98.4307, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0057, s2.acc: 99.2041, s2.loss_bbox: 0.0081, loss: 0.1889
2022-04-03 17:41:16,333 - mmdet - INFO - Epoch [27][800/976]	lr: 1.868e-05, eta: 3:51:54, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0171, s0.loss_cls: 0.0823, s0.acc: 96.9648, s0.loss_bbox: 0.0614, s1.loss_cls: 0.0289, s1.acc: 97.9131, s1.loss_bbox: 0.0398, s2.loss_cls: 0.0078, s2.acc: 98.9053, s2.loss_bbox: 0.0110, loss: 0.2552
2022-04-03 17:42:35,349 - mmdet - INFO - Epoch [27][850/976]	lr: 1.868e-05, eta: 3:50:39, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0132, s0.loss_cls: 0.0639, s0.acc: 97.5400, s0.loss_bbox: 0.0454, s1.loss_cls: 0.0225, s1.acc: 98.2949, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0061, s2.acc: 99.1172, s2.loss_bbox: 0.0085, loss: 0.1953
2022-04-03 17:43:54,281 - mmdet - INFO - Epoch [27][900/976]	lr: 1.868e-05, eta: 3:49:23, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0142, s0.loss_cls: 0.0809, s0.acc: 97.1504, s0.loss_bbox: 0.0546, s1.loss_cls: 0.0275, s1.acc: 98.0830, s1.loss_bbox: 0.0359, s2.loss_cls: 0.0075, s2.acc: 98.9805, s2.loss_bbox: 0.0096, loss: 0.2389
2022-04-03 17:45:12,996 - mmdet - INFO - Epoch [27][950/976]	lr: 1.868e-05, eta: 3:48:07, time: 1.574, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0126, s0.loss_cls: 0.0680, s0.acc: 97.4951, s0.loss_bbox: 0.0473, s1.loss_cls: 0.0220, s1.acc: 98.3760, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0053, s2.acc: 99.2334, s2.loss_bbox: 0.0073, loss: 0.1979
2022-04-03 17:45:54,025 - mmdet - INFO - Saving checkpoint at 27 epochs
2022-04-03 17:48:20,530 - mmdet - INFO - Evaluating bbox...
2022-04-03 17:48:26,526 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.636
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.503
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.012
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.181
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.188
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.666

2022-04-03 17:48:26,527 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.277 | Paper       | 0.341 | Paper pack | 0.530 |
| Metal         | 0.543 | Glass       | 0.481 | Plastic    | 0.425 |
| Styrofoam     | 0.431 | Plastic bag | 0.577 | Battery    | 0.726 |
| Clothing      | 0.375 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 17:48:26,605 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 17:48:26,605 - mmdet - INFO - Epoch(val) [27][982]	bbox_mAP: 0.4700, bbox_mAP_50: 0.6360, bbox_mAP_75: 0.5030, bbox_mAP_s: 0.0120, bbox_mAP_m: 0.1810, bbox_mAP_l: 0.5350, bbox_mAP_copypaste: 0.470 0.636 0.503 0.012 0.181 0.535
2022-04-03 17:49:48,950 - mmdet - INFO - Epoch [28][50/976]	lr: 1.550e-05, eta: 3:45:06, time: 1.647, data_time: 0.064, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0138, s0.loss_cls: 0.0672, s0.acc: 97.5264, s0.loss_bbox: 0.0492, s1.loss_cls: 0.0226, s1.acc: 98.3711, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0062, s2.acc: 99.1084, s2.loss_bbox: 0.0092, loss: 0.2055
2022-04-03 17:51:07,926 - mmdet - INFO - Epoch [28][100/976]	lr: 1.550e-05, eta: 3:43:52, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0136, s0.loss_cls: 0.0651, s0.acc: 97.4316, s0.loss_bbox: 0.0487, s1.loss_cls: 0.0236, s1.acc: 98.2168, s1.loss_bbox: 0.0343, s2.loss_cls: 0.0061, s2.acc: 99.0957, s2.loss_bbox: 0.0095, loss: 0.2066
2022-04-03 17:52:27,592 - mmdet - INFO - Epoch [28][150/976]	lr: 1.550e-05, eta: 3:42:38, time: 1.593, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0158, s0.loss_cls: 0.0762, s0.acc: 97.2324, s0.loss_bbox: 0.0530, s1.loss_cls: 0.0279, s1.acc: 97.9121, s1.loss_bbox: 0.0385, s2.loss_cls: 0.0081, s2.acc: 98.8320, s2.loss_bbox: 0.0115, loss: 0.2380
2022-04-03 17:53:46,372 - mmdet - INFO - Epoch [28][200/976]	lr: 1.550e-05, eta: 3:41:23, time: 1.576, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0118, s0.loss_cls: 0.0604, s0.acc: 97.7217, s0.loss_bbox: 0.0409, s1.loss_cls: 0.0197, s1.acc: 98.5498, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0047, s2.acc: 99.3213, s2.loss_bbox: 0.0071, loss: 0.1763
2022-04-03 17:55:05,623 - mmdet - INFO - Epoch [28][250/976]	lr: 1.550e-05, eta: 3:40:09, time: 1.585, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0095, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0790, s0.acc: 97.0547, s0.loss_bbox: 0.0565, s1.loss_cls: 0.0259, s1.acc: 98.0957, s1.loss_bbox: 0.0365, s2.loss_cls: 0.0071, s2.acc: 99.0098, s2.loss_bbox: 0.0098, loss: 0.2401
2022-04-03 17:56:25,255 - mmdet - INFO - Epoch [28][300/976]	lr: 1.550e-05, eta: 3:38:55, time: 1.593, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0074, loss_rpn_bbox: 0.0168, s0.loss_cls: 0.0735, s0.acc: 97.2754, s0.loss_bbox: 0.0500, s1.loss_cls: 0.0274, s1.acc: 97.9854, s1.loss_bbox: 0.0356, s2.loss_cls: 0.0074, s2.acc: 98.9209, s2.loss_bbox: 0.0096, loss: 0.2278
2022-04-03 17:57:44,508 - mmdet - INFO - Epoch [28][350/976]	lr: 1.550e-05, eta: 3:37:41, time: 1.585, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0140, s0.loss_cls: 0.0779, s0.acc: 97.1084, s0.loss_bbox: 0.0565, s1.loss_cls: 0.0281, s1.acc: 97.9150, s1.loss_bbox: 0.0391, s2.loss_cls: 0.0077, s2.acc: 98.8643, s2.loss_bbox: 0.0113, loss: 0.2420
2022-04-03 17:59:03,865 - mmdet - INFO - Epoch [28][400/976]	lr: 1.550e-05, eta: 3:36:26, time: 1.587, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0147, s0.loss_cls: 0.0677, s0.acc: 97.4502, s0.loss_bbox: 0.0487, s1.loss_cls: 0.0239, s1.acc: 98.2354, s1.loss_bbox: 0.0335, s2.loss_cls: 0.0070, s2.acc: 98.9648, s2.loss_bbox: 0.0101, loss: 0.2111
2022-04-03 18:00:23,321 - mmdet - INFO - Epoch [28][450/976]	lr: 1.550e-05, eta: 3:35:12, time: 1.589, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0144, s0.loss_cls: 0.0733, s0.acc: 97.2275, s0.loss_bbox: 0.0532, s1.loss_cls: 0.0255, s1.acc: 98.1016, s1.loss_bbox: 0.0365, s2.loss_cls: 0.0067, s2.acc: 98.9814, s2.loss_bbox: 0.0096, loss: 0.2244
2022-04-03 18:01:42,231 - mmdet - INFO - Epoch [28][500/976]	lr: 1.550e-05, eta: 3:33:57, time: 1.578, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.0799, s0.acc: 96.9980, s0.loss_bbox: 0.0570, s1.loss_cls: 0.0292, s1.acc: 97.8242, s1.loss_bbox: 0.0401, s2.loss_cls: 0.0087, s2.acc: 98.7539, s2.loss_bbox: 0.0122, loss: 0.2503
2022-04-03 18:03:00,885 - mmdet - INFO - Epoch [28][550/976]	lr: 1.550e-05, eta: 3:32:41, time: 1.573, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0168, s0.loss_cls: 0.0734, s0.acc: 97.2354, s0.loss_bbox: 0.0539, s1.loss_cls: 0.0265, s1.acc: 98.0420, s1.loss_bbox: 0.0374, s2.loss_cls: 0.0068, s2.acc: 99.0029, s2.loss_bbox: 0.0101, loss: 0.2310
2022-04-03 18:04:20,137 - mmdet - INFO - Epoch [28][600/976]	lr: 1.550e-05, eta: 3:31:26, time: 1.585, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0122, s0.loss_cls: 0.0627, s0.acc: 97.6621, s0.loss_bbox: 0.0449, s1.loss_cls: 0.0205, s1.acc: 98.4932, s1.loss_bbox: 0.0274, s2.loss_cls: 0.0055, s2.acc: 99.2227, s2.loss_bbox: 0.0078, loss: 0.1861
2022-04-03 18:05:39,192 - mmdet - INFO - Epoch [28][650/976]	lr: 1.550e-05, eta: 3:30:11, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0135, s0.loss_cls: 0.0667, s0.acc: 97.4736, s0.loss_bbox: 0.0463, s1.loss_cls: 0.0231, s1.acc: 98.2227, s1.loss_bbox: 0.0324, s2.loss_cls: 0.0062, s2.acc: 99.0801, s2.loss_bbox: 0.0091, loss: 0.2026
2022-04-03 18:06:58,870 - mmdet - INFO - Epoch [28][700/976]	lr: 1.550e-05, eta: 3:28:57, time: 1.594, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0139, s0.loss_cls: 0.0714, s0.acc: 97.4150, s0.loss_bbox: 0.0501, s1.loss_cls: 0.0254, s1.acc: 98.1904, s1.loss_bbox: 0.0327, s2.loss_cls: 0.0067, s2.acc: 99.0547, s2.loss_bbox: 0.0096, loss: 0.2165
2022-04-03 18:08:18,352 - mmdet - INFO - Epoch [28][750/976]	lr: 1.550e-05, eta: 3:27:42, time: 1.590, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0158, s0.loss_cls: 0.0718, s0.acc: 97.2773, s0.loss_bbox: 0.0508, s1.loss_cls: 0.0258, s1.acc: 98.0615, s1.loss_bbox: 0.0353, s2.loss_cls: 0.0074, s2.acc: 98.9346, s2.loss_bbox: 0.0106, loss: 0.2236
2022-04-03 18:09:37,767 - mmdet - INFO - Epoch [28][800/976]	lr: 1.550e-05, eta: 3:26:27, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0131, s0.loss_cls: 0.0616, s0.acc: 97.6221, s0.loss_bbox: 0.0471, s1.loss_cls: 0.0201, s1.acc: 98.4961, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0054, s2.acc: 99.1875, s2.loss_bbox: 0.0077, loss: 0.1883
2022-04-03 18:10:56,911 - mmdet - INFO - Epoch [28][850/976]	lr: 1.550e-05, eta: 3:25:11, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0146, s0.loss_cls: 0.0692, s0.acc: 97.4463, s0.loss_bbox: 0.0491, s1.loss_cls: 0.0236, s1.acc: 98.2812, s1.loss_bbox: 0.0316, s2.loss_cls: 0.0067, s2.acc: 99.0850, s2.loss_bbox: 0.0092, loss: 0.2108
2022-04-03 18:12:15,518 - mmdet - INFO - Epoch [28][900/976]	lr: 1.550e-05, eta: 3:23:55, time: 1.572, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0099, s0.loss_cls: 0.0605, s0.acc: 97.6885, s0.loss_bbox: 0.0425, s1.loss_cls: 0.0205, s1.acc: 98.4922, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0057, s2.acc: 99.1836, s2.loss_bbox: 0.0083, loss: 0.1792
2022-04-03 18:13:35,007 - mmdet - INFO - Epoch [28][950/976]	lr: 1.550e-05, eta: 3:22:40, time: 1.590, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0168, s0.loss_cls: 0.0834, s0.acc: 96.9697, s0.loss_bbox: 0.0577, s1.loss_cls: 0.0299, s1.acc: 97.8496, s1.loss_bbox: 0.0412, s2.loss_cls: 0.0084, s2.acc: 98.7969, s2.loss_bbox: 0.0116, loss: 0.2565
2022-04-03 18:14:16,209 - mmdet - INFO - Saving checkpoint at 28 epochs
2022-04-03 18:16:42,667 - mmdet - INFO - Evaluating bbox...
2022-04-03 18:16:48,405 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.632
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.180
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.077
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.385
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.662

2022-04-03 18:16:48,406 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.273 | Paper       | 0.340 | Paper pack | 0.532 |
| Metal         | 0.535 | Glass       | 0.475 | Plastic    | 0.429 |
| Styrofoam     | 0.442 | Plastic bag | 0.580 | Battery    | 0.694 |
| Clothing      | 0.392 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 18:16:48,474 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 18:16:48,474 - mmdet - INFO - Epoch(val) [28][982]	bbox_mAP: 0.4690, bbox_mAP_50: 0.6320, bbox_mAP_75: 0.5020, bbox_mAP_s: 0.0060, bbox_mAP_m: 0.1800, bbox_mAP_l: 0.5330, bbox_mAP_copypaste: 0.469 0.632 0.502 0.006 0.180 0.533
2022-04-03 18:18:10,211 - mmdet - INFO - Epoch [29][50/976]	lr: 1.258e-05, eta: 3:19:55, time: 1.634, data_time: 0.065, memory: 25267, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0125, s0.loss_cls: 0.0603, s0.acc: 97.6650, s0.loss_bbox: 0.0430, s1.loss_cls: 0.0197, s1.acc: 98.5059, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0051, s2.acc: 99.2305, s2.loss_bbox: 0.0077, loss: 0.1812
2022-04-03 18:19:29,345 - mmdet - INFO - Epoch [29][100/976]	lr: 1.258e-05, eta: 3:18:40, time: 1.583, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0126, s0.loss_cls: 0.0628, s0.acc: 97.6025, s0.loss_bbox: 0.0444, s1.loss_cls: 0.0221, s1.acc: 98.3213, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0058, s2.acc: 99.1436, s2.loss_bbox: 0.0085, loss: 0.1914
2022-04-03 18:20:48,360 - mmdet - INFO - Epoch [29][150/976]	lr: 1.258e-05, eta: 3:17:25, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0128, s0.loss_cls: 0.0753, s0.acc: 97.2041, s0.loss_bbox: 0.0514, s1.loss_cls: 0.0262, s1.acc: 98.0742, s1.loss_bbox: 0.0338, s2.loss_cls: 0.0068, s2.acc: 99.0322, s2.loss_bbox: 0.0095, loss: 0.2227
2022-04-03 18:22:08,351 - mmdet - INFO - Epoch [29][200/976]	lr: 1.258e-05, eta: 3:16:11, time: 1.600, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0174, s0.loss_cls: 0.0737, s0.acc: 97.1631, s0.loss_bbox: 0.0555, s1.loss_cls: 0.0261, s1.acc: 98.0244, s1.loss_bbox: 0.0380, s2.loss_cls: 0.0073, s2.acc: 98.9463, s2.loss_bbox: 0.0104, loss: 0.2367
2022-04-03 18:23:27,156 - mmdet - INFO - Epoch [29][250/976]	lr: 1.258e-05, eta: 3:14:55, time: 1.576, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0124, s0.loss_cls: 0.0641, s0.acc: 97.5664, s0.loss_bbox: 0.0481, s1.loss_cls: 0.0224, s1.acc: 98.3291, s1.loss_bbox: 0.0329, s2.loss_cls: 0.0059, s2.acc: 99.1582, s2.loss_bbox: 0.0084, loss: 0.2009
2022-04-03 18:24:45,971 - mmdet - INFO - Epoch [29][300/976]	lr: 1.258e-05, eta: 3:13:39, time: 1.576, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0130, s0.loss_cls: 0.0680, s0.acc: 97.5449, s0.loss_bbox: 0.0502, s1.loss_cls: 0.0242, s1.acc: 98.2676, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0066, s2.acc: 99.0840, s2.loss_bbox: 0.0085, loss: 0.2097
2022-04-03 18:26:04,959 - mmdet - INFO - Epoch [29][350/976]	lr: 1.258e-05, eta: 3:12:24, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0116, s0.loss_cls: 0.0665, s0.acc: 97.6104, s0.loss_bbox: 0.0475, s1.loss_cls: 0.0231, s1.acc: 98.3252, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0061, s2.acc: 99.1348, s2.loss_bbox: 0.0082, loss: 0.1989
2022-04-03 18:27:24,034 - mmdet - INFO - Epoch [29][400/976]	lr: 1.258e-05, eta: 3:11:08, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0155, s0.loss_cls: 0.0690, s0.acc: 97.4414, s0.loss_bbox: 0.0535, s1.loss_cls: 0.0241, s1.acc: 98.1748, s1.loss_bbox: 0.0370, s2.loss_cls: 0.0070, s2.acc: 98.9697, s2.loss_bbox: 0.0109, loss: 0.2226
2022-04-03 18:28:42,850 - mmdet - INFO - Epoch [29][450/976]	lr: 1.258e-05, eta: 3:09:53, time: 1.576, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0077, loss_rpn_bbox: 0.0132, s0.loss_cls: 0.0721, s0.acc: 97.2471, s0.loss_bbox: 0.0512, s1.loss_cls: 0.0248, s1.acc: 98.1211, s1.loss_bbox: 0.0358, s2.loss_cls: 0.0068, s2.acc: 98.9668, s2.loss_bbox: 0.0103, loss: 0.2219
2022-04-03 18:30:02,090 - mmdet - INFO - Epoch [29][500/976]	lr: 1.258e-05, eta: 3:08:37, time: 1.585, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0074, loss_rpn_bbox: 0.0127, s0.loss_cls: 0.0597, s0.acc: 97.7080, s0.loss_bbox: 0.0413, s1.loss_cls: 0.0211, s1.acc: 98.4219, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0059, s2.acc: 99.1562, s2.loss_bbox: 0.0075, loss: 0.1832
2022-04-03 18:31:20,468 - mmdet - INFO - Epoch [29][550/976]	lr: 1.258e-05, eta: 3:07:21, time: 1.568, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0788, s0.acc: 97.0996, s0.loss_bbox: 0.0574, s1.loss_cls: 0.0269, s1.acc: 98.0391, s1.loss_bbox: 0.0375, s2.loss_cls: 0.0072, s2.acc: 98.9512, s2.loss_bbox: 0.0103, loss: 0.2420
2022-04-03 18:32:38,840 - mmdet - INFO - Epoch [29][600/976]	lr: 1.258e-05, eta: 3:06:05, time: 1.567, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0127, s0.loss_cls: 0.0554, s0.acc: 97.8721, s0.loss_bbox: 0.0422, s1.loss_cls: 0.0181, s1.acc: 98.6152, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0047, s2.acc: 99.3193, s2.loss_bbox: 0.0071, loss: 0.1706
2022-04-03 18:33:57,956 - mmdet - INFO - Epoch [29][650/976]	lr: 1.258e-05, eta: 3:04:49, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0140, s0.loss_cls: 0.0725, s0.acc: 97.2031, s0.loss_bbox: 0.0530, s1.loss_cls: 0.0259, s1.acc: 98.0293, s1.loss_bbox: 0.0372, s2.loss_cls: 0.0069, s2.acc: 98.9795, s2.loss_bbox: 0.0100, loss: 0.2246
2022-04-03 18:35:17,345 - mmdet - INFO - Epoch [29][700/976]	lr: 1.258e-05, eta: 3:03:34, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0151, s0.loss_cls: 0.0633, s0.acc: 97.5938, s0.loss_bbox: 0.0477, s1.loss_cls: 0.0228, s1.acc: 98.2783, s1.loss_bbox: 0.0342, s2.loss_cls: 0.0068, s2.acc: 98.9990, s2.loss_bbox: 0.0101, loss: 0.2062
2022-04-03 18:36:36,833 - mmdet - INFO - Epoch [29][750/976]	lr: 1.258e-05, eta: 3:02:18, time: 1.590, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0128, s0.loss_cls: 0.0710, s0.acc: 97.2412, s0.loss_bbox: 0.0517, s1.loss_cls: 0.0256, s1.acc: 98.0840, s1.loss_bbox: 0.0356, s2.loss_cls: 0.0072, s2.acc: 98.9600, s2.loss_bbox: 0.0103, loss: 0.2210
2022-04-03 18:37:56,025 - mmdet - INFO - Epoch [29][800/976]	lr: 1.258e-05, eta: 3:01:03, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0130, s0.loss_cls: 0.0692, s0.acc: 97.3672, s0.loss_bbox: 0.0497, s1.loss_cls: 0.0232, s1.acc: 98.2451, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0062, s2.acc: 99.0928, s2.loss_bbox: 0.0090, loss: 0.2082
2022-04-03 18:39:15,120 - mmdet - INFO - Epoch [29][850/976]	lr: 1.258e-05, eta: 2:59:47, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0155, s0.loss_cls: 0.0734, s0.acc: 97.2617, s0.loss_bbox: 0.0519, s1.loss_cls: 0.0258, s1.acc: 98.0635, s1.loss_bbox: 0.0350, s2.loss_cls: 0.0068, s2.acc: 99.0215, s2.loss_bbox: 0.0101, loss: 0.2262
2022-04-03 18:40:34,497 - mmdet - INFO - Epoch [29][900/976]	lr: 1.258e-05, eta: 2:58:31, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0103, loss_rpn_bbox: 0.0197, s0.loss_cls: 0.0898, s0.acc: 96.7178, s0.loss_bbox: 0.0662, s1.loss_cls: 0.0328, s1.acc: 97.5557, s1.loss_bbox: 0.0462, s2.loss_cls: 0.0096, s2.acc: 98.6006, s2.loss_bbox: 0.0136, loss: 0.2881
2022-04-03 18:41:53,239 - mmdet - INFO - Epoch [29][950/976]	lr: 1.258e-05, eta: 2:57:15, time: 1.575, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0162, s0.loss_cls: 0.0712, s0.acc: 97.3594, s0.loss_bbox: 0.0477, s1.loss_cls: 0.0245, s1.acc: 98.1748, s1.loss_bbox: 0.0329, s2.loss_cls: 0.0071, s2.acc: 98.9912, s2.loss_bbox: 0.0100, loss: 0.2174
2022-04-03 18:42:34,228 - mmdet - INFO - Saving checkpoint at 29 epochs
2022-04-03 18:45:01,257 - mmdet - INFO - Evaluating bbox...
2022-04-03 18:45:07,347 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.632
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.505
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.167
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.540
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.130
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.670

2022-04-03 18:45:07,348 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.285 | Paper       | 0.339 | Paper pack | 0.543 |
| Metal         | 0.544 | Glass       | 0.476 | Plastic    | 0.435 |
| Styrofoam     | 0.427 | Plastic bag | 0.581 | Battery    | 0.721 |
| Clothing      | 0.381 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 18:45:07,427 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 18:45:07,428 - mmdet - INFO - Epoch(val) [29][982]	bbox_mAP: 0.4730, bbox_mAP_50: 0.6320, bbox_mAP_75: 0.5050, bbox_mAP_s: 0.0070, bbox_mAP_m: 0.1670, bbox_mAP_l: 0.5400, bbox_mAP_copypaste: 0.473 0.632 0.505 0.007 0.167 0.540
2022-04-03 18:46:29,744 - mmdet - INFO - Epoch [30][50/976]	lr: 9.952e-06, eta: 2:54:42, time: 1.646, data_time: 0.065, memory: 25267, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0141, s0.loss_cls: 0.0724, s0.acc: 97.3857, s0.loss_bbox: 0.0488, s1.loss_cls: 0.0243, s1.acc: 98.2646, s1.loss_bbox: 0.0311, s2.loss_cls: 0.0063, s2.acc: 99.1260, s2.loss_bbox: 0.0088, loss: 0.2117
2022-04-03 18:47:48,652 - mmdet - INFO - Epoch [30][100/976]	lr: 9.952e-06, eta: 2:53:26, time: 1.578, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0683, s0.acc: 97.3564, s0.loss_bbox: 0.0474, s1.loss_cls: 0.0234, s1.acc: 98.2861, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0062, s2.acc: 99.1406, s2.loss_bbox: 0.0086, loss: 0.2063
2022-04-03 18:49:07,604 - mmdet - INFO - Epoch [30][150/976]	lr: 9.952e-06, eta: 2:52:10, time: 1.579, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.0711, s0.acc: 97.2441, s0.loss_bbox: 0.0558, s1.loss_cls: 0.0235, s1.acc: 98.2559, s1.loss_bbox: 0.0345, s2.loss_cls: 0.0061, s2.acc: 99.1162, s2.loss_bbox: 0.0092, loss: 0.2214
2022-04-03 18:50:26,829 - mmdet - INFO - Epoch [30][200/976]	lr: 9.952e-06, eta: 2:50:55, time: 1.584, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0086, loss_rpn_bbox: 0.0144, s0.loss_cls: 0.0689, s0.acc: 97.3916, s0.loss_bbox: 0.0500, s1.loss_cls: 0.0236, s1.acc: 98.2295, s1.loss_bbox: 0.0331, s2.loss_cls: 0.0064, s2.acc: 99.0664, s2.loss_bbox: 0.0092, loss: 0.2140
2022-04-03 18:51:45,467 - mmdet - INFO - Epoch [30][250/976]	lr: 9.952e-06, eta: 2:49:39, time: 1.573, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0107, s0.loss_cls: 0.0588, s0.acc: 97.8096, s0.loss_bbox: 0.0419, s1.loss_cls: 0.0210, s1.acc: 98.4355, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0059, s2.acc: 99.1445, s2.loss_bbox: 0.0079, loss: 0.1804
2022-04-03 18:53:04,841 - mmdet - INFO - Epoch [30][300/976]	lr: 9.952e-06, eta: 2:48:23, time: 1.587, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0077, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.0747, s0.acc: 97.2266, s0.loss_bbox: 0.0557, s1.loss_cls: 0.0291, s1.acc: 97.8613, s1.loss_bbox: 0.0376, s2.loss_cls: 0.0085, s2.acc: 98.8242, s2.loss_bbox: 0.0110, loss: 0.2401
2022-04-03 18:54:23,984 - mmdet - INFO - Epoch [30][350/976]	lr: 9.952e-06, eta: 2:47:08, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0146, s0.loss_cls: 0.0610, s0.acc: 97.6729, s0.loss_bbox: 0.0471, s1.loss_cls: 0.0217, s1.acc: 98.3477, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0058, s2.acc: 99.1260, s2.loss_bbox: 0.0083, loss: 0.1965
2022-04-03 18:55:43,141 - mmdet - INFO - Epoch [30][400/976]	lr: 9.952e-06, eta: 2:45:52, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0077, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0723, s0.acc: 97.2510, s0.loss_bbox: 0.0530, s1.loss_cls: 0.0252, s1.acc: 98.0928, s1.loss_bbox: 0.0371, s2.loss_cls: 0.0067, s2.acc: 99.0176, s2.loss_bbox: 0.0100, loss: 0.2276
2022-04-03 18:57:02,758 - mmdet - INFO - Epoch [30][450/976]	lr: 9.952e-06, eta: 2:44:37, time: 1.592, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0149, s0.loss_cls: 0.0698, s0.acc: 97.4531, s0.loss_bbox: 0.0502, s1.loss_cls: 0.0262, s1.acc: 98.0303, s1.loss_bbox: 0.0365, s2.loss_cls: 0.0073, s2.acc: 98.9375, s2.loss_bbox: 0.0105, loss: 0.2234
2022-04-03 18:58:22,109 - mmdet - INFO - Epoch [30][500/976]	lr: 9.952e-06, eta: 2:43:21, time: 1.587, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0130, s0.loss_cls: 0.0648, s0.acc: 97.4922, s0.loss_bbox: 0.0488, s1.loss_cls: 0.0229, s1.acc: 98.3008, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0066, s2.acc: 99.0391, s2.loss_bbox: 0.0102, loss: 0.2044
2022-04-03 18:59:40,849 - mmdet - INFO - Epoch [30][550/976]	lr: 9.952e-06, eta: 2:42:05, time: 1.575, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0129, s0.loss_cls: 0.0574, s0.acc: 97.8760, s0.loss_bbox: 0.0409, s1.loss_cls: 0.0200, s1.acc: 98.5449, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0054, s2.acc: 99.2520, s2.loss_bbox: 0.0078, loss: 0.1777
2022-04-03 19:01:00,051 - mmdet - INFO - Epoch [30][600/976]	lr: 9.952e-06, eta: 2:40:49, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0126, s0.loss_cls: 0.0755, s0.acc: 97.2100, s0.loss_bbox: 0.0523, s1.loss_cls: 0.0258, s1.acc: 98.1396, s1.loss_bbox: 0.0340, s2.loss_cls: 0.0072, s2.acc: 98.9590, s2.loss_bbox: 0.0103, loss: 0.2266
2022-04-03 19:02:19,004 - mmdet - INFO - Epoch [30][650/976]	lr: 9.952e-06, eta: 2:39:33, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0108, s0.loss_cls: 0.0541, s0.acc: 97.9795, s0.loss_bbox: 0.0396, s1.loss_cls: 0.0188, s1.acc: 98.5498, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0049, s2.acc: 99.2764, s2.loss_bbox: 0.0072, loss: 0.1673
2022-04-03 19:03:38,052 - mmdet - INFO - Epoch [30][700/976]	lr: 9.952e-06, eta: 2:38:16, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0118, s0.loss_cls: 0.0590, s0.acc: 97.7119, s0.loss_bbox: 0.0448, s1.loss_cls: 0.0205, s1.acc: 98.4600, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0053, s2.acc: 99.1924, s2.loss_bbox: 0.0077, loss: 0.1835
2022-04-03 19:04:57,493 - mmdet - INFO - Epoch [30][750/976]	lr: 9.952e-06, eta: 2:37:01, time: 1.589, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0155, s0.loss_cls: 0.0729, s0.acc: 97.2510, s0.loss_bbox: 0.0541, s1.loss_cls: 0.0263, s1.acc: 97.9902, s1.loss_bbox: 0.0379, s2.loss_cls: 0.0070, s2.acc: 98.9775, s2.loss_bbox: 0.0101, loss: 0.2312
2022-04-03 19:06:16,409 - mmdet - INFO - Epoch [30][800/976]	lr: 9.952e-06, eta: 2:35:44, time: 1.578, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0133, s0.loss_cls: 0.0696, s0.acc: 97.4512, s0.loss_bbox: 0.0458, s1.loss_cls: 0.0237, s1.acc: 98.2949, s1.loss_bbox: 0.0316, s2.loss_cls: 0.0068, s2.acc: 99.0039, s2.loss_bbox: 0.0093, loss: 0.2054
2022-04-03 19:07:35,689 - mmdet - INFO - Epoch [30][850/976]	lr: 9.952e-06, eta: 2:34:28, time: 1.586, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0152, s0.loss_cls: 0.0636, s0.acc: 97.6738, s0.loss_bbox: 0.0432, s1.loss_cls: 0.0224, s1.acc: 98.3750, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0067, s2.acc: 99.0205, s2.loss_bbox: 0.0094, loss: 0.1960
2022-04-03 19:08:54,827 - mmdet - INFO - Epoch [30][900/976]	lr: 9.952e-06, eta: 2:33:12, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0136, s0.loss_cls: 0.0695, s0.acc: 97.4043, s0.loss_bbox: 0.0483, s1.loss_cls: 0.0246, s1.acc: 98.1846, s1.loss_bbox: 0.0340, s2.loss_cls: 0.0065, s2.acc: 99.0781, s2.loss_bbox: 0.0101, loss: 0.2134
2022-04-03 19:10:14,104 - mmdet - INFO - Epoch [30][950/976]	lr: 9.952e-06, eta: 2:31:56, time: 1.586, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0074, loss_rpn_bbox: 0.0179, s0.loss_cls: 0.0830, s0.acc: 96.9443, s0.loss_bbox: 0.0591, s1.loss_cls: 0.0303, s1.acc: 97.7305, s1.loss_bbox: 0.0414, s2.loss_cls: 0.0084, s2.acc: 98.7725, s2.loss_bbox: 0.0121, loss: 0.2596
2022-04-03 19:10:55,229 - mmdet - INFO - Saving checkpoint at 30 epochs
2022-04-03 19:13:21,862 - mmdet - INFO - Evaluating bbox...
2022-04-03 19:13:27,609 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.636
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.176
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.671

2022-04-03 19:13:27,610 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.288 | Paper       | 0.342 | Paper pack | 0.534 |
| Metal         | 0.540 | Glass       | 0.488 | Plastic    | 0.437 |
| Styrofoam     | 0.423 | Plastic bag | 0.578 | Battery    | 0.757 |
| Clothing      | 0.384 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 19:13:27,681 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 19:13:27,681 - mmdet - INFO - Epoch(val) [30][982]	bbox_mAP: 0.4770, bbox_mAP_50: 0.6360, bbox_mAP_75: 0.5110, bbox_mAP_s: 0.0060, bbox_mAP_m: 0.1760, bbox_mAP_l: 0.5430, bbox_mAP_copypaste: 0.477 0.636 0.511 0.006 0.176 0.543
2022-04-03 19:14:49,455 - mmdet - INFO - Epoch [31][50/976]	lr: 7.632e-06, eta: 2:29:32, time: 1.635, data_time: 0.064, memory: 25267, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0142, s0.loss_cls: 0.0697, s0.acc: 97.3887, s0.loss_bbox: 0.0515, s1.loss_cls: 0.0240, s1.acc: 98.1924, s1.loss_bbox: 0.0355, s2.loss_cls: 0.0065, s2.acc: 99.0547, s2.loss_bbox: 0.0095, loss: 0.2173
2022-04-03 19:16:08,539 - mmdet - INFO - Epoch [31][100/976]	lr: 7.632e-06, eta: 2:28:16, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0135, s0.loss_cls: 0.0670, s0.acc: 97.4590, s0.loss_bbox: 0.0496, s1.loss_cls: 0.0240, s1.acc: 98.2393, s1.loss_bbox: 0.0331, s2.loss_cls: 0.0068, s2.acc: 99.0146, s2.loss_bbox: 0.0088, loss: 0.2099
2022-04-03 19:17:27,472 - mmdet - INFO - Epoch [31][150/976]	lr: 7.632e-06, eta: 2:27:00, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0135, s0.loss_cls: 0.0629, s0.acc: 97.6729, s0.loss_bbox: 0.0439, s1.loss_cls: 0.0213, s1.acc: 98.4375, s1.loss_bbox: 0.0290, s2.loss_cls: 0.0057, s2.acc: 99.1514, s2.loss_bbox: 0.0081, loss: 0.1916
2022-04-03 19:18:46,451 - mmdet - INFO - Epoch [31][200/976]	lr: 7.632e-06, eta: 2:25:43, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0148, s0.loss_cls: 0.0628, s0.acc: 97.6504, s0.loss_bbox: 0.0441, s1.loss_cls: 0.0218, s1.acc: 98.4277, s1.loss_bbox: 0.0307, s2.loss_cls: 0.0061, s2.acc: 99.1406, s2.loss_bbox: 0.0096, loss: 0.1950
2022-04-03 19:20:05,182 - mmdet - INFO - Epoch [31][250/976]	lr: 7.632e-06, eta: 2:24:27, time: 1.575, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0094, s0.loss_cls: 0.0551, s0.acc: 97.9736, s0.loss_bbox: 0.0393, s1.loss_cls: 0.0175, s1.acc: 98.7402, s1.loss_bbox: 0.0242, s2.loss_cls: 0.0045, s2.acc: 99.3359, s2.loss_bbox: 0.0066, loss: 0.1608
2022-04-03 19:21:23,904 - mmdet - INFO - Epoch [31][300/976]	lr: 7.632e-06, eta: 2:23:11, time: 1.574, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0149, s0.loss_cls: 0.0700, s0.acc: 97.4062, s0.loss_bbox: 0.0551, s1.loss_cls: 0.0260, s1.acc: 98.0752, s1.loss_bbox: 0.0368, s2.loss_cls: 0.0068, s2.acc: 99.0557, s2.loss_bbox: 0.0096, loss: 0.2271
2022-04-03 19:22:43,115 - mmdet - INFO - Epoch [31][350/976]	lr: 7.632e-06, eta: 2:21:55, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0146, s0.loss_cls: 0.0674, s0.acc: 97.4795, s0.loss_bbox: 0.0507, s1.loss_cls: 0.0244, s1.acc: 98.1709, s1.loss_bbox: 0.0344, s2.loss_cls: 0.0072, s2.acc: 98.9473, s2.loss_bbox: 0.0104, loss: 0.2160
2022-04-03 19:24:02,375 - mmdet - INFO - Epoch [31][400/976]	lr: 7.632e-06, eta: 2:20:39, time: 1.585, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0145, s0.loss_cls: 0.0753, s0.acc: 97.0918, s0.loss_bbox: 0.0537, s1.loss_cls: 0.0270, s1.acc: 97.9697, s1.loss_bbox: 0.0392, s2.loss_cls: 0.0080, s2.acc: 98.8438, s2.loss_bbox: 0.0117, loss: 0.2349
2022-04-03 19:25:21,449 - mmdet - INFO - Epoch [31][450/976]	lr: 7.632e-06, eta: 2:19:23, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0101, s0.loss_cls: 0.0556, s0.acc: 97.8848, s0.loss_bbox: 0.0394, s1.loss_cls: 0.0200, s1.acc: 98.4834, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0054, s2.acc: 99.2139, s2.loss_bbox: 0.0078, loss: 0.1718
2022-04-03 19:26:40,704 - mmdet - INFO - Epoch [31][500/976]	lr: 7.632e-06, eta: 2:18:06, time: 1.585, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0143, s0.loss_cls: 0.0692, s0.acc: 97.4297, s0.loss_bbox: 0.0473, s1.loss_cls: 0.0221, s1.acc: 98.3926, s1.loss_bbox: 0.0308, s2.loss_cls: 0.0062, s2.acc: 99.1025, s2.loss_bbox: 0.0087, loss: 0.2031
2022-04-03 19:27:59,261 - mmdet - INFO - Epoch [31][550/976]	lr: 7.632e-06, eta: 2:16:50, time: 1.571, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0119, s0.loss_cls: 0.0655, s0.acc: 97.5410, s0.loss_bbox: 0.0467, s1.loss_cls: 0.0227, s1.acc: 98.3203, s1.loss_bbox: 0.0324, s2.loss_cls: 0.0061, s2.acc: 99.1201, s2.loss_bbox: 0.0090, loss: 0.2002
2022-04-03 19:29:18,166 - mmdet - INFO - Epoch [31][600/976]	lr: 7.632e-06, eta: 2:15:33, time: 1.578, data_time: 0.012, memory: 25267, loss_rpn_cls: 0.0072, loss_rpn_bbox: 0.0162, s0.loss_cls: 0.0703, s0.acc: 97.2764, s0.loss_bbox: 0.0518, s1.loss_cls: 0.0253, s1.acc: 98.1094, s1.loss_bbox: 0.0365, s2.loss_cls: 0.0075, s2.acc: 98.9414, s2.loss_bbox: 0.0104, loss: 0.2251
2022-04-03 19:30:37,818 - mmdet - INFO - Epoch [31][650/976]	lr: 7.632e-06, eta: 2:14:17, time: 1.593, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0648, s0.acc: 97.4717, s0.loss_bbox: 0.0481, s1.loss_cls: 0.0241, s1.acc: 98.1660, s1.loss_bbox: 0.0339, s2.loss_cls: 0.0067, s2.acc: 99.0029, s2.loss_bbox: 0.0098, loss: 0.2091
2022-04-03 19:31:56,855 - mmdet - INFO - Epoch [31][700/976]	lr: 7.632e-06, eta: 2:13:01, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0116, s0.loss_cls: 0.0656, s0.acc: 97.5117, s0.loss_bbox: 0.0471, s1.loss_cls: 0.0228, s1.acc: 98.2725, s1.loss_bbox: 0.0324, s2.loss_cls: 0.0060, s2.acc: 99.1152, s2.loss_bbox: 0.0097, loss: 0.2012
2022-04-03 19:33:15,448 - mmdet - INFO - Epoch [31][750/976]	lr: 7.632e-06, eta: 2:11:44, time: 1.572, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0152, s0.loss_cls: 0.0718, s0.acc: 97.2783, s0.loss_bbox: 0.0540, s1.loss_cls: 0.0251, s1.acc: 98.1201, s1.loss_bbox: 0.0369, s2.loss_cls: 0.0068, s2.acc: 99.0078, s2.loss_bbox: 0.0099, loss: 0.2259
2022-04-03 19:34:34,684 - mmdet - INFO - Epoch [31][800/976]	lr: 7.632e-06, eta: 2:10:28, time: 1.585, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0153, s0.loss_cls: 0.0634, s0.acc: 97.6201, s0.loss_bbox: 0.0435, s1.loss_cls: 0.0238, s1.acc: 98.2148, s1.loss_bbox: 0.0329, s2.loss_cls: 0.0066, s2.acc: 99.0234, s2.loss_bbox: 0.0098, loss: 0.2051
2022-04-03 19:35:54,176 - mmdet - INFO - Epoch [31][850/976]	lr: 7.632e-06, eta: 2:09:12, time: 1.590, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0153, s0.loss_cls: 0.0774, s0.acc: 97.0703, s0.loss_bbox: 0.0556, s1.loss_cls: 0.0292, s1.acc: 97.8516, s1.loss_bbox: 0.0389, s2.loss_cls: 0.0083, s2.acc: 98.8174, s2.loss_bbox: 0.0112, loss: 0.2428
2022-04-03 19:37:13,284 - mmdet - INFO - Epoch [31][900/976]	lr: 7.632e-06, eta: 2:07:55, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0133, s0.loss_cls: 0.0652, s0.acc: 97.5586, s0.loss_bbox: 0.0498, s1.loss_cls: 0.0216, s1.acc: 98.3887, s1.loss_bbox: 0.0315, s2.loss_cls: 0.0058, s2.acc: 99.1338, s2.loss_bbox: 0.0085, loss: 0.2023
2022-04-03 19:38:31,994 - mmdet - INFO - Epoch [31][950/976]	lr: 7.632e-06, eta: 2:06:39, time: 1.574, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0136, s0.loss_cls: 0.0572, s0.acc: 97.8604, s0.loss_bbox: 0.0400, s1.loss_cls: 0.0197, s1.acc: 98.5586, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0053, s2.acc: 99.2109, s2.loss_bbox: 0.0071, loss: 0.1753
2022-04-03 19:39:13,347 - mmdet - INFO - Saving checkpoint at 31 epochs
2022-04-03 19:41:40,560 - mmdet - INFO - Evaluating bbox...
2022-04-03 19:41:46,298 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.634
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.539
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.113
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.378
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.662

2022-04-03 19:41:46,300 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.290 | Paper       | 0.342 | Paper pack | 0.535 |
| Metal         | 0.536 | Glass       | 0.484 | Plastic    | 0.435 |
| Styrofoam     | 0.437 | Plastic bag | 0.582 | Battery    | 0.702 |
| Clothing      | 0.378 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 19:41:46,372 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 19:41:46,372 - mmdet - INFO - Epoch(val) [31][982]	bbox_mAP: 0.4720, bbox_mAP_50: 0.6340, bbox_mAP_75: 0.5040, bbox_mAP_s: 0.0060, bbox_mAP_m: 0.1720, bbox_mAP_l: 0.5390, bbox_mAP_copypaste: 0.472 0.634 0.504 0.006 0.172 0.539
2022-04-03 19:43:08,486 - mmdet - INFO - Epoch [32][50/976]	lr: 5.638e-06, eta: 2:04:21, time: 1.642, data_time: 0.065, memory: 25267, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0127, s0.loss_cls: 0.0635, s0.acc: 97.5781, s0.loss_bbox: 0.0445, s1.loss_cls: 0.0214, s1.acc: 98.4121, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0057, s2.acc: 99.1582, s2.loss_bbox: 0.0086, loss: 0.1909
2022-04-03 19:44:27,735 - mmdet - INFO - Epoch [32][100/976]	lr: 5.638e-06, eta: 2:03:05, time: 1.585, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0146, s0.loss_cls: 0.0691, s0.acc: 97.4277, s0.loss_bbox: 0.0489, s1.loss_cls: 0.0265, s1.acc: 98.0303, s1.loss_bbox: 0.0365, s2.loss_cls: 0.0082, s2.acc: 98.8711, s2.loss_bbox: 0.0112, loss: 0.2226
2022-04-03 19:45:46,753 - mmdet - INFO - Epoch [32][150/976]	lr: 5.638e-06, eta: 2:01:49, time: 1.580, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0123, s0.loss_cls: 0.0571, s0.acc: 97.8330, s0.loss_bbox: 0.0435, s1.loss_cls: 0.0201, s1.acc: 98.4609, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0054, s2.acc: 99.2158, s2.loss_bbox: 0.0081, loss: 0.1812
2022-04-03 19:47:06,193 - mmdet - INFO - Epoch [32][200/976]	lr: 5.638e-06, eta: 2:00:33, time: 1.589, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0136, s0.loss_cls: 0.0631, s0.acc: 97.6260, s0.loss_bbox: 0.0444, s1.loss_cls: 0.0226, s1.acc: 98.3164, s1.loss_bbox: 0.0304, s2.loss_cls: 0.0059, s2.acc: 99.1299, s2.loss_bbox: 0.0086, loss: 0.1947
2022-04-03 19:48:25,361 - mmdet - INFO - Epoch [32][250/976]	lr: 5.638e-06, eta: 1:59:16, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0123, s0.loss_cls: 0.0647, s0.acc: 97.6221, s0.loss_bbox: 0.0490, s1.loss_cls: 0.0242, s1.acc: 98.2861, s1.loss_bbox: 0.0315, s2.loss_cls: 0.0065, s2.acc: 99.1162, s2.loss_bbox: 0.0085, loss: 0.2032
2022-04-03 19:49:44,516 - mmdet - INFO - Epoch [32][300/976]	lr: 5.638e-06, eta: 1:58:00, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0691, s0.acc: 97.3877, s0.loss_bbox: 0.0503, s1.loss_cls: 0.0240, s1.acc: 98.2480, s1.loss_bbox: 0.0323, s2.loss_cls: 0.0066, s2.acc: 99.0586, s2.loss_bbox: 0.0088, loss: 0.2123
2022-04-03 19:51:03,827 - mmdet - INFO - Epoch [32][350/976]	lr: 5.638e-06, eta: 1:56:44, time: 1.586, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0096, loss_rpn_bbox: 0.0164, s0.loss_cls: 0.0757, s0.acc: 97.1885, s0.loss_bbox: 0.0507, s1.loss_cls: 0.0258, s1.acc: 98.0742, s1.loss_bbox: 0.0328, s2.loss_cls: 0.0075, s2.acc: 98.9238, s2.loss_bbox: 0.0103, loss: 0.2288
2022-04-03 19:52:23,257 - mmdet - INFO - Epoch [32][400/976]	lr: 5.638e-06, eta: 1:55:27, time: 1.589, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0124, s0.loss_cls: 0.0665, s0.acc: 97.4639, s0.loss_bbox: 0.0490, s1.loss_cls: 0.0225, s1.acc: 98.2588, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0063, s2.acc: 99.0352, s2.loss_bbox: 0.0098, loss: 0.2053
2022-04-03 19:53:42,084 - mmdet - INFO - Epoch [32][450/976]	lr: 5.638e-06, eta: 1:54:11, time: 1.576, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0125, s0.loss_cls: 0.0547, s0.acc: 97.8779, s0.loss_bbox: 0.0433, s1.loss_cls: 0.0183, s1.acc: 98.5957, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0050, s2.acc: 99.2393, s2.loss_bbox: 0.0081, loss: 0.1747
2022-04-03 19:55:01,656 - mmdet - INFO - Epoch [32][500/976]	lr: 5.638e-06, eta: 1:52:55, time: 1.591, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0644, s0.acc: 97.5498, s0.loss_bbox: 0.0460, s1.loss_cls: 0.0229, s1.acc: 98.2676, s1.loss_bbox: 0.0325, s2.loss_cls: 0.0062, s2.acc: 99.0850, s2.loss_bbox: 0.0091, loss: 0.1996
2022-04-03 19:56:20,823 - mmdet - INFO - Epoch [32][550/976]	lr: 5.638e-06, eta: 1:51:38, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0155, s0.loss_cls: 0.0614, s0.acc: 97.7070, s0.loss_bbox: 0.0465, s1.loss_cls: 0.0220, s1.acc: 98.3398, s1.loss_bbox: 0.0325, s2.loss_cls: 0.0061, s2.acc: 99.0986, s2.loss_bbox: 0.0089, loss: 0.1999
2022-04-03 19:57:39,841 - mmdet - INFO - Epoch [32][600/976]	lr: 5.638e-06, eta: 1:50:22, time: 1.580, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0625, s0.acc: 97.5498, s0.loss_bbox: 0.0478, s1.loss_cls: 0.0213, s1.acc: 98.3574, s1.loss_bbox: 0.0316, s2.loss_cls: 0.0058, s2.acc: 99.1172, s2.loss_bbox: 0.0088, loss: 0.1976
2022-04-03 19:58:58,911 - mmdet - INFO - Epoch [32][650/976]	lr: 5.638e-06, eta: 1:49:05, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0145, s0.loss_cls: 0.0674, s0.acc: 97.4453, s0.loss_bbox: 0.0506, s1.loss_cls: 0.0227, s1.acc: 98.3125, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0062, s2.acc: 99.1064, s2.loss_bbox: 0.0091, loss: 0.2086
2022-04-03 20:00:18,309 - mmdet - INFO - Epoch [32][700/976]	lr: 5.638e-06, eta: 1:47:48, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0138, s0.loss_cls: 0.0681, s0.acc: 97.3887, s0.loss_bbox: 0.0502, s1.loss_cls: 0.0247, s1.acc: 98.0840, s1.loss_bbox: 0.0343, s2.loss_cls: 0.0068, s2.acc: 99.0107, s2.loss_bbox: 0.0103, loss: 0.2142
2022-04-03 20:01:37,477 - mmdet - INFO - Epoch [32][750/976]	lr: 5.638e-06, eta: 1:46:32, time: 1.583, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0116, s0.loss_cls: 0.0595, s0.acc: 97.7266, s0.loss_bbox: 0.0424, s1.loss_cls: 0.0205, s1.acc: 98.4473, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0055, s2.acc: 99.1934, s2.loss_bbox: 0.0081, loss: 0.1818
2022-04-03 20:02:56,403 - mmdet - INFO - Epoch [32][800/976]	lr: 5.638e-06, eta: 1:45:15, time: 1.578, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0116, s0.loss_cls: 0.0611, s0.acc: 97.6436, s0.loss_bbox: 0.0453, s1.loss_cls: 0.0209, s1.acc: 98.4521, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0056, s2.acc: 99.1650, s2.loss_bbox: 0.0089, loss: 0.1892
2022-04-03 20:04:15,354 - mmdet - INFO - Epoch [32][850/976]	lr: 5.638e-06, eta: 1:43:58, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0144, s0.loss_cls: 0.0671, s0.acc: 97.4512, s0.loss_bbox: 0.0497, s1.loss_cls: 0.0240, s1.acc: 98.2412, s1.loss_bbox: 0.0337, s2.loss_cls: 0.0067, s2.acc: 99.0127, s2.loss_bbox: 0.0102, loss: 0.2122
2022-04-03 20:05:34,186 - mmdet - INFO - Epoch [32][900/976]	lr: 5.638e-06, eta: 1:42:42, time: 1.577, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0111, s0.loss_cls: 0.0546, s0.acc: 97.8926, s0.loss_bbox: 0.0394, s1.loss_cls: 0.0183, s1.acc: 98.5596, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0050, s2.acc: 99.2412, s2.loss_bbox: 0.0072, loss: 0.1668
2022-04-03 20:06:53,732 - mmdet - INFO - Epoch [32][950/976]	lr: 5.638e-06, eta: 1:41:25, time: 1.591, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.0757, s0.acc: 97.1602, s0.loss_bbox: 0.0522, s1.loss_cls: 0.0268, s1.acc: 98.0400, s1.loss_bbox: 0.0357, s2.loss_cls: 0.0079, s2.acc: 98.8838, s2.loss_bbox: 0.0116, loss: 0.2328
2022-04-03 20:07:34,939 - mmdet - INFO - Saving checkpoint at 32 epochs
2022-04-03 20:10:02,011 - mmdet - INFO - Evaluating bbox...
2022-04-03 20:10:07,625 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.634
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.505
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.170
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.665

2022-04-03 20:10:07,626 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.288 | Paper       | 0.341 | Paper pack | 0.540 |
| Metal         | 0.538 | Glass       | 0.476 | Plastic    | 0.437 |
| Styrofoam     | 0.439 | Plastic bag | 0.587 | Battery    | 0.713 |
| Clothing      | 0.383 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 20:10:07,699 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 20:10:07,699 - mmdet - INFO - Epoch(val) [32][982]	bbox_mAP: 0.4740, bbox_mAP_50: 0.6340, bbox_mAP_75: 0.5050, bbox_mAP_s: 0.0060, bbox_mAP_m: 0.1700, bbox_mAP_l: 0.5410, bbox_mAP_copypaste: 0.474 0.634 0.505 0.006 0.170 0.541
2022-04-03 20:11:30,131 - mmdet - INFO - Epoch [33][50/976]	lr: 3.985e-06, eta: 1:39:13, time: 1.648, data_time: 0.065, memory: 25267, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0115, s0.loss_cls: 0.0665, s0.acc: 97.5674, s0.loss_bbox: 0.0465, s1.loss_cls: 0.0229, s1.acc: 98.3154, s1.loss_bbox: 0.0311, s2.loss_cls: 0.0059, s2.acc: 99.1338, s2.loss_bbox: 0.0084, loss: 0.1974
2022-04-03 20:12:49,142 - mmdet - INFO - Epoch [33][100/976]	lr: 3.985e-06, eta: 1:37:57, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0113, s0.loss_cls: 0.0589, s0.acc: 97.6748, s0.loss_bbox: 0.0444, s1.loss_cls: 0.0207, s1.acc: 98.4053, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0054, s2.acc: 99.1777, s2.loss_bbox: 0.0086, loss: 0.1831
2022-04-03 20:14:08,352 - mmdet - INFO - Epoch [33][150/976]	lr: 3.985e-06, eta: 1:36:40, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0752, s0.acc: 97.2354, s0.loss_bbox: 0.0536, s1.loss_cls: 0.0268, s1.acc: 98.0430, s1.loss_bbox: 0.0370, s2.loss_cls: 0.0074, s2.acc: 98.9297, s2.loss_bbox: 0.0109, loss: 0.2344
2022-04-03 20:15:27,318 - mmdet - INFO - Epoch [33][200/976]	lr: 3.985e-06, eta: 1:35:24, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0120, s0.loss_cls: 0.0599, s0.acc: 97.7412, s0.loss_bbox: 0.0439, s1.loss_cls: 0.0214, s1.acc: 98.4297, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0057, s2.acc: 99.1650, s2.loss_bbox: 0.0082, loss: 0.1861
2022-04-03 20:16:46,317 - mmdet - INFO - Epoch [33][250/976]	lr: 3.985e-06, eta: 1:34:07, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0167, s0.loss_cls: 0.0778, s0.acc: 97.1240, s0.loss_bbox: 0.0550, s1.loss_cls: 0.0283, s1.acc: 97.8877, s1.loss_bbox: 0.0393, s2.loss_cls: 0.0086, s2.acc: 98.7734, s2.loss_bbox: 0.0124, loss: 0.2448
2022-04-03 20:18:05,675 - mmdet - INFO - Epoch [33][300/976]	lr: 3.985e-06, eta: 1:32:51, time: 1.587, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0129, s0.loss_cls: 0.0653, s0.acc: 97.4932, s0.loss_bbox: 0.0490, s1.loss_cls: 0.0232, s1.acc: 98.2256, s1.loss_bbox: 0.0342, s2.loss_cls: 0.0067, s2.acc: 99.0195, s2.loss_bbox: 0.0104, loss: 0.2072
2022-04-03 20:19:24,390 - mmdet - INFO - Epoch [33][350/976]	lr: 3.985e-06, eta: 1:31:34, time: 1.574, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0139, s0.loss_cls: 0.0621, s0.acc: 97.6211, s0.loss_bbox: 0.0461, s1.loss_cls: 0.0224, s1.acc: 98.2637, s1.loss_bbox: 0.0334, s2.loss_cls: 0.0064, s2.acc: 99.0371, s2.loss_bbox: 0.0093, loss: 0.1981
2022-04-03 20:20:43,475 - mmdet - INFO - Epoch [33][400/976]	lr: 3.985e-06, eta: 1:30:17, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0719, s0.acc: 97.3604, s0.loss_bbox: 0.0516, s1.loss_cls: 0.0239, s1.acc: 98.2471, s1.loss_bbox: 0.0343, s2.loss_cls: 0.0065, s2.acc: 99.0664, s2.loss_bbox: 0.0089, loss: 0.2192
2022-04-03 20:22:02,903 - mmdet - INFO - Epoch [33][450/976]	lr: 3.985e-06, eta: 1:29:01, time: 1.589, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0138, s0.loss_cls: 0.0584, s0.acc: 97.7139, s0.loss_bbox: 0.0457, s1.loss_cls: 0.0202, s1.acc: 98.4541, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0051, s2.acc: 99.2246, s2.loss_bbox: 0.0084, loss: 0.1871
2022-04-03 20:23:21,706 - mmdet - INFO - Epoch [33][500/976]	lr: 3.985e-06, eta: 1:27:44, time: 1.576, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0136, s0.loss_cls: 0.0577, s0.acc: 97.7588, s0.loss_bbox: 0.0420, s1.loss_cls: 0.0203, s1.acc: 98.4385, s1.loss_bbox: 0.0293, s2.loss_cls: 0.0053, s2.acc: 99.1924, s2.loss_bbox: 0.0087, loss: 0.1826
2022-04-03 20:24:40,618 - mmdet - INFO - Epoch [33][550/976]	lr: 3.985e-06, eta: 1:26:27, time: 1.578, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0135, s0.loss_cls: 0.0609, s0.acc: 97.7256, s0.loss_bbox: 0.0453, s1.loss_cls: 0.0211, s1.acc: 98.4102, s1.loss_bbox: 0.0306, s2.loss_cls: 0.0055, s2.acc: 99.1631, s2.loss_bbox: 0.0086, loss: 0.1905
2022-04-03 20:25:59,443 - mmdet - INFO - Epoch [33][600/976]	lr: 3.985e-06, eta: 1:25:10, time: 1.576, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0706, s0.acc: 97.3223, s0.loss_bbox: 0.0527, s1.loss_cls: 0.0255, s1.acc: 98.0518, s1.loss_bbox: 0.0374, s2.loss_cls: 0.0074, s2.acc: 98.9160, s2.loss_bbox: 0.0112, loss: 0.2247
2022-04-03 20:27:19,559 - mmdet - INFO - Epoch [33][650/976]	lr: 3.985e-06, eta: 1:23:54, time: 1.602, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0134, s0.loss_cls: 0.0679, s0.acc: 97.4199, s0.loss_bbox: 0.0491, s1.loss_cls: 0.0240, s1.acc: 98.2334, s1.loss_bbox: 0.0332, s2.loss_cls: 0.0069, s2.acc: 99.0000, s2.loss_bbox: 0.0104, loss: 0.2095
2022-04-03 20:28:38,817 - mmdet - INFO - Epoch [33][700/976]	lr: 3.985e-06, eta: 1:22:37, time: 1.585, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0130, s0.loss_cls: 0.0583, s0.acc: 97.8164, s0.loss_bbox: 0.0393, s1.loss_cls: 0.0200, s1.acc: 98.4404, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0056, s2.acc: 99.1729, s2.loss_bbox: 0.0080, loss: 0.1798
2022-04-03 20:29:57,670 - mmdet - INFO - Epoch [33][750/976]	lr: 3.985e-06, eta: 1:21:20, time: 1.577, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0129, s0.loss_cls: 0.0570, s0.acc: 97.7930, s0.loss_bbox: 0.0398, s1.loss_cls: 0.0205, s1.acc: 98.4473, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0056, s2.acc: 99.1846, s2.loss_bbox: 0.0076, loss: 0.1760
2022-04-03 20:31:16,873 - mmdet - INFO - Epoch [33][800/976]	lr: 3.985e-06, eta: 1:20:03, time: 1.584, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0150, s0.loss_cls: 0.0667, s0.acc: 97.5352, s0.loss_bbox: 0.0494, s1.loss_cls: 0.0237, s1.acc: 98.2422, s1.loss_bbox: 0.0323, s2.loss_cls: 0.0067, s2.acc: 99.0439, s2.loss_bbox: 0.0093, loss: 0.2093
2022-04-03 20:32:35,735 - mmdet - INFO - Epoch [33][850/976]	lr: 3.985e-06, eta: 1:18:46, time: 1.577, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0121, s0.loss_cls: 0.0594, s0.acc: 97.7891, s0.loss_bbox: 0.0438, s1.loss_cls: 0.0200, s1.acc: 98.4863, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0052, s2.acc: 99.2432, s2.loss_bbox: 0.0080, loss: 0.1833
2022-04-03 20:33:54,740 - mmdet - INFO - Epoch [33][900/976]	lr: 3.985e-06, eta: 1:17:29, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0132, s0.loss_cls: 0.0654, s0.acc: 97.5566, s0.loss_bbox: 0.0460, s1.loss_cls: 0.0215, s1.acc: 98.3672, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0055, s2.acc: 99.1992, s2.loss_bbox: 0.0086, loss: 0.1953
2022-04-03 20:35:14,135 - mmdet - INFO - Epoch [33][950/976]	lr: 3.985e-06, eta: 1:16:12, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0116, s0.loss_cls: 0.0617, s0.acc: 97.5918, s0.loss_bbox: 0.0450, s1.loss_cls: 0.0215, s1.acc: 98.3389, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0060, s2.acc: 99.1064, s2.loss_bbox: 0.0088, loss: 0.1907
2022-04-03 20:35:55,396 - mmdet - INFO - Saving checkpoint at 33 epochs
2022-04-03 20:38:22,684 - mmdet - INFO - Evaluating bbox...
2022-04-03 20:38:28,583 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.633
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.539
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.122
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.670

2022-04-03 20:38:28,584 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.292 | Paper       | 0.344 | Paper pack | 0.534 |
| Metal         | 0.536 | Glass       | 0.476 | Plastic    | 0.440 |
| Styrofoam     | 0.442 | Plastic bag | 0.585 | Battery    | 0.699 |
| Clothing      | 0.381 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 20:38:28,661 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 20:38:28,661 - mmdet - INFO - Epoch(val) [33][982]	bbox_mAP: 0.4730, bbox_mAP_50: 0.6330, bbox_mAP_75: 0.5060, bbox_mAP_s: 0.0060, bbox_mAP_m: 0.1710, bbox_mAP_l: 0.5390, bbox_mAP_copypaste: 0.473 0.633 0.506 0.006 0.171 0.539
2022-04-03 20:39:50,344 - mmdet - INFO - Epoch [34][50/976]	lr: 2.687e-06, eta: 1:14:05, time: 1.633, data_time: 0.065, memory: 25267, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0131, s0.loss_cls: 0.0629, s0.acc: 97.6328, s0.loss_bbox: 0.0475, s1.loss_cls: 0.0226, s1.acc: 98.2969, s1.loss_bbox: 0.0329, s2.loss_cls: 0.0059, s2.acc: 99.1133, s2.loss_bbox: 0.0088, loss: 0.2003
2022-04-03 20:41:09,815 - mmdet - INFO - Epoch [34][100/976]	lr: 2.687e-06, eta: 1:12:48, time: 1.589, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0140, s0.loss_cls: 0.0642, s0.acc: 97.6240, s0.loss_bbox: 0.0502, s1.loss_cls: 0.0229, s1.acc: 98.3096, s1.loss_bbox: 0.0327, s2.loss_cls: 0.0064, s2.acc: 99.0566, s2.loss_bbox: 0.0097, loss: 0.2070
2022-04-03 20:42:28,781 - mmdet - INFO - Epoch [34][150/976]	lr: 2.687e-06, eta: 1:11:32, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0168, s0.loss_cls: 0.0716, s0.acc: 97.3545, s0.loss_bbox: 0.0539, s1.loss_cls: 0.0253, s1.acc: 98.1416, s1.loss_bbox: 0.0364, s2.loss_cls: 0.0074, s2.acc: 98.9541, s2.loss_bbox: 0.0103, loss: 0.2285
2022-04-03 20:43:48,120 - mmdet - INFO - Epoch [34][200/976]	lr: 2.687e-06, eta: 1:10:15, time: 1.587, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.0726, s0.acc: 97.2305, s0.loss_bbox: 0.0510, s1.loss_cls: 0.0256, s1.acc: 98.0322, s1.loss_bbox: 0.0364, s2.loss_cls: 0.0074, s2.acc: 98.9277, s2.loss_bbox: 0.0106, loss: 0.2282
2022-04-03 20:45:07,468 - mmdet - INFO - Epoch [34][250/976]	lr: 2.687e-06, eta: 1:08:58, time: 1.587, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0138, s0.loss_cls: 0.0562, s0.acc: 97.8438, s0.loss_bbox: 0.0408, s1.loss_cls: 0.0203, s1.acc: 98.4717, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0056, s2.acc: 99.1885, s2.loss_bbox: 0.0085, loss: 0.1797
2022-04-03 20:46:26,492 - mmdet - INFO - Epoch [34][300/976]	lr: 2.687e-06, eta: 1:07:41, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0093, s0.loss_cls: 0.0482, s0.acc: 98.1123, s0.loss_bbox: 0.0383, s1.loss_cls: 0.0164, s1.acc: 98.7070, s1.loss_bbox: 0.0252, s2.loss_cls: 0.0043, s2.acc: 99.3535, s2.loss_bbox: 0.0068, loss: 0.1523
2022-04-03 20:47:45,380 - mmdet - INFO - Epoch [34][350/976]	lr: 2.687e-06, eta: 1:06:24, time: 1.578, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0122, s0.loss_cls: 0.0640, s0.acc: 97.5195, s0.loss_bbox: 0.0474, s1.loss_cls: 0.0226, s1.acc: 98.3154, s1.loss_bbox: 0.0309, s2.loss_cls: 0.0066, s2.acc: 99.0596, s2.loss_bbox: 0.0090, loss: 0.2009
2022-04-03 20:49:04,473 - mmdet - INFO - Epoch [34][400/976]	lr: 2.687e-06, eta: 1:05:08, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0147, s0.loss_cls: 0.0602, s0.acc: 97.7109, s0.loss_bbox: 0.0439, s1.loss_cls: 0.0209, s1.acc: 98.4307, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0064, s2.acc: 99.0586, s2.loss_bbox: 0.0091, loss: 0.1905
2022-04-03 20:50:23,647 - mmdet - INFO - Epoch [34][450/976]	lr: 2.687e-06, eta: 1:03:51, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0148, s0.loss_cls: 0.0669, s0.acc: 97.4697, s0.loss_bbox: 0.0493, s1.loss_cls: 0.0246, s1.acc: 98.1631, s1.loss_bbox: 0.0359, s2.loss_cls: 0.0073, s2.acc: 98.9600, s2.loss_bbox: 0.0107, loss: 0.2162
2022-04-03 20:51:43,050 - mmdet - INFO - Epoch [34][500/976]	lr: 2.687e-06, eta: 1:02:34, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0118, s0.loss_cls: 0.0574, s0.acc: 97.8232, s0.loss_bbox: 0.0429, s1.loss_cls: 0.0189, s1.acc: 98.5762, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0050, s2.acc: 99.2842, s2.loss_bbox: 0.0073, loss: 0.1746
2022-04-03 20:53:02,070 - mmdet - INFO - Epoch [34][550/976]	lr: 2.687e-06, eta: 1:01:17, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0139, s0.loss_cls: 0.0661, s0.acc: 97.4814, s0.loss_bbox: 0.0501, s1.loss_cls: 0.0238, s1.acc: 98.1953, s1.loss_bbox: 0.0339, s2.loss_cls: 0.0065, s2.acc: 99.0264, s2.loss_bbox: 0.0102, loss: 0.2108
2022-04-03 20:54:21,195 - mmdet - INFO - Epoch [34][600/976]	lr: 2.687e-06, eta: 1:00:00, time: 1.582, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0125, s0.loss_cls: 0.0580, s0.acc: 97.7686, s0.loss_bbox: 0.0451, s1.loss_cls: 0.0207, s1.acc: 98.4189, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0055, s2.acc: 99.1875, s2.loss_bbox: 0.0080, loss: 0.1840
2022-04-03 20:55:41,101 - mmdet - INFO - Epoch [34][650/976]	lr: 2.687e-06, eta: 0:58:43, time: 1.598, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0134, s0.loss_cls: 0.0691, s0.acc: 97.3760, s0.loss_bbox: 0.0513, s1.loss_cls: 0.0239, s1.acc: 98.2314, s1.loss_bbox: 0.0350, s2.loss_cls: 0.0066, s2.acc: 99.0469, s2.loss_bbox: 0.0098, loss: 0.2148
2022-04-03 20:57:00,303 - mmdet - INFO - Epoch [34][700/976]	lr: 2.687e-06, eta: 0:57:26, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0140, s0.loss_cls: 0.0635, s0.acc: 97.6035, s0.loss_bbox: 0.0460, s1.loss_cls: 0.0215, s1.acc: 98.3740, s1.loss_bbox: 0.0323, s2.loss_cls: 0.0065, s2.acc: 99.0078, s2.loss_bbox: 0.0100, loss: 0.1996
2022-04-03 20:58:19,331 - mmdet - INFO - Epoch [34][750/976]	lr: 2.687e-06, eta: 0:56:09, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0126, s0.loss_cls: 0.0660, s0.acc: 97.4854, s0.loss_bbox: 0.0484, s1.loss_cls: 0.0231, s1.acc: 98.2480, s1.loss_bbox: 0.0329, s2.loss_cls: 0.0065, s2.acc: 99.0518, s2.loss_bbox: 0.0093, loss: 0.2048
2022-04-03 20:59:37,755 - mmdet - INFO - Epoch [34][800/976]	lr: 2.687e-06, eta: 0:54:52, time: 1.568, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0115, s0.loss_cls: 0.0558, s0.acc: 97.8350, s0.loss_bbox: 0.0397, s1.loss_cls: 0.0194, s1.acc: 98.4980, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0055, s2.acc: 99.1875, s2.loss_bbox: 0.0081, loss: 0.1732
2022-04-03 21:00:57,147 - mmdet - INFO - Epoch [34][850/976]	lr: 2.687e-06, eta: 0:53:35, time: 1.588, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0140, s0.loss_cls: 0.0683, s0.acc: 97.4434, s0.loss_bbox: 0.0485, s1.loss_cls: 0.0242, s1.acc: 98.1973, s1.loss_bbox: 0.0342, s2.loss_cls: 0.0071, s2.acc: 98.9707, s2.loss_bbox: 0.0104, loss: 0.2128
2022-04-03 21:02:15,933 - mmdet - INFO - Epoch [34][900/976]	lr: 2.687e-06, eta: 0:52:18, time: 1.576, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0119, s0.loss_cls: 0.0634, s0.acc: 97.6689, s0.loss_bbox: 0.0469, s1.loss_cls: 0.0216, s1.acc: 98.3857, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0059, s2.acc: 99.1445, s2.loss_bbox: 0.0078, loss: 0.1925
2022-04-03 21:03:35,526 - mmdet - INFO - Epoch [34][950/976]	lr: 2.687e-06, eta: 0:51:01, time: 1.592, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0683, s0.acc: 97.3965, s0.loss_bbox: 0.0482, s1.loss_cls: 0.0246, s1.acc: 98.1904, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0066, s2.acc: 99.0029, s2.loss_bbox: 0.0102, loss: 0.2126
2022-04-03 21:04:16,861 - mmdet - INFO - Saving checkpoint at 34 epochs
2022-04-03 21:06:43,667 - mmdet - INFO - Evaluating bbox...
2022-04-03 21:06:49,311 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.632
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.503
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.170
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.123
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.663

2022-04-03 21:06:49,312 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.293 | Paper       | 0.341 | Paper pack | 0.540 |
| Metal         | 0.538 | Glass       | 0.481 | Plastic    | 0.441 |
| Styrofoam     | 0.447 | Plastic bag | 0.585 | Battery    | 0.697 |
| Clothing      | 0.378 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 21:06:49,377 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 21:06:49,377 - mmdet - INFO - Epoch(val) [34][982]	bbox_mAP: 0.4740, bbox_mAP_50: 0.6320, bbox_mAP_75: 0.5030, bbox_mAP_s: 0.0060, bbox_mAP_m: 0.1700, bbox_mAP_l: 0.5410, bbox_mAP_copypaste: 0.474 0.632 0.503 0.006 0.170 0.541
2022-04-03 21:08:11,449 - mmdet - INFO - Epoch [35][50/976]	lr: 1.752e-06, eta: 0:48:57, time: 1.641, data_time: 0.066, memory: 25267, loss_rpn_cls: 0.0072, loss_rpn_bbox: 0.0141, s0.loss_cls: 0.0597, s0.acc: 97.6973, s0.loss_bbox: 0.0456, s1.loss_cls: 0.0204, s1.acc: 98.4941, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0056, s2.acc: 99.1602, s2.loss_bbox: 0.0085, loss: 0.1909
2022-04-03 21:09:31,286 - mmdet - INFO - Epoch [35][100/976]	lr: 1.752e-06, eta: 0:47:41, time: 1.597, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0134, s0.loss_cls: 0.0622, s0.acc: 97.7090, s0.loss_bbox: 0.0454, s1.loss_cls: 0.0226, s1.acc: 98.3125, s1.loss_bbox: 0.0328, s2.loss_cls: 0.0063, s2.acc: 99.0596, s2.loss_bbox: 0.0100, loss: 0.1981
2022-04-03 21:10:50,509 - mmdet - INFO - Epoch [35][150/976]	lr: 1.752e-06, eta: 0:46:24, time: 1.584, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0112, s0.loss_cls: 0.0496, s0.acc: 98.1377, s0.loss_bbox: 0.0366, s1.loss_cls: 0.0177, s1.acc: 98.6680, s1.loss_bbox: 0.0252, s2.loss_cls: 0.0044, s2.acc: 99.3398, s2.loss_bbox: 0.0072, loss: 0.1569
2022-04-03 21:12:09,498 - mmdet - INFO - Epoch [35][200/976]	lr: 1.752e-06, eta: 0:45:07, time: 1.580, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0108, s0.loss_cls: 0.0525, s0.acc: 98.0254, s0.loss_bbox: 0.0393, s1.loss_cls: 0.0174, s1.acc: 98.7178, s1.loss_bbox: 0.0250, s2.loss_cls: 0.0045, s2.acc: 99.3496, s2.loss_bbox: 0.0069, loss: 0.1617
2022-04-03 21:13:28,125 - mmdet - INFO - Epoch [35][250/976]	lr: 1.752e-06, eta: 0:43:50, time: 1.572, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0123, s0.loss_cls: 0.0659, s0.acc: 97.4785, s0.loss_bbox: 0.0491, s1.loss_cls: 0.0212, s1.acc: 98.3555, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0057, s2.acc: 99.1670, s2.loss_bbox: 0.0085, loss: 0.2001
2022-04-03 21:14:47,436 - mmdet - INFO - Epoch [35][300/976]	lr: 1.752e-06, eta: 0:42:33, time: 1.586, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0148, s0.loss_cls: 0.0646, s0.acc: 97.5000, s0.loss_bbox: 0.0514, s1.loss_cls: 0.0226, s1.acc: 98.2852, s1.loss_bbox: 0.0339, s2.loss_cls: 0.0064, s2.acc: 99.0586, s2.loss_bbox: 0.0102, loss: 0.2090
2022-04-03 21:16:06,587 - mmdet - INFO - Epoch [35][350/976]	lr: 1.752e-06, eta: 0:41:16, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0630, s0.acc: 97.6211, s0.loss_bbox: 0.0470, s1.loss_cls: 0.0230, s1.acc: 98.3320, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0063, s2.acc: 99.0840, s2.loss_bbox: 0.0093, loss: 0.1997
2022-04-03 21:17:25,784 - mmdet - INFO - Epoch [35][400/976]	lr: 1.752e-06, eta: 0:39:59, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0131, s0.loss_cls: 0.0603, s0.acc: 97.7197, s0.loss_bbox: 0.0442, s1.loss_cls: 0.0208, s1.acc: 98.4141, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0056, s2.acc: 99.1885, s2.loss_bbox: 0.0085, loss: 0.1868
2022-04-03 21:18:44,968 - mmdet - INFO - Epoch [35][450/976]	lr: 1.752e-06, eta: 0:38:41, time: 1.584, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0126, s0.loss_cls: 0.0582, s0.acc: 97.7334, s0.loss_bbox: 0.0434, s1.loss_cls: 0.0202, s1.acc: 98.5371, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0055, s2.acc: 99.2070, s2.loss_bbox: 0.0084, loss: 0.1847
2022-04-03 21:20:03,911 - mmdet - INFO - Epoch [35][500/976]	lr: 1.752e-06, eta: 0:37:24, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0129, s0.loss_cls: 0.0611, s0.acc: 97.6270, s0.loss_bbox: 0.0464, s1.loss_cls: 0.0214, s1.acc: 98.3809, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0061, s2.acc: 99.0918, s2.loss_bbox: 0.0088, loss: 0.1935
2022-04-03 21:21:22,945 - mmdet - INFO - Epoch [35][550/976]	lr: 1.752e-06, eta: 0:36:07, time: 1.581, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0144, s0.loss_cls: 0.0649, s0.acc: 97.5684, s0.loss_bbox: 0.0487, s1.loss_cls: 0.0247, s1.acc: 98.1221, s1.loss_bbox: 0.0344, s2.loss_cls: 0.0066, s2.acc: 98.9971, s2.loss_bbox: 0.0105, loss: 0.2094
2022-04-03 21:22:42,452 - mmdet - INFO - Epoch [35][600/976]	lr: 1.752e-06, eta: 0:34:50, time: 1.590, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.0720, s0.acc: 97.2949, s0.loss_bbox: 0.0514, s1.loss_cls: 0.0266, s1.acc: 98.0439, s1.loss_bbox: 0.0382, s2.loss_cls: 0.0074, s2.acc: 98.9502, s2.loss_bbox: 0.0106, loss: 0.2286
2022-04-03 21:24:01,715 - mmdet - INFO - Epoch [35][650/976]	lr: 1.752e-06, eta: 0:33:33, time: 1.585, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0713, s0.acc: 97.3506, s0.loss_bbox: 0.0495, s1.loss_cls: 0.0256, s1.acc: 98.0908, s1.loss_bbox: 0.0363, s2.loss_cls: 0.0072, s2.acc: 98.9424, s2.loss_bbox: 0.0110, loss: 0.2208
2022-04-03 21:25:21,029 - mmdet - INFO - Epoch [35][700/976]	lr: 1.752e-06, eta: 0:32:16, time: 1.586, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0122, s0.loss_cls: 0.0640, s0.acc: 97.5732, s0.loss_bbox: 0.0452, s1.loss_cls: 0.0224, s1.acc: 98.2979, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0065, s2.acc: 99.0244, s2.loss_bbox: 0.0097, loss: 0.1989
2022-04-03 21:26:39,930 - mmdet - INFO - Epoch [35][750/976]	lr: 1.752e-06, eta: 0:30:59, time: 1.578, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0729, s0.acc: 97.3105, s0.loss_bbox: 0.0529, s1.loss_cls: 0.0267, s1.acc: 98.0547, s1.loss_bbox: 0.0365, s2.loss_cls: 0.0076, s2.acc: 98.9619, s2.loss_bbox: 0.0110, loss: 0.2296
2022-04-03 21:27:59,562 - mmdet - INFO - Epoch [35][800/976]	lr: 1.752e-06, eta: 0:29:42, time: 1.593, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0142, s0.loss_cls: 0.0699, s0.acc: 97.4512, s0.loss_bbox: 0.0506, s1.loss_cls: 0.0250, s1.acc: 98.1543, s1.loss_bbox: 0.0332, s2.loss_cls: 0.0071, s2.acc: 98.9697, s2.loss_bbox: 0.0106, loss: 0.2173
2022-04-03 21:29:18,579 - mmdet - INFO - Epoch [35][850/976]	lr: 1.752e-06, eta: 0:28:24, time: 1.580, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0113, s0.loss_cls: 0.0614, s0.acc: 97.6445, s0.loss_bbox: 0.0478, s1.loss_cls: 0.0210, s1.acc: 98.3848, s1.loss_bbox: 0.0306, s2.loss_cls: 0.0055, s2.acc: 99.1660, s2.loss_bbox: 0.0082, loss: 0.1897
2022-04-03 21:30:37,399 - mmdet - INFO - Epoch [35][900/976]	lr: 1.752e-06, eta: 0:27:07, time: 1.576, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0124, s0.loss_cls: 0.0563, s0.acc: 97.8486, s0.loss_bbox: 0.0415, s1.loss_cls: 0.0194, s1.acc: 98.5068, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0055, s2.acc: 99.1709, s2.loss_bbox: 0.0079, loss: 0.1754
2022-04-03 21:31:56,585 - mmdet - INFO - Epoch [35][950/976]	lr: 1.752e-06, eta: 0:25:50, time: 1.584, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0122, s0.loss_cls: 0.0588, s0.acc: 97.7422, s0.loss_bbox: 0.0455, s1.loss_cls: 0.0207, s1.acc: 98.5137, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0057, s2.acc: 99.1748, s2.loss_bbox: 0.0092, loss: 0.1889
2022-04-03 21:32:38,244 - mmdet - INFO - Saving checkpoint at 35 epochs
2022-04-03 21:35:05,522 - mmdet - INFO - Evaluating bbox...
2022-04-03 21:35:11,295 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.635
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.544
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.122
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.663

2022-04-03 21:35:11,296 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.293 | Paper       | 0.340 | Paper pack | 0.539 |
| Metal         | 0.541 | Glass       | 0.492 | Plastic    | 0.441 |
| Styrofoam     | 0.446 | Plastic bag | 0.586 | Battery    | 0.710 |
| Clothing      | 0.381 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 21:35:11,370 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 21:35:11,370 - mmdet - INFO - Epoch(val) [35][982]	bbox_mAP: 0.4770, bbox_mAP_50: 0.6350, bbox_mAP_75: 0.5080, bbox_mAP_s: 0.0070, bbox_mAP_m: 0.1710, bbox_mAP_l: 0.5440, bbox_mAP_copypaste: 0.477 0.635 0.508 0.007 0.171 0.544
2022-04-03 21:36:33,562 - mmdet - INFO - Epoch [36][50/976]	lr: 1.188e-06, eta: 0:23:50, time: 1.643, data_time: 0.066, memory: 25267, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0108, s0.loss_cls: 0.0521, s0.acc: 98.0068, s0.loss_bbox: 0.0406, s1.loss_cls: 0.0180, s1.acc: 98.6152, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0047, s2.acc: 99.2656, s2.loss_bbox: 0.0075, loss: 0.1655
2022-04-03 21:37:53,621 - mmdet - INFO - Epoch [36][100/976]	lr: 1.188e-06, eta: 0:22:33, time: 1.601, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0146, s0.loss_cls: 0.0656, s0.acc: 97.4697, s0.loss_bbox: 0.0487, s1.loss_cls: 0.0235, s1.acc: 98.2012, s1.loss_bbox: 0.0342, s2.loss_cls: 0.0067, s2.acc: 99.0146, s2.loss_bbox: 0.0102, loss: 0.2092
2022-04-03 21:39:12,882 - mmdet - INFO - Epoch [36][150/976]	lr: 1.188e-06, eta: 0:21:16, time: 1.585, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0684, s0.acc: 97.3896, s0.loss_bbox: 0.0499, s1.loss_cls: 0.0252, s1.acc: 98.1191, s1.loss_bbox: 0.0355, s2.loss_cls: 0.0075, s2.acc: 98.9219, s2.loss_bbox: 0.0112, loss: 0.2191
2022-04-03 21:40:32,542 - mmdet - INFO - Epoch [36][200/976]	lr: 1.188e-06, eta: 0:19:59, time: 1.593, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0139, s0.loss_cls: 0.0631, s0.acc: 97.6104, s0.loss_bbox: 0.0432, s1.loss_cls: 0.0219, s1.acc: 98.3896, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0059, s2.acc: 99.1406, s2.loss_bbox: 0.0089, loss: 0.1919
2022-04-03 21:41:51,492 - mmdet - INFO - Epoch [36][250/976]	lr: 1.188e-06, eta: 0:18:41, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0135, s0.loss_cls: 0.0656, s0.acc: 97.4648, s0.loss_bbox: 0.0505, s1.loss_cls: 0.0232, s1.acc: 98.2158, s1.loss_bbox: 0.0331, s2.loss_cls: 0.0066, s2.acc: 99.0195, s2.loss_bbox: 0.0099, loss: 0.2089
2022-04-03 21:43:10,650 - mmdet - INFO - Epoch [36][300/976]	lr: 1.188e-06, eta: 0:17:24, time: 1.583, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0090, s0.loss_cls: 0.0494, s0.acc: 98.1074, s0.loss_bbox: 0.0346, s1.loss_cls: 0.0174, s1.acc: 98.6846, s1.loss_bbox: 0.0232, s2.loss_cls: 0.0046, s2.acc: 99.2969, s2.loss_bbox: 0.0064, loss: 0.1482
2022-04-03 21:44:30,171 - mmdet - INFO - Epoch [36][350/976]	lr: 1.188e-06, eta: 0:16:07, time: 1.590, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0138, s0.loss_cls: 0.0587, s0.acc: 97.7666, s0.loss_bbox: 0.0456, s1.loss_cls: 0.0215, s1.acc: 98.4297, s1.loss_bbox: 0.0316, s2.loss_cls: 0.0060, s2.acc: 99.1035, s2.loss_bbox: 0.0089, loss: 0.1918
2022-04-03 21:45:49,968 - mmdet - INFO - Epoch [36][400/976]	lr: 1.188e-06, eta: 0:14:50, time: 1.596, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0165, s0.loss_cls: 0.0697, s0.acc: 97.3252, s0.loss_bbox: 0.0497, s1.loss_cls: 0.0260, s1.acc: 97.9893, s1.loss_bbox: 0.0359, s2.loss_cls: 0.0069, s2.acc: 98.9844, s2.loss_bbox: 0.0104, loss: 0.2206
2022-04-03 21:47:08,867 - mmdet - INFO - Epoch [36][450/976]	lr: 1.188e-06, eta: 0:13:33, time: 1.578, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0104, s0.loss_cls: 0.0556, s0.acc: 97.8623, s0.loss_bbox: 0.0417, s1.loss_cls: 0.0194, s1.acc: 98.5293, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0050, s2.acc: 99.2344, s2.loss_bbox: 0.0076, loss: 0.1706
2022-04-03 21:48:28,174 - mmdet - INFO - Epoch [36][500/976]	lr: 1.188e-06, eta: 0:12:15, time: 1.586, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0165, s0.loss_cls: 0.0670, s0.acc: 97.4756, s0.loss_bbox: 0.0497, s1.loss_cls: 0.0245, s1.acc: 98.1533, s1.loss_bbox: 0.0354, s2.loss_cls: 0.0073, s2.acc: 98.9424, s2.loss_bbox: 0.0108, loss: 0.2172
2022-04-03 21:49:47,890 - mmdet - INFO - Epoch [36][550/976]	lr: 1.188e-06, eta: 0:10:58, time: 1.594, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0139, s0.loss_cls: 0.0567, s0.acc: 97.7832, s0.loss_bbox: 0.0453, s1.loss_cls: 0.0210, s1.acc: 98.3398, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0056, s2.acc: 99.1621, s2.loss_bbox: 0.0086, loss: 0.1894
2022-04-03 21:51:06,996 - mmdet - INFO - Epoch [36][600/976]	lr: 1.188e-06, eta: 0:09:41, time: 1.582, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0130, s0.loss_cls: 0.0724, s0.acc: 97.3604, s0.loss_bbox: 0.0498, s1.loss_cls: 0.0243, s1.acc: 98.2520, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0067, s2.acc: 99.0811, s2.loss_bbox: 0.0095, loss: 0.2134
2022-04-03 21:52:26,336 - mmdet - INFO - Epoch [36][650/976]	lr: 1.188e-06, eta: 0:08:24, time: 1.587, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0126, s0.loss_cls: 0.0624, s0.acc: 97.6279, s0.loss_bbox: 0.0455, s1.loss_cls: 0.0213, s1.acc: 98.3926, s1.loss_bbox: 0.0325, s2.loss_cls: 0.0065, s2.acc: 99.0254, s2.loss_bbox: 0.0097, loss: 0.1964
2022-04-03 21:53:45,874 - mmdet - INFO - Epoch [36][700/976]	lr: 1.188e-06, eta: 0:07:06, time: 1.591, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0143, s0.loss_cls: 0.0680, s0.acc: 97.2939, s0.loss_bbox: 0.0536, s1.loss_cls: 0.0239, s1.acc: 98.2012, s1.loss_bbox: 0.0362, s2.loss_cls: 0.0065, s2.acc: 99.0352, s2.loss_bbox: 0.0100, loss: 0.2194
2022-04-03 21:55:05,708 - mmdet - INFO - Epoch [36][750/976]	lr: 1.188e-06, eta: 0:05:49, time: 1.597, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0122, s0.loss_cls: 0.0588, s0.acc: 97.8057, s0.loss_bbox: 0.0456, s1.loss_cls: 0.0203, s1.acc: 98.4961, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0055, s2.acc: 99.1670, s2.loss_bbox: 0.0082, loss: 0.1844
2022-04-03 21:56:24,879 - mmdet - INFO - Epoch [36][800/976]	lr: 1.188e-06, eta: 0:04:32, time: 1.583, data_time: 0.014, memory: 25267, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0136, s0.loss_cls: 0.0573, s0.acc: 97.8232, s0.loss_bbox: 0.0446, s1.loss_cls: 0.0198, s1.acc: 98.5273, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0053, s2.acc: 99.2285, s2.loss_bbox: 0.0083, loss: 0.1859
2022-04-03 21:57:43,818 - mmdet - INFO - Epoch [36][850/976]	lr: 1.188e-06, eta: 0:03:14, time: 1.579, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0118, s0.loss_cls: 0.0636, s0.acc: 97.5938, s0.loss_bbox: 0.0476, s1.loss_cls: 0.0232, s1.acc: 98.3164, s1.loss_bbox: 0.0322, s2.loss_cls: 0.0065, s2.acc: 99.0586, s2.loss_bbox: 0.0091, loss: 0.1996
2022-04-03 21:59:02,468 - mmdet - INFO - Epoch [36][900/976]	lr: 1.188e-06, eta: 0:01:57, time: 1.573, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0134, s0.loss_cls: 0.0648, s0.acc: 97.5205, s0.loss_bbox: 0.0474, s1.loss_cls: 0.0232, s1.acc: 98.2412, s1.loss_bbox: 0.0330, s2.loss_cls: 0.0060, s2.acc: 99.0840, s2.loss_bbox: 0.0093, loss: 0.2019
2022-04-03 22:00:21,257 - mmdet - INFO - Epoch [36][950/976]	lr: 1.188e-06, eta: 0:00:40, time: 1.576, data_time: 0.013, memory: 25267, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0120, s0.loss_cls: 0.0579, s0.acc: 97.8535, s0.loss_bbox: 0.0426, s1.loss_cls: 0.0198, s1.acc: 98.5674, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0057, s2.acc: 99.1670, s2.loss_bbox: 0.0079, loss: 0.1796
2022-04-03 22:01:02,525 - mmdet - INFO - Saving checkpoint at 36 epochs
2022-04-03 22:03:29,410 - mmdet - INFO - Evaluating bbox...
2022-04-03 22:03:35,051 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.638
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.124
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.376
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.668

2022-04-03 22:03:35,052 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.294 | Paper       | 0.341 | Paper pack | 0.543 |
| Metal         | 0.542 | Glass       | 0.489 | Plastic    | 0.439 |
| Styrofoam     | 0.442 | Plastic bag | 0.586 | Battery    | 0.745 |
| Clothing      | 0.376 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-03 22:03:35,124 - mmdet - INFO - Exp name: htc_swin_b.py
2022-04-03 22:03:35,124 - mmdet - INFO - Epoch(val) [36][982]	bbox_mAP: 0.4800, bbox_mAP_50: 0.6380, bbox_mAP_75: 0.5100, bbox_mAP_s: 0.0070, bbox_mAP_m: 0.1710, bbox_mAP_l: 0.5470, bbox_mAP_copypaste: 0.480 0.638 0.510 0.007 0.171 0.547

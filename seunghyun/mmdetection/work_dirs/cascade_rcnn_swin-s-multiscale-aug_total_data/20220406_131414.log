2022-04-06 13:14:15,772 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2
OpenCV: 4.5.5
MMCV: 1.4.6
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMDetection: 2.22.0+
------------------------------------------------------------

2022-04-06 13:14:17,648 - mmdet - INFO - Distributed training: False
2022-04-06 13:14:19,580 - mmdet - INFO - Config:
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='SwinTransformer',
        embed_dims=96,
        depths=[2, 2, 18, 2],
        num_heads=[3, 6, 12, 24],
        window_size=7,
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.2,
        patch_norm=True,
        out_indices=(0, 1, 2, 3),
        with_cp=False,
        convert_weights=True,
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_small_patch4_window7_224.pth'
        )),
    neck=dict(
        type='FPN',
        in_channels=[96, 192, 384, 768],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(
            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))
        ]),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100)))
dataset_type = 'CocoDataset'
data_root = '/opt/ml/detection/dataset/'
classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
img_scale = (1024, 1024)
albu_train_transforms = [
    dict(
        type='OneOf',
        transforms=[
            dict(type='Flip', p=1.0),
            dict(type='RandomRotate90', p=1.0)
        ],
        p=0.5),
    dict(
        type='RandomResizedCrop',
        height=1024,
        width=1024,
        scale=(0.5, 1.0),
        p=0.5),
    dict(
        type='RandomBrightnessContrast',
        brightness_limit=0.1,
        contrast_limit=0.15,
        p=0.5),
    dict(
        type='HueSaturationValue',
        hue_shift_limit=15,
        sat_shift_limit=25,
        val_shift_limit=10,
        p=0.5),
    dict(type='GaussNoise', p=0.3),
    dict(
        type='OneOf',
        transforms=[
            dict(type='Blur', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='MedianBlur', blur_limit=5, p=1.0),
            dict(type='MotionBlur', p=1.0)
        ],
        p=0.1)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1024, 1024), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.0),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Flip', p=1.0),
                    dict(type='RandomRotate90', p=1.0)
                ],
                p=0.5),
            dict(
                type='RandomResizedCrop',
                height=1024,
                width=1024,
                scale=(0.5, 1.0),
                p=0.5),
            dict(
                type='RandomBrightnessContrast',
                brightness_limit=0.1,
                contrast_limit=0.15,
                p=0.5),
            dict(
                type='HueSaturationValue',
                hue_shift_limit=15,
                sat_shift_limit=25,
                val_shift_limit=10,
                p=0.5),
            dict(type='GaussNoise', p=0.3),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Blur', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='MedianBlur', blur_limit=5, p=1.0),
                    dict(type='MotionBlur', p=1.0)
                ],
                p=0.1)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/train.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1024, 1024), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.0),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Flip', p=1.0),
                            dict(type='RandomRotate90', p=1.0)
                        ],
                        p=0.5),
                    dict(
                        type='RandomResizedCrop',
                        height=1024,
                        width=1024,
                        scale=(0.5, 1.0),
                        p=0.5),
                    dict(
                        type='RandomBrightnessContrast',
                        brightness_limit=0.1,
                        contrast_limit=0.15,
                        p=0.5),
                    dict(
                        type='HueSaturationValue',
                        hue_shift_limit=15,
                        sat_shift_limit=25,
                        val_shift_limit=10,
                        p=0.5),
                    dict(type='GaussNoise', p=0.3),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Blur', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='MedianBlur', blur_limit=5, p=1.0),
                            dict(type='MotionBlur', p=1.0)
                        ],
                        p=0.1)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file=
        '/opt/ml/detection/dataset/stratified_kfold/basic_v2/cv_val_3.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/test.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='bbox', classwise=True)
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=611,
    warmup_ratio=0.001,
    min_lr=1e-06)
runner = dict(type='EpochBasedRunner', max_epochs=30)
checkpoint_config = dict(max_keep_ckpts=1, interval=1)
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(
            type='WandbLoggerHook',
            interval=1000,
            init_kwargs=dict(
                project='two-stage-model',
                entity='canvas11',
                name='LEE_SwinS_Multiscale_TOTAL_DATA'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = '/opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/cascade_rcnn_swin-s-multiscale-aug/epoch_24.pth'
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_small_patch4_window7_224.pth'
fp16 = dict(loss_scale=512.0)
work_dir = 'work_dirs/cascade_rcnn_swin-s-multiscale-aug_total_data'
auto_resume = False
gpu_ids = [0]

2022-04-06 13:14:19,581 - mmdet - INFO - Set random seed to 943768560, deterministic: False
2022-04-06 13:14:20,519 - mmdet - INFO - load checkpoint from http path: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_small_patch4_window7_224.pth
2022-04-06 13:14:20,792 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2022-04-06 13:14:20,814 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2022-04-06 13:14:20,822 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-04-06 13:14:20,925 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-04-06 13:14:21,027 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.projection.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.norm0.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 96, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 192, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 384, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 
2022-04-06 13:14:25,348 - mmdet - INFO - load checkpoint from local path: /opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/cascade_rcnn_swin-s-multiscale-aug/epoch_24.pth
2022-04-06 13:14:26,187 - mmdet - INFO - resumed epoch 24, iter 11712
2022-04-06 13:14:26,189 - mmdet - INFO - Start running, host: root@0a25b60abdd2, work_dir: /opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/cascade_rcnn_swin-s-multiscale-aug_total_data
2022-04-06 13:14:26,189 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2022-04-06 13:14:26,190 - mmdet - INFO - workflow: [('train', 1)], max: 30 epochs
2022-04-06 13:14:26,192 - mmdet - INFO - Checkpoints will be saved to /opt/ml/detection/SEUNGHYUN_WORKSPACE/my_mmdetection/work_dirs/cascade_rcnn_swin-s-multiscale-aug_total_data by HardDiskBackend.
2022-04-06 13:15:54,222 - mmdet - INFO - Epoch [25][50/611]	lr: 1.045e-05, eta: 2:57:44, time: 1.624, data_time: 0.085, memory: 28856, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0210, s0.loss_cls: 0.1211, s0.acc: 96.0054, s0.loss_bbox: 0.0695, s1.loss_cls: 0.0564, s1.acc: 96.3266, s1.loss_bbox: 0.0670, s2.loss_cls: 0.0278, s2.acc: 96.3941, s2.loss_bbox: 0.0394, loss: 0.4200
2022-04-06 13:17:12,298 - mmdet - INFO - Epoch [25][100/611]	lr: 1.045e-05, eta: 2:53:00, time: 1.562, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0259, s0.loss_cls: 0.1484, s0.acc: 95.1162, s0.loss_bbox: 0.0830, s1.loss_cls: 0.0695, s1.acc: 95.5308, s1.loss_bbox: 0.0792, s2.loss_cls: 0.0341, s2.acc: 95.4344, s2.loss_bbox: 0.0477, loss: 0.5080
2022-04-06 13:18:30,859 - mmdet - INFO - Epoch [25][150/611]	lr: 1.045e-05, eta: 2:50:54, time: 1.571, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0181, loss_rpn_bbox: 0.0216, s0.loss_cls: 0.1400, s0.acc: 95.3882, s0.loss_bbox: 0.0826, s1.loss_cls: 0.0666, s1.acc: 95.7326, s1.loss_bbox: 0.0787, s2.loss_cls: 0.0320, s2.acc: 95.8250, s2.loss_bbox: 0.0445, loss: 0.4841
2022-04-06 13:19:48,750 - mmdet - INFO - Epoch [25][200/611]	lr: 1.045e-05, eta: 2:48:51, time: 1.558, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0174, loss_rpn_bbox: 0.0212, s0.loss_cls: 0.1233, s0.acc: 95.8501, s0.loss_bbox: 0.0726, s1.loss_cls: 0.0576, s1.acc: 96.2704, s1.loss_bbox: 0.0716, s2.loss_cls: 0.0284, s2.acc: 96.2357, s2.loss_bbox: 0.0427, loss: 0.4347
2022-04-06 13:21:07,796 - mmdet - INFO - Epoch [25][250/611]	lr: 1.045e-05, eta: 2:47:35, time: 1.581, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0227, loss_rpn_bbox: 0.0213, s0.loss_cls: 0.1419, s0.acc: 95.4600, s0.loss_bbox: 0.0782, s1.loss_cls: 0.0662, s1.acc: 95.8982, s1.loss_bbox: 0.0752, s2.loss_cls: 0.0323, s2.acc: 95.9462, s2.loss_bbox: 0.0448, loss: 0.4826
2022-04-06 13:22:25,561 - mmdet - INFO - Epoch [25][300/611]	lr: 1.045e-05, eta: 2:45:51, time: 1.555, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0333, loss_rpn_bbox: 0.0229, s0.loss_cls: 0.1468, s0.acc: 95.1299, s0.loss_bbox: 0.0820, s1.loss_cls: 0.0688, s1.acc: 95.5663, s1.loss_bbox: 0.0780, s2.loss_cls: 0.0340, s2.acc: 95.6074, s2.loss_bbox: 0.0453, loss: 0.5111
2022-04-06 13:23:43,559 - mmdet - INFO - Epoch [25][350/611]	lr: 1.045e-05, eta: 2:44:18, time: 1.560, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0231, s0.loss_cls: 0.1362, s0.acc: 95.6357, s0.loss_bbox: 0.0769, s1.loss_cls: 0.0634, s1.acc: 95.9836, s1.loss_bbox: 0.0754, s2.loss_cls: 0.0316, s2.acc: 96.0239, s2.loss_bbox: 0.0458, loss: 0.4691
2022-04-06 13:25:01,609 - mmdet - INFO - Epoch [25][400/611]	lr: 1.045e-05, eta: 2:42:51, time: 1.561, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0211, s0.loss_cls: 0.1288, s0.acc: 95.6709, s0.loss_bbox: 0.0762, s1.loss_cls: 0.0605, s1.acc: 96.0393, s1.loss_bbox: 0.0714, s2.loss_cls: 0.0291, s2.acc: 96.0663, s2.loss_bbox: 0.0417, loss: 0.4507
2022-04-06 13:26:19,847 - mmdet - INFO - Epoch [25][450/611]	lr: 1.045e-05, eta: 2:41:27, time: 1.565, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0185, loss_rpn_bbox: 0.0201, s0.loss_cls: 0.1180, s0.acc: 96.1763, s0.loss_bbox: 0.0658, s1.loss_cls: 0.0548, s1.acc: 96.5803, s1.loss_bbox: 0.0613, s2.loss_cls: 0.0266, s2.acc: 96.6340, s2.loss_bbox: 0.0384, loss: 0.4035
2022-04-06 13:27:38,124 - mmdet - INFO - Epoch [25][500/611]	lr: 1.045e-05, eta: 2:40:06, time: 1.566, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0195, loss_rpn_bbox: 0.0180, s0.loss_cls: 0.1244, s0.acc: 95.8296, s0.loss_bbox: 0.0734, s1.loss_cls: 0.0564, s1.acc: 96.2725, s1.loss_bbox: 0.0707, s2.loss_cls: 0.0274, s2.acc: 96.3012, s2.loss_bbox: 0.0419, loss: 0.4318
2022-04-06 13:28:56,018 - mmdet - INFO - Epoch [25][550/611]	lr: 1.045e-05, eta: 2:38:40, time: 1.558, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.0222, s0.loss_cls: 0.1323, s0.acc: 95.5469, s0.loss_bbox: 0.0780, s1.loss_cls: 0.0607, s1.acc: 95.9179, s1.loss_bbox: 0.0724, s2.loss_cls: 0.0294, s2.acc: 95.9818, s2.loss_bbox: 0.0429, loss: 0.4618
2022-04-06 13:30:14,167 - mmdet - INFO - Epoch [25][600/611]	lr: 1.045e-05, eta: 2:37:19, time: 1.563, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0203, loss_rpn_bbox: 0.0213, s0.loss_cls: 0.1462, s0.acc: 95.3062, s0.loss_bbox: 0.0778, s1.loss_cls: 0.0688, s1.acc: 95.6014, s1.loss_bbox: 0.0750, s2.loss_cls: 0.0343, s2.acc: 95.5310, s2.loss_bbox: 0.0455, loss: 0.4890
2022-04-06 13:30:31,663 - mmdet - INFO - Saving checkpoint at 25 epochs
2022-04-06 13:32:04,847 - mmdet - INFO - Evaluating bbox...
2022-04-06 13:32:08,641 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.657
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.524
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.018
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.187
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.061
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.343
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.659

2022-04-06 13:32:08,642 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.322 | Paper       | 0.349 | Paper pack | 0.564 |
| Metal         | 0.540 | Glass       | 0.479 | Plastic    | 0.455 |
| Styrofoam     | 0.441 | Plastic bag | 0.595 | Battery    | 0.724 |
| Clothing      | 0.450 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-06 13:32:08,686 - mmdet - INFO - Exp name: cascade_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco.py
2022-04-06 13:32:08,686 - mmdet - INFO - Epoch(val) [25][982]	bbox_mAP: 0.4920, bbox_mAP_50: 0.6570, bbox_mAP_75: 0.5240, bbox_mAP_s: 0.0180, bbox_mAP_m: 0.1870, bbox_mAP_l: 0.5570, bbox_mAP_copypaste: 0.492 0.657 0.524 0.018 0.187 0.557
2022-04-06 13:33:29,560 - mmdet - INFO - Epoch [26][50/611]	lr: 7.632e-06, eta: 2:33:30, time: 1.617, data_time: 0.085, memory: 28856, loss_rpn_cls: 0.0189, loss_rpn_bbox: 0.0207, s0.loss_cls: 0.1215, s0.acc: 95.9434, s0.loss_bbox: 0.0687, s1.loss_cls: 0.0545, s1.acc: 96.4512, s1.loss_bbox: 0.0661, s2.loss_cls: 0.0263, s2.acc: 96.5465, s2.loss_bbox: 0.0410, loss: 0.4177
2022-04-06 13:34:46,615 - mmdet - INFO - Epoch [26][100/611]	lr: 7.632e-06, eta: 2:32:10, time: 1.541, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0143, loss_rpn_bbox: 0.0165, s0.loss_cls: 0.1099, s0.acc: 96.3843, s0.loss_bbox: 0.0611, s1.loss_cls: 0.0502, s1.acc: 96.7111, s1.loss_bbox: 0.0594, s2.loss_cls: 0.0245, s2.acc: 96.7569, s2.loss_bbox: 0.0367, loss: 0.3726
2022-04-06 13:36:04,722 - mmdet - INFO - Epoch [26][150/611]	lr: 7.632e-06, eta: 2:30:59, time: 1.562, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0193, s0.loss_cls: 0.1296, s0.acc: 95.6924, s0.loss_bbox: 0.0754, s1.loss_cls: 0.0573, s1.acc: 96.3279, s1.loss_bbox: 0.0710, s2.loss_cls: 0.0276, s2.acc: 96.3809, s2.loss_bbox: 0.0443, loss: 0.4407
2022-04-06 13:37:21,735 - mmdet - INFO - Epoch [26][200/611]	lr: 7.632e-06, eta: 2:29:40, time: 1.540, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0178, loss_rpn_bbox: 0.0212, s0.loss_cls: 0.1377, s0.acc: 95.4326, s0.loss_bbox: 0.0796, s1.loss_cls: 0.0613, s1.acc: 95.9422, s1.loss_bbox: 0.0735, s2.loss_cls: 0.0297, s2.acc: 96.0419, s2.loss_bbox: 0.0437, loss: 0.4644
2022-04-06 13:38:40,067 - mmdet - INFO - Epoch [26][250/611]	lr: 7.632e-06, eta: 2:28:29, time: 1.567, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0191, s0.loss_cls: 0.1233, s0.acc: 95.6143, s0.loss_bbox: 0.0777, s1.loss_cls: 0.0559, s1.acc: 96.0550, s1.loss_bbox: 0.0739, s2.loss_cls: 0.0278, s2.acc: 96.0940, s2.loss_bbox: 0.0447, loss: 0.4379
2022-04-06 13:39:59,048 - mmdet - INFO - Epoch [26][300/611]	lr: 7.632e-06, eta: 2:27:22, time: 1.580, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0194, loss_rpn_bbox: 0.0228, s0.loss_cls: 0.1319, s0.acc: 95.5859, s0.loss_bbox: 0.0778, s1.loss_cls: 0.0592, s1.acc: 96.0290, s1.loss_bbox: 0.0750, s2.loss_cls: 0.0290, s2.acc: 96.1162, s2.loss_bbox: 0.0449, loss: 0.4600
2022-04-06 13:41:17,677 - mmdet - INFO - Epoch [26][350/611]	lr: 7.632e-06, eta: 2:26:11, time: 1.573, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0201, loss_rpn_bbox: 0.0216, s0.loss_cls: 0.1340, s0.acc: 95.5522, s0.loss_bbox: 0.0784, s1.loss_cls: 0.0603, s1.acc: 96.0618, s1.loss_bbox: 0.0740, s2.loss_cls: 0.0290, s2.acc: 96.0825, s2.loss_bbox: 0.0452, loss: 0.4627
2022-04-06 13:42:36,607 - mmdet - INFO - Epoch [26][400/611]	lr: 7.632e-06, eta: 2:25:01, time: 1.579, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.0226, s0.loss_cls: 0.1238, s0.acc: 95.7549, s0.loss_bbox: 0.0761, s1.loss_cls: 0.0556, s1.acc: 96.3003, s1.loss_bbox: 0.0715, s2.loss_cls: 0.0271, s2.acc: 96.2660, s2.loss_bbox: 0.0429, loss: 0.4406
2022-04-06 13:43:55,395 - mmdet - INFO - Epoch [26][450/611]	lr: 7.632e-06, eta: 2:23:50, time: 1.576, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.0200, s0.loss_cls: 0.1199, s0.acc: 95.9390, s0.loss_bbox: 0.0723, s1.loss_cls: 0.0556, s1.acc: 96.2969, s1.loss_bbox: 0.0694, s2.loss_cls: 0.0267, s2.acc: 96.4776, s2.loss_bbox: 0.0416, loss: 0.4239
2022-04-06 13:45:13,073 - mmdet - INFO - Epoch [26][500/611]	lr: 7.632e-06, eta: 2:22:32, time: 1.554, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0199, loss_rpn_bbox: 0.0243, s0.loss_cls: 0.1363, s0.acc: 95.3599, s0.loss_bbox: 0.0824, s1.loss_cls: 0.0607, s1.acc: 95.9775, s1.loss_bbox: 0.0771, s2.loss_cls: 0.0296, s2.acc: 96.0820, s2.loss_bbox: 0.0455, loss: 0.4759
2022-04-06 13:46:31,633 - mmdet - INFO - Epoch [26][550/611]	lr: 7.632e-06, eta: 2:21:19, time: 1.571, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.0236, s0.loss_cls: 0.1265, s0.acc: 95.6743, s0.loss_bbox: 0.0768, s1.loss_cls: 0.0582, s1.acc: 96.1777, s1.loss_bbox: 0.0738, s2.loss_cls: 0.0287, s2.acc: 96.2181, s2.loss_bbox: 0.0447, loss: 0.4499
2022-04-06 13:47:49,646 - mmdet - INFO - Epoch [26][600/611]	lr: 7.632e-06, eta: 2:20:03, time: 1.560, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0145, loss_rpn_bbox: 0.0190, s0.loss_cls: 0.1168, s0.acc: 96.0010, s0.loss_bbox: 0.0720, s1.loss_cls: 0.0527, s1.acc: 96.4420, s1.loss_bbox: 0.0667, s2.loss_cls: 0.0254, s2.acc: 96.5579, s2.loss_bbox: 0.0389, loss: 0.4060
2022-04-06 13:48:06,611 - mmdet - INFO - Saving checkpoint at 26 epochs
2022-04-06 13:49:40,776 - mmdet - INFO - Evaluating bbox...
2022-04-06 13:49:44,386 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.686
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.550
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.019
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.203
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.061
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.678

2022-04-06 13:49:44,387 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.358 | Paper       | 0.374 | Paper pack | 0.593 |
| Metal         | 0.570 | Glass       | 0.496 | Plastic    | 0.479 |
| Styrofoam     | 0.449 | Plastic bag | 0.617 | Battery    | 0.794 |
| Clothing      | 0.480 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-06 13:49:44,433 - mmdet - INFO - Exp name: cascade_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco.py
2022-04-06 13:49:44,433 - mmdet - INFO - Epoch(val) [26][982]	bbox_mAP: 0.5210, bbox_mAP_50: 0.6860, bbox_mAP_75: 0.5500, bbox_mAP_s: 0.0190, bbox_mAP_m: 0.2030, bbox_mAP_l: 0.5880, bbox_mAP_copypaste: 0.521 0.686 0.550 0.019 0.203 0.588
2022-04-06 13:51:05,835 - mmdet - INFO - Epoch [27][50/611]	lr: 5.279e-06, eta: 2:17:31, time: 1.628, data_time: 0.086, memory: 28856, loss_rpn_cls: 0.0145, loss_rpn_bbox: 0.0180, s0.loss_cls: 0.1139, s0.acc: 96.0742, s0.loss_bbox: 0.0706, s1.loss_cls: 0.0506, s1.acc: 96.5877, s1.loss_bbox: 0.0691, s2.loss_cls: 0.0239, s2.acc: 96.6966, s2.loss_bbox: 0.0412, loss: 0.4019
2022-04-06 13:52:23,553 - mmdet - INFO - Epoch [27][100/611]	lr: 5.279e-06, eta: 2:16:16, time: 1.554, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0218, s0.loss_cls: 0.1289, s0.acc: 95.7324, s0.loss_bbox: 0.0742, s1.loss_cls: 0.0592, s1.acc: 96.0623, s1.loss_bbox: 0.0687, s2.loss_cls: 0.0294, s2.acc: 96.0396, s2.loss_bbox: 0.0415, loss: 0.4439
2022-04-06 13:53:41,166 - mmdet - INFO - Epoch [27][150/611]	lr: 5.279e-06, eta: 2:15:01, time: 1.552, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0179, loss_rpn_bbox: 0.0212, s0.loss_cls: 0.1257, s0.acc: 95.5928, s0.loss_bbox: 0.0743, s1.loss_cls: 0.0563, s1.acc: 96.0963, s1.loss_bbox: 0.0736, s2.loss_cls: 0.0274, s2.acc: 96.1970, s2.loss_bbox: 0.0455, loss: 0.4419
2022-04-06 13:54:59,346 - mmdet - INFO - Epoch [27][200/611]	lr: 5.279e-06, eta: 2:13:47, time: 1.564, data_time: 0.023, memory: 28856, loss_rpn_cls: 0.0158, loss_rpn_bbox: 0.0203, s0.loss_cls: 0.1221, s0.acc: 95.8296, s0.loss_bbox: 0.0745, s1.loss_cls: 0.0560, s1.acc: 96.2686, s1.loss_bbox: 0.0695, s2.loss_cls: 0.0274, s2.acc: 96.3857, s2.loss_bbox: 0.0427, loss: 0.4283
2022-04-06 13:56:18,038 - mmdet - INFO - Epoch [27][250/611]	lr: 5.279e-06, eta: 2:12:35, time: 1.574, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0206, loss_rpn_bbox: 0.0227, s0.loss_cls: 0.1337, s0.acc: 95.4048, s0.loss_bbox: 0.0844, s1.loss_cls: 0.0600, s1.acc: 95.9953, s1.loss_bbox: 0.0772, s2.loss_cls: 0.0289, s2.acc: 96.1122, s2.loss_bbox: 0.0477, loss: 0.4751
2022-04-06 13:57:37,209 - mmdet - INFO - Epoch [27][300/611]	lr: 5.279e-06, eta: 2:11:24, time: 1.583, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0179, loss_rpn_bbox: 0.0203, s0.loss_cls: 0.1175, s0.acc: 95.9907, s0.loss_bbox: 0.0744, s1.loss_cls: 0.0524, s1.acc: 96.4504, s1.loss_bbox: 0.0689, s2.loss_cls: 0.0256, s2.acc: 96.4709, s2.loss_bbox: 0.0417, loss: 0.4187
2022-04-06 13:58:55,213 - mmdet - INFO - Epoch [27][350/611]	lr: 5.279e-06, eta: 2:10:09, time: 1.560, data_time: 0.023, memory: 28856, loss_rpn_cls: 0.0187, loss_rpn_bbox: 0.0199, s0.loss_cls: 0.1189, s0.acc: 95.8896, s0.loss_bbox: 0.0720, s1.loss_cls: 0.0527, s1.acc: 96.3886, s1.loss_bbox: 0.0702, s2.loss_cls: 0.0255, s2.acc: 96.4899, s2.loss_bbox: 0.0421, loss: 0.4199
2022-04-06 14:00:13,548 - mmdet - INFO - Epoch [27][400/611]	lr: 5.279e-06, eta: 2:08:54, time: 1.567, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0163, loss_rpn_bbox: 0.0193, s0.loss_cls: 0.1222, s0.acc: 95.7588, s0.loss_bbox: 0.0730, s1.loss_cls: 0.0547, s1.acc: 96.2642, s1.loss_bbox: 0.0711, s2.loss_cls: 0.0266, s2.acc: 96.3079, s2.loss_bbox: 0.0435, loss: 0.4267
2022-04-06 14:01:31,806 - mmdet - INFO - Epoch [27][450/611]	lr: 5.279e-06, eta: 2:07:39, time: 1.565, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0134, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.1084, s0.acc: 96.2979, s0.loss_bbox: 0.0634, s1.loss_cls: 0.0492, s1.acc: 96.6793, s1.loss_bbox: 0.0617, s2.loss_cls: 0.0238, s2.acc: 96.7071, s2.loss_bbox: 0.0377, loss: 0.3744
2022-04-06 14:02:49,176 - mmdet - INFO - Epoch [27][500/611]	lr: 5.279e-06, eta: 2:06:22, time: 1.547, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0206, loss_rpn_bbox: 0.0251, s0.loss_cls: 0.1373, s0.acc: 95.2651, s0.loss_bbox: 0.0862, s1.loss_cls: 0.0614, s1.acc: 95.8445, s1.loss_bbox: 0.0804, s2.loss_cls: 0.0293, s2.acc: 95.9378, s2.loss_bbox: 0.0474, loss: 0.4877
2022-04-06 14:04:07,764 - mmdet - INFO - Epoch [27][550/611]	lr: 5.279e-06, eta: 2:05:07, time: 1.572, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0174, loss_rpn_bbox: 0.0208, s0.loss_cls: 0.1179, s0.acc: 96.0063, s0.loss_bbox: 0.0698, s1.loss_cls: 0.0535, s1.acc: 96.4444, s1.loss_bbox: 0.0672, s2.loss_cls: 0.0258, s2.acc: 96.6348, s2.loss_bbox: 0.0417, loss: 0.4142
2022-04-06 14:05:25,838 - mmdet - INFO - Epoch [27][600/611]	lr: 5.279e-06, eta: 2:03:51, time: 1.561, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0189, s0.loss_cls: 0.1273, s0.acc: 95.7031, s0.loss_bbox: 0.0761, s1.loss_cls: 0.0560, s1.acc: 96.2616, s1.loss_bbox: 0.0708, s2.loss_cls: 0.0267, s2.acc: 96.4814, s2.loss_bbox: 0.0416, loss: 0.4352
2022-04-06 14:05:42,745 - mmdet - INFO - Saving checkpoint at 27 epochs
2022-04-06 14:07:15,566 - mmdet - INFO - Evaluating bbox...
2022-04-06 14:07:19,275 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.704
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.224
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.060
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.384
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.684

2022-04-06 14:07:19,276 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.377 | Paper       | 0.380 | Paper pack | 0.612 |
| Metal         | 0.597 | Glass       | 0.508 | Plastic    | 0.500 |
| Styrofoam     | 0.479 | Plastic bag | 0.619 | Battery    | 0.749 |
| Clothing      | 0.520 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-06 14:07:19,315 - mmdet - INFO - Exp name: cascade_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco.py
2022-04-06 14:07:19,315 - mmdet - INFO - Epoch(val) [27][982]	bbox_mAP: 0.5340, bbox_mAP_50: 0.7040, bbox_mAP_75: 0.5640, bbox_mAP_s: 0.0210, bbox_mAP_m: 0.2240, bbox_mAP_l: 0.6000, bbox_mAP_copypaste: 0.534 0.704 0.564 0.021 0.224 0.600
2022-04-06 14:08:39,748 - mmdet - INFO - Epoch [28][50/611]	lr: 3.423e-06, eta: 2:01:41, time: 1.608, data_time: 0.085, memory: 28856, loss_rpn_cls: 0.0152, loss_rpn_bbox: 0.0168, s0.loss_cls: 0.1164, s0.acc: 96.0420, s0.loss_bbox: 0.0704, s1.loss_cls: 0.0508, s1.acc: 96.5675, s1.loss_bbox: 0.0673, s2.loss_cls: 0.0245, s2.acc: 96.5975, s2.loss_bbox: 0.0418, loss: 0.4032
2022-04-06 14:09:57,567 - mmdet - INFO - Epoch [28][100/611]	lr: 3.423e-06, eta: 2:00:26, time: 1.556, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.0249, s0.loss_cls: 0.1295, s0.acc: 95.5332, s0.loss_bbox: 0.0834, s1.loss_cls: 0.0568, s1.acc: 96.1250, s1.loss_bbox: 0.0766, s2.loss_cls: 0.0269, s2.acc: 96.3234, s2.loss_bbox: 0.0450, loss: 0.4623
2022-04-06 14:11:16,199 - mmdet - INFO - Epoch [28][150/611]	lr: 3.423e-06, eta: 1:59:12, time: 1.573, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0158, loss_rpn_bbox: 0.0192, s0.loss_cls: 0.1137, s0.acc: 96.0371, s0.loss_bbox: 0.0738, s1.loss_cls: 0.0510, s1.acc: 96.5516, s1.loss_bbox: 0.0696, s2.loss_cls: 0.0247, s2.acc: 96.6053, s2.loss_bbox: 0.0444, loss: 0.4122
2022-04-06 14:12:34,138 - mmdet - INFO - Epoch [28][200/611]	lr: 3.423e-06, eta: 1:57:57, time: 1.559, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0174, loss_rpn_bbox: 0.0186, s0.loss_cls: 0.1183, s0.acc: 95.9473, s0.loss_bbox: 0.0698, s1.loss_cls: 0.0528, s1.acc: 96.4312, s1.loss_bbox: 0.0664, s2.loss_cls: 0.0256, s2.acc: 96.4791, s2.loss_bbox: 0.0420, loss: 0.4109
2022-04-06 14:13:52,398 - mmdet - INFO - Epoch [28][250/611]	lr: 3.423e-06, eta: 1:56:42, time: 1.565, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.0237, s0.loss_cls: 0.1212, s0.acc: 95.8120, s0.loss_bbox: 0.0737, s1.loss_cls: 0.0545, s1.acc: 96.2963, s1.loss_bbox: 0.0689, s2.loss_cls: 0.0263, s2.acc: 96.4211, s2.loss_bbox: 0.0390, loss: 0.4248
2022-04-06 14:15:09,735 - mmdet - INFO - Epoch [28][300/611]	lr: 3.423e-06, eta: 1:55:25, time: 1.547, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.0197, s0.loss_cls: 0.1224, s0.acc: 95.7222, s0.loss_bbox: 0.0749, s1.loss_cls: 0.0545, s1.acc: 96.2672, s1.loss_bbox: 0.0709, s2.loss_cls: 0.0269, s2.acc: 96.3423, s2.loss_bbox: 0.0429, loss: 0.4293
2022-04-06 14:16:28,161 - mmdet - INFO - Epoch [28][350/611]	lr: 3.423e-06, eta: 1:54:11, time: 1.568, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0168, loss_rpn_bbox: 0.0216, s0.loss_cls: 0.1168, s0.acc: 96.0347, s0.loss_bbox: 0.0704, s1.loss_cls: 0.0517, s1.acc: 96.5294, s1.loss_bbox: 0.0670, s2.loss_cls: 0.0246, s2.acc: 96.6534, s2.loss_bbox: 0.0409, loss: 0.4100
2022-04-06 14:17:46,306 - mmdet - INFO - Epoch [28][400/611]	lr: 3.423e-06, eta: 1:52:55, time: 1.563, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0193, loss_rpn_bbox: 0.0207, s0.loss_cls: 0.1296, s0.acc: 95.6641, s0.loss_bbox: 0.0766, s1.loss_cls: 0.0579, s1.acc: 96.2263, s1.loss_bbox: 0.0709, s2.loss_cls: 0.0279, s2.acc: 96.2278, s2.loss_bbox: 0.0418, loss: 0.4447
2022-04-06 14:19:04,612 - mmdet - INFO - Epoch [28][450/611]	lr: 3.423e-06, eta: 1:51:40, time: 1.566, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.0197, s0.loss_cls: 0.1130, s0.acc: 96.0718, s0.loss_bbox: 0.0697, s1.loss_cls: 0.0494, s1.acc: 96.6397, s1.loss_bbox: 0.0668, s2.loss_cls: 0.0238, s2.acc: 96.6604, s2.loss_bbox: 0.0401, loss: 0.3994
2022-04-06 14:20:22,154 - mmdet - INFO - Epoch [28][500/611]	lr: 3.423e-06, eta: 1:50:23, time: 1.551, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0211, s0.loss_cls: 0.1283, s0.acc: 95.7363, s0.loss_bbox: 0.0764, s1.loss_cls: 0.0566, s1.acc: 96.2603, s1.loss_bbox: 0.0726, s2.loss_cls: 0.0264, s2.acc: 96.3798, s2.loss_bbox: 0.0441, loss: 0.4414
2022-04-06 14:21:40,004 - mmdet - INFO - Epoch [28][550/611]	lr: 3.423e-06, eta: 1:49:07, time: 1.557, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0174, loss_rpn_bbox: 0.0186, s0.loss_cls: 0.1224, s0.acc: 95.7568, s0.loss_bbox: 0.0765, s1.loss_cls: 0.0544, s1.acc: 96.2674, s1.loss_bbox: 0.0740, s2.loss_cls: 0.0266, s2.acc: 96.2779, s2.loss_bbox: 0.0449, loss: 0.4347
2022-04-06 14:22:57,610 - mmdet - INFO - Epoch [28][600/611]	lr: 3.423e-06, eta: 1:47:50, time: 1.552, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0205, s0.loss_cls: 0.1169, s0.acc: 95.9390, s0.loss_bbox: 0.0744, s1.loss_cls: 0.0530, s1.acc: 96.4169, s1.loss_bbox: 0.0703, s2.loss_cls: 0.0256, s2.acc: 96.4686, s2.loss_bbox: 0.0421, loss: 0.4190
2022-04-06 14:23:15,049 - mmdet - INFO - Saving checkpoint at 28 epochs
2022-04-06 14:24:48,470 - mmdet - INFO - Evaluating bbox...
2022-04-06 14:24:51,965 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.717
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.578
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.024
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.228
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.061
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.696

2022-04-06 14:24:51,966 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.385 | Paper       | 0.386 | Paper pack | 0.616 |
| Metal         | 0.608 | Glass       | 0.512 | Plastic    | 0.505 |
| Styrofoam     | 0.486 | Plastic bag | 0.630 | Battery    | 0.794 |
| Clothing      | 0.543 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-06 14:24:52,004 - mmdet - INFO - Exp name: cascade_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco.py
2022-04-06 14:24:52,004 - mmdet - INFO - Epoch(val) [28][982]	bbox_mAP: 0.5470, bbox_mAP_50: 0.7170, bbox_mAP_75: 0.5780, bbox_mAP_s: 0.0240, bbox_mAP_m: 0.2280, bbox_mAP_l: 0.6140, bbox_mAP_copypaste: 0.547 0.717 0.578 0.024 0.228 0.614
2022-04-06 14:26:12,614 - mmdet - INFO - Epoch [29][50/611]	lr: 2.082e-06, eta: 1:45:53, time: 1.612, data_time: 0.085, memory: 28856, loss_rpn_cls: 0.0165, loss_rpn_bbox: 0.0191, s0.loss_cls: 0.1138, s0.acc: 96.1162, s0.loss_bbox: 0.0697, s1.loss_cls: 0.0507, s1.acc: 96.6064, s1.loss_bbox: 0.0669, s2.loss_cls: 0.0247, s2.acc: 96.6842, s2.loss_bbox: 0.0410, loss: 0.4024
2022-04-06 14:27:30,904 - mmdet - INFO - Epoch [29][100/611]	lr: 2.082e-06, eta: 1:44:38, time: 1.566, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0204, s0.loss_cls: 0.1218, s0.acc: 95.8281, s0.loss_bbox: 0.0773, s1.loss_cls: 0.0526, s1.acc: 96.4843, s1.loss_bbox: 0.0728, s2.loss_cls: 0.0251, s2.acc: 96.5862, s2.loss_bbox: 0.0440, loss: 0.4300
2022-04-06 14:28:48,837 - mmdet - INFO - Epoch [29][150/611]	lr: 2.082e-06, eta: 1:43:22, time: 1.559, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0234, s0.loss_cls: 0.1248, s0.acc: 95.6416, s0.loss_bbox: 0.0782, s1.loss_cls: 0.0551, s1.acc: 96.1765, s1.loss_bbox: 0.0736, s2.loss_cls: 0.0264, s2.acc: 96.3084, s2.loss_bbox: 0.0428, loss: 0.4420
2022-04-06 14:30:06,560 - mmdet - INFO - Epoch [29][200/611]	lr: 2.082e-06, eta: 1:42:06, time: 1.554, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0176, loss_rpn_bbox: 0.0184, s0.loss_cls: 0.1183, s0.acc: 95.9399, s0.loss_bbox: 0.0738, s1.loss_cls: 0.0521, s1.acc: 96.4557, s1.loss_bbox: 0.0722, s2.loss_cls: 0.0251, s2.acc: 96.6261, s2.loss_bbox: 0.0435, loss: 0.4210
2022-04-06 14:31:25,128 - mmdet - INFO - Epoch [29][250/611]	lr: 2.082e-06, eta: 1:40:51, time: 1.571, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0157, loss_rpn_bbox: 0.0185, s0.loss_cls: 0.1159, s0.acc: 95.9746, s0.loss_bbox: 0.0702, s1.loss_cls: 0.0512, s1.acc: 96.4839, s1.loss_bbox: 0.0702, s2.loss_cls: 0.0248, s2.acc: 96.4523, s2.loss_bbox: 0.0426, loss: 0.4090
2022-04-06 14:32:44,172 - mmdet - INFO - Epoch [29][300/611]	lr: 2.082e-06, eta: 1:39:37, time: 1.581, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.0206, s0.loss_cls: 0.1231, s0.acc: 95.7212, s0.loss_bbox: 0.0767, s1.loss_cls: 0.0558, s1.acc: 96.1418, s1.loss_bbox: 0.0727, s2.loss_cls: 0.0269, s2.acc: 96.1691, s2.loss_bbox: 0.0441, loss: 0.4407
2022-04-06 14:34:02,058 - mmdet - INFO - Epoch [29][350/611]	lr: 2.082e-06, eta: 1:38:21, time: 1.558, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0165, loss_rpn_bbox: 0.0190, s0.loss_cls: 0.1114, s0.acc: 96.2676, s0.loss_bbox: 0.0693, s1.loss_cls: 0.0493, s1.acc: 96.7565, s1.loss_bbox: 0.0634, s2.loss_cls: 0.0233, s2.acc: 96.7942, s2.loss_bbox: 0.0378, loss: 0.3900
2022-04-06 14:35:20,491 - mmdet - INFO - Epoch [29][400/611]	lr: 2.082e-06, eta: 1:37:05, time: 1.569, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0225, s0.loss_cls: 0.1217, s0.acc: 95.8208, s0.loss_bbox: 0.0751, s1.loss_cls: 0.0550, s1.acc: 96.3424, s1.loss_bbox: 0.0726, s2.loss_cls: 0.0270, s2.acc: 96.3177, s2.loss_bbox: 0.0432, loss: 0.4353
2022-04-06 14:36:38,416 - mmdet - INFO - Epoch [29][450/611]	lr: 2.082e-06, eta: 1:35:49, time: 1.558, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0171, loss_rpn_bbox: 0.0221, s0.loss_cls: 0.1242, s0.acc: 95.7471, s0.loss_bbox: 0.0765, s1.loss_cls: 0.0551, s1.acc: 96.2561, s1.loss_bbox: 0.0714, s2.loss_cls: 0.0263, s2.acc: 96.2956, s2.loss_bbox: 0.0438, loss: 0.4364
2022-04-06 14:37:56,891 - mmdet - INFO - Epoch [29][500/611]	lr: 2.082e-06, eta: 1:34:33, time: 1.569, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0156, loss_rpn_bbox: 0.0190, s0.loss_cls: 0.1239, s0.acc: 95.8188, s0.loss_bbox: 0.0704, s1.loss_cls: 0.0558, s1.acc: 96.2852, s1.loss_bbox: 0.0680, s2.loss_cls: 0.0264, s2.acc: 96.4446, s2.loss_bbox: 0.0408, loss: 0.4198
2022-04-06 14:39:15,299 - mmdet - INFO - Epoch [29][550/611]	lr: 2.082e-06, eta: 1:33:18, time: 1.568, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0191, loss_rpn_bbox: 0.0223, s0.loss_cls: 0.1222, s0.acc: 95.7759, s0.loss_bbox: 0.0764, s1.loss_cls: 0.0535, s1.acc: 96.4029, s1.loss_bbox: 0.0729, s2.loss_cls: 0.0257, s2.acc: 96.3931, s2.loss_bbox: 0.0433, loss: 0.4355
2022-04-06 14:40:33,839 - mmdet - INFO - Epoch [29][600/611]	lr: 2.082e-06, eta: 1:32:02, time: 1.571, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0165, loss_rpn_bbox: 0.0194, s0.loss_cls: 0.1159, s0.acc: 96.1050, s0.loss_bbox: 0.0679, s1.loss_cls: 0.0514, s1.acc: 96.6036, s1.loss_bbox: 0.0630, s2.loss_cls: 0.0244, s2.acc: 96.8130, s2.loss_bbox: 0.0383, loss: 0.3969
2022-04-06 14:40:50,952 - mmdet - INFO - Saving checkpoint at 29 epochs
2022-04-06 14:42:24,579 - mmdet - INFO - Evaluating bbox...
2022-04-06 14:42:28,150 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.719
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.025
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.233
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.066
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.385
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.695

2022-04-06 14:42:28,151 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.392 | Paper       | 0.392 | Paper pack | 0.624 |
| Metal         | 0.613 | Glass       | 0.520 | Plastic    | 0.516 |
| Styrofoam     | 0.491 | Plastic bag | 0.632 | Battery    | 0.772 |
| Clothing      | 0.543 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-06 14:42:28,188 - mmdet - INFO - Exp name: cascade_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco.py
2022-04-06 14:42:28,188 - mmdet - INFO - Epoch(val) [29][982]	bbox_mAP: 0.5490, bbox_mAP_50: 0.7190, bbox_mAP_75: 0.5820, bbox_mAP_s: 0.0250, bbox_mAP_m: 0.2330, bbox_mAP_l: 0.6160, bbox_mAP_copypaste: 0.549 0.719 0.582 0.025 0.233 0.616
2022-04-06 14:43:50,727 - mmdet - INFO - Epoch [30][50/611]	lr: 1.271e-06, eta: 1:30:14, time: 1.650, data_time: 0.086, memory: 28856, loss_rpn_cls: 0.0190, loss_rpn_bbox: 0.0209, s0.loss_cls: 0.1207, s0.acc: 95.8428, s0.loss_bbox: 0.0752, s1.loss_cls: 0.0543, s1.acc: 96.2787, s1.loss_bbox: 0.0718, s2.loss_cls: 0.0270, s2.acc: 96.2918, s2.loss_bbox: 0.0431, loss: 0.4321
2022-04-06 14:45:08,814 - mmdet - INFO - Epoch [30][100/611]	lr: 1.271e-06, eta: 1:28:58, time: 1.562, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.0196, s0.loss_cls: 0.1181, s0.acc: 95.9839, s0.loss_bbox: 0.0734, s1.loss_cls: 0.0517, s1.acc: 96.5681, s1.loss_bbox: 0.0687, s2.loss_cls: 0.0246, s2.acc: 96.6599, s2.loss_bbox: 0.0419, loss: 0.4156
2022-04-06 14:46:26,291 - mmdet - INFO - Epoch [30][150/611]	lr: 1.271e-06, eta: 1:27:42, time: 1.549, data_time: 0.021, memory: 28856, loss_rpn_cls: 0.0152, loss_rpn_bbox: 0.0197, s0.loss_cls: 0.1114, s0.acc: 96.1128, s0.loss_bbox: 0.0693, s1.loss_cls: 0.0508, s1.acc: 96.4916, s1.loss_bbox: 0.0656, s2.loss_cls: 0.0244, s2.acc: 96.5841, s2.loss_bbox: 0.0397, loss: 0.3960
2022-04-06 14:47:44,109 - mmdet - INFO - Epoch [30][200/611]	lr: 1.271e-06, eta: 1:26:25, time: 1.556, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0160, loss_rpn_bbox: 0.0194, s0.loss_cls: 0.1097, s0.acc: 96.1143, s0.loss_bbox: 0.0698, s1.loss_cls: 0.0479, s1.acc: 96.6448, s1.loss_bbox: 0.0649, s2.loss_cls: 0.0232, s2.acc: 96.8623, s2.loss_bbox: 0.0386, loss: 0.3895
2022-04-06 14:49:02,347 - mmdet - INFO - Epoch [30][250/611]	lr: 1.271e-06, eta: 1:25:09, time: 1.565, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0156, loss_rpn_bbox: 0.0175, s0.loss_cls: 0.1071, s0.acc: 96.2812, s0.loss_bbox: 0.0666, s1.loss_cls: 0.0459, s1.acc: 96.9890, s1.loss_bbox: 0.0663, s2.loss_cls: 0.0221, s2.acc: 96.9504, s2.loss_bbox: 0.0406, loss: 0.3818
2022-04-06 14:50:19,848 - mmdet - INFO - Epoch [30][300/611]	lr: 1.271e-06, eta: 1:23:53, time: 1.550, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0221, s0.loss_cls: 0.1317, s0.acc: 95.4048, s0.loss_bbox: 0.0839, s1.loss_cls: 0.0584, s1.acc: 95.9862, s1.loss_bbox: 0.0787, s2.loss_cls: 0.0278, s2.acc: 96.0959, s2.loss_bbox: 0.0475, loss: 0.4681
2022-04-06 14:51:38,258 - mmdet - INFO - Epoch [30][350/611]	lr: 1.271e-06, eta: 1:22:37, time: 1.568, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0182, loss_rpn_bbox: 0.0225, s0.loss_cls: 0.1375, s0.acc: 95.2886, s0.loss_bbox: 0.0848, s1.loss_cls: 0.0614, s1.acc: 95.8280, s1.loss_bbox: 0.0790, s2.loss_cls: 0.0296, s2.acc: 95.9522, s2.loss_bbox: 0.0469, loss: 0.4798
2022-04-06 14:52:56,200 - mmdet - INFO - Epoch [30][400/611]	lr: 1.271e-06, eta: 1:21:20, time: 1.559, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0150, loss_rpn_bbox: 0.0189, s0.loss_cls: 0.1145, s0.acc: 96.1577, s0.loss_bbox: 0.0710, s1.loss_cls: 0.0505, s1.acc: 96.7357, s1.loss_bbox: 0.0674, s2.loss_cls: 0.0241, s2.acc: 96.8118, s2.loss_bbox: 0.0398, loss: 0.4013
2022-04-06 14:54:13,864 - mmdet - INFO - Epoch [30][450/611]	lr: 1.271e-06, eta: 1:20:04, time: 1.553, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0143, loss_rpn_bbox: 0.0189, s0.loss_cls: 0.1177, s0.acc: 95.9487, s0.loss_bbox: 0.0723, s1.loss_cls: 0.0529, s1.acc: 96.3035, s1.loss_bbox: 0.0700, s2.loss_cls: 0.0251, s2.acc: 96.4734, s2.loss_bbox: 0.0417, loss: 0.4130
2022-04-06 14:55:32,012 - mmdet - INFO - Epoch [30][500/611]	lr: 1.271e-06, eta: 1:18:47, time: 1.563, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0163, loss_rpn_bbox: 0.0214, s0.loss_cls: 0.1160, s0.acc: 95.9644, s0.loss_bbox: 0.0721, s1.loss_cls: 0.0520, s1.acc: 96.3959, s1.loss_bbox: 0.0707, s2.loss_cls: 0.0257, s2.acc: 96.4649, s2.loss_bbox: 0.0416, loss: 0.4158
2022-04-06 14:56:49,346 - mmdet - INFO - Epoch [30][550/611]	lr: 1.271e-06, eta: 1:17:30, time: 1.547, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0162, loss_rpn_bbox: 0.0198, s0.loss_cls: 0.1164, s0.acc: 96.0298, s0.loss_bbox: 0.0678, s1.loss_cls: 0.0522, s1.acc: 96.5012, s1.loss_bbox: 0.0655, s2.loss_cls: 0.0251, s2.acc: 96.5436, s2.loss_bbox: 0.0401, loss: 0.4031
2022-04-06 14:58:07,177 - mmdet - INFO - Epoch [30][600/611]	lr: 1.271e-06, eta: 1:16:14, time: 1.557, data_time: 0.022, memory: 28856, loss_rpn_cls: 0.0209, loss_rpn_bbox: 0.0219, s0.loss_cls: 0.1210, s0.acc: 95.9458, s0.loss_bbox: 0.0702, s1.loss_cls: 0.0530, s1.acc: 96.4881, s1.loss_bbox: 0.0667, s2.loss_cls: 0.0258, s2.acc: 96.5480, s2.loss_bbox: 0.0407, loss: 0.4201
2022-04-06 14:58:24,364 - mmdet - INFO - Saving checkpoint at 30 epochs
2022-04-06 14:59:57,589 - mmdet - INFO - Evaluating bbox...
2022-04-06 15:00:01,073 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.554
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.587
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.026
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.239
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.065
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.389
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.697

2022-04-06 15:00:01,074 - mmdet - INFO - 
+---------------+-------+-------------+-------+------------+-------+
| category      | AP    | category    | AP    | category   | AP    |
+---------------+-------+-------------+-------+------------+-------+
| General trash | 0.398 | Paper       | 0.392 | Paper pack | 0.631 |
| Metal         | 0.615 | Glass       | 0.521 | Plastic    | 0.519 |
| Styrofoam     | 0.493 | Plastic bag | 0.634 | Battery    | 0.779 |
| Clothing      | 0.560 | None        | None  | None       | None  |
+---------------+-------+-------------+-------+------------+-------+
2022-04-06 15:00:01,109 - mmdet - INFO - Exp name: cascade_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco.py
2022-04-06 15:00:01,109 - mmdet - INFO - Epoch(val) [30][982]	bbox_mAP: 0.5540, bbox_mAP_50: 0.7230, bbox_mAP_75: 0.5870, bbox_mAP_s: 0.0260, bbox_mAP_m: 0.2390, bbox_mAP_l: 0.6200, bbox_mAP_copypaste: 0.554 0.723 0.587 0.026 0.239 0.620

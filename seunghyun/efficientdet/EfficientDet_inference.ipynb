{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GLb2lMFmNl8O"
   },
   "outputs": [],
   "source": [
    "# 라이브러리 및 모듈 import\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eVbwnEcyNl8b"
   },
   "outputs": [],
   "source": [
    "# CustomDataset class 선언\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "      data_dir: data가 존재하는 폴더 경로\n",
    "      transforms: data transform (resize, crop, Totensor, etc,,,)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotation, data_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "        self.predictions = {\n",
    "            \"images\": self.coco.dataset[\"images\"].copy(),\n",
    "            \"categories\": self.coco.dataset[\"categories\"].copy(),\n",
    "            \"annotations\": None\n",
    "        }\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        # 라벨 등 이미지 외 다른 정보 없기 때문에 train dataset과 달리 이미지만 전처리\n",
    "        \n",
    "        # transform\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image=image)\n",
    "\n",
    "        return sample['image'], image_id\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8XAO7td8Nl8d"
   },
   "outputs": [],
   "source": [
    "# Albumentation을 이용, augmentation 선언\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        A.Flip(p=0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "R_XLukpXNl8e"
   },
   "outputs": [],
   "source": [
    "from effdet import DetBenchPredict\n",
    "import gc\n",
    "\n",
    "# Effdet config를 통해 모델 불러오기 + ckpt load\n",
    "def load_net(checkpoint_path, device):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d3')\n",
    "    config.num_classes = 10\n",
    "    config.image_size = (512,512)\n",
    "    \n",
    "    config.soft_nms = False\n",
    "    config.max_det_per_image = 50\n",
    "    \n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes)\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    net = DetBenchPredict(net)\n",
    "    net.load_state_dict(checkpoint)\n",
    "    net.eval()\n",
    "\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zM1rE2zCNl8g"
   },
   "outputs": [],
   "source": [
    "# valid function\n",
    "def valid_fn(val_data_loader, model, device):\n",
    "    outputs = []\n",
    "    for images, image_ids in tqdm(val_data_loader):\n",
    "        # gpu 계산을 위해 image.to(device)       \n",
    "        images = torch.stack(images) # bs, ch, w, h \n",
    "        images = images.to(device).float()\n",
    "        output = model(images)\n",
    "        for out in output:\n",
    "            outputs.append({'boxes': out.detach().cpu().numpy()[:,:4], \n",
    "                            'scores': out.detach().cpu().numpy()[:,4], \n",
    "                            'labels': out.detach().cpu().numpy()[:,-1]})\n",
    "    return outputs\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eH4GRrXlNl8l"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    annotation = '../../dataset/test.json'\n",
    "    data_dir = '../../dataset'\n",
    "    val_dataset = CustomDataset(annotation, data_dir, get_valid_transform())\n",
    "    for fold, epoch  in zip([1, 2, 3, 4, 5], [81, 46, 62, 65, 55]):\n",
    "        \n",
    "        checkpoint_path = f'./pretrained/fold{fold}/epoch_{epoch}.pth'\n",
    "        # epoch = checkpoint_path.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        print(f'fold{fold}, epoch{epoch}: {checkpoint_path}')\n",
    "\n",
    "        score_threshold = 0.1\n",
    "        val_data_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=4,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        print(device)\n",
    "\n",
    "        model = load_net(checkpoint_path, device)\n",
    "\n",
    "        outputs = valid_fn(val_data_loader, model, device)\n",
    "\n",
    "        prediction_strings = []\n",
    "        file_names = []\n",
    "        coco = COCO(annotation)\n",
    "\n",
    "        for i, output in enumerate(outputs):\n",
    "            prediction_string = ''\n",
    "            image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "            for box, score, label in zip(output['boxes'], output['scores'], output['labels']):\n",
    "                if score > score_threshold:\n",
    "                    prediction_string += str(int(label)-1) + ' ' + str(score) + ' ' + str(box[0] * 2) + ' ' + str(\n",
    "                        box[1] * 2) + ' ' + str(box[2] * 2) + ' ' + str(box[3] * 2) + ' '\n",
    "            prediction_strings.append(prediction_string)\n",
    "            file_names.append(image_info['file_name'])\n",
    "\n",
    "        submission = pd.DataFrame()\n",
    "        submission['PredictionString'] = prediction_strings\n",
    "        submission['image_id'] = file_names\n",
    "        submission.to_csv(f'effdet_submissions/effdet_fold{fold}_epoch_{epoch}.csv', index=None)\n",
    "        print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1TpoSuGCNl8n",
    "outputId": "3df656f0-24df-4aa9-e544-3955810ef4c1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "fold1, epoch81: ./pretrained/fold1/epoch_81.pth\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [03:26<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "                                    PredictionString       image_id\n",
      "0  7 0.9299216 603.4823608398438 512.719299316406...  test/0000.jpg\n",
      "1  5 0.62437433 142.91941833496094 1.875686645507...  test/0001.jpg\n",
      "2  1 0.7901068 279.421630859375 261.6471557617187...  test/0002.jpg\n",
      "3  9 0.74314713 145.923095703125 254.927459716796...  test/0003.jpg\n",
      "4  7 0.81348485 201.53683471679688 244.2016601562...  test/0004.jpg\n",
      "fold2, epoch46: ./pretrained/fold2/epoch_46.pth\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [03:26<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "                                    PredictionString       image_id\n",
      "0  7 0.9180697 220.8009033203125 57.9095153808593...  test/0000.jpg\n",
      "1  5 0.6502935 139.77149963378906 3.8359985351562...  test/0001.jpg\n",
      "2  1 0.69247663 287.4536437988281 330.17990112304...  test/0002.jpg\n",
      "3  9 0.70538384 143.6434326171875 254.58435058593...  test/0003.jpg\n",
      "4  1 0.4975834 191.9168701171875 270.29248046875 ...  test/0004.jpg\n",
      "fold3, epoch62: ./pretrained/fold3/epoch_62.pth\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [03:25<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "                                    PredictionString       image_id\n",
      "0  7 0.96499103 223.342529296875 49.5193939208984...  test/0000.jpg\n",
      "1  5 0.70357233 137.8030548095703 0.9522399902343...  test/0001.jpg\n",
      "2  1 0.7618972 315.6864318847656 308.734680175781...  test/0002.jpg\n",
      "3  9 0.51350516 133.09820556640625 263.4837646484...  test/0003.jpg\n",
      "4  0 0.5149405 205.68875122070312 335.8544921875 ...  test/0004.jpg\n",
      "fold4, epoch65: ./pretrained/fold4/epoch_65.pth\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [03:32<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "                                    PredictionString       image_id\n",
      "0  7 0.9560713 612.5043334960938 530.345642089843...  test/0000.jpg\n",
      "1  5 0.8271004 135.14688110351562 6.2983703613281...  test/0001.jpg\n",
      "2  1 0.8122465 99.21257019042969 290.108459472656...  test/0002.jpg\n",
      "3  9 0.8097313 145.3818359375 248.24847412109375 ...  test/0003.jpg\n",
      "4  7 0.78980166 183.87530517578125 264.0597839355...  test/0004.jpg\n",
      "fold5, epoch55: ./pretrained/fold5/epoch_55.pth\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [03:28<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "                                    PredictionString       image_id\n",
      "0  7 0.9540538 609.06884765625 524.638916015625 9...  test/0000.jpg\n",
      "1  3 0.77380335 350.5903625488281 229.86987304687...  test/0001.jpg\n",
      "2  1 0.82217926 299.5276794433594 280.63452148437...  test/0002.jpg\n",
      "3  9 0.83619136 133.674072265625 266.681915283203...  test/0003.jpg\n",
      "4  7 0.91149044 209.179931640625 260.293701171875...  test/0004.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TckxFyr3Nl8r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EfficientDet_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
